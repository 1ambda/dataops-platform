# Day 1: Core Engine êµ¬í˜„ ê°€ì´ë“œ

## ê°œìš”

Day 1ì—ì„œëŠ” DLI_HOME ê¸°ë°˜ì˜ Dataset Spec ì‹œìŠ¤í…œê³¼ Core Engineì„ êµ¬í˜„í•©ë‹ˆë‹¤.

### êµ¬í˜„ ìƒíƒœ

| í•­ëª© | ìƒíƒœ |
|------|------|
| ì™„ë£Œì¼ | 2025-12-29 |
| í…ŒìŠ¤íŠ¸ | 393 tests passed (core + CLI + library) |
| ì½”ë“œ í’ˆì§ˆ | pyright 0 errors, ruff 0 errors |

### ì£¼ìš” ë³€ê²½ì‚¬í•­ (v1 â†’ v2 â†’ v3)

| í•­ëª© | v1 (ê¸°ì¡´) | v2 | v3 (ì‹ ê·œ) |
|------|----------|----------|----------|
| Spec íƒ€ì… | ë‹¨ì¼ | ë‹¨ì¼ DatasetSpec | **MetricSpec + DatasetSpec ë¶„ë¦¬** |
| íŒŒì¼ ëª…ëª… | `_schema.yml` | `spec.*.yaml` | `metric.*.yaml` + `dataset.*.yaml` |
| ë””ë ‰í† ë¦¬ | `queries/` ê³ ì • | `$DLI_HOME/datasets/` | `metrics/` + `datasets/` ë¶„ë¦¬ |
| ì¿¼ë¦¬ íƒ€ì… | SELECT ì¤‘ì‹¬ | SELECT / DML | **Metric=SELECT, Dataset=DML ê°•ì œ** |
| ì‹¤í–‰ ë‹¨ê³„ | Mainë§Œ | Pre â†’ Main â†’ Post | Pre/PostëŠ” Dataset ì „ìš© |
| ë©”íŠ¸ë¦­ ì •ì˜ | ì—†ìŒ | DatasetSpec ë‚´ | **MetricSpec ì „ìš©** |

---

## Metric/Dataset ë¶„ë¦¬ (v3)

v3ì—ì„œëŠ” Metricê³¼ Datasetì„ ëª…í™•íˆ ë¶„ë¦¬í•˜ì—¬ ê´€ë¦¬í•©ë‹ˆë‹¤.

### í•µì‹¬ ì›ì¹™

| êµ¬ë¶„ | MetricSpec | DatasetSpec |
|------|------------|-------------|
| **type í•„ë“œ** | `Metric` | `Dataset` |
| **query_type** | `SELECT` (ê°•ì œ) | `DML` (ê°•ì œ) |
| **ìš©ë„** | ì½ê¸° ì „ìš© ë¶„ì„ ì¿¼ë¦¬ | ë°ì´í„° ì²˜ë¦¬ (INSERT/UPDATE/DELETE/MERGE) |
| **ë©”íŠ¸ë¦­/ë””ë©˜ì…˜** | ì§€ì› | ë¯¸ì§€ì› |
| **Pre/Post ë¬¸** | ë¯¸ì§€ì› | ì§€ì› |
| **íŒŒì¼ íŒ¨í„´** | `metric.*.yaml` | `dataset.*.yaml` |
| **ë””ë ‰í† ë¦¬** | `metrics/` | `datasets/` |

### íŒŒì¼ ëª…ëª… ê·œì¹™

```
# MetricSpec
metric.{catalog}.{schema}.{name}.yaml
ì˜ˆ: metric.iceberg.analytics.user_engagement.yaml

# DatasetSpec
dataset.{catalog}.{schema}.{name}.yaml
ì˜ˆ: dataset.iceberg.analytics.daily_clicks.yaml
```

### ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
$DLI_HOME/
â”œâ”€â”€ dli.yaml
â”œâ”€â”€ metrics/                              # ë©”íŠ¸ë¦­ ì „ìš©
â”‚   â”œâ”€â”€ analytics/
â”‚   â”‚   â”œâ”€â”€ metric.iceberg.analytics.user_engagement.yaml
â”‚   â”‚   â””â”€â”€ user_engagement.sql
â”‚   â””â”€â”€ revenue/
â”‚       â””â”€â”€ metric.iceberg.analytics.revenue_summary.yaml
â”œâ”€â”€ datasets/                             # ë°ì´í„°ì…‹ ì „ìš©
â”‚   â”œâ”€â”€ feed/
â”‚   â”‚   â”œâ”€â”€ dataset.iceberg.analytics.daily_clicks.yaml
â”‚   â”‚   â””â”€â”€ daily_clicks.sql
â”‚   â””â”€â”€ reporting/
â”‚       â””â”€â”€ dataset.iceberg.reporting.daily_summary.yaml
```

### dli.yaml ì„¤ì •

```yaml
discovery:
  datasets_dir: "datasets"
  metrics_dir: "metrics"

  metric_patterns:
    - "metric.*.yaml"
    - "metric.yaml"
  dataset_patterns:
    - "dataset.*.yaml"
    - "dataset.yaml"
```

### ëª¨ë¸ í´ë˜ìŠ¤

```python
from dli.core import (
    SpecType,      # Metric | Dataset
    SpecBase,      # ê³µí†µ ê¸°ë°˜ í´ë˜ìŠ¤
    MetricSpec,    # type=Metric, query_type=SELECT
    DatasetSpec,   # type=Dataset, query_type=DML
    Spec,          # MetricSpec | DatasetSpec (Union)
)

# MetricSpec ìƒì„± (SELECT ì „ìš©)
metric = MetricSpec(
    name="iceberg.analytics.user_engagement",
    owner="analyst@example.com",
    team="@analytics",
    query_statement="SELECT * FROM user_events",
    metrics=[...],
    dimensions=[...],
)

# DatasetSpec ìƒì„± (DML ì „ìš©)
dataset = DatasetSpec(
    name="iceberg.analytics.daily_clicks",
    owner="engineer@example.com",
    team="@data-engineering",
    query_file="daily_clicks.sql",
    pre_statements=[...],
    post_statements=[...],
)
```

### Discovery API

```python
from dli.core import SpecDiscovery, DatasetDiscovery

# í†µí•© Discovery (ì‹ ê·œ)
spec_discovery = SpecDiscovery(config)
for spec in spec_discovery.discover_all():      # MetricSpec | DatasetSpec
    print(f"{spec.type}: {spec.name}")

for metric in spec_discovery.discover_metrics(): # MetricSpecë§Œ
    print(f"Metric: {metric.name}")

for dataset in spec_discovery.discover_datasets(): # DatasetSpecë§Œ
    print(f"Dataset: {dataset.name}")

# DatasetDiscovery (DatasetSpec ì „ìš©)
dataset_discovery = DatasetDiscovery(config)
for dataset in dataset_discovery.discover_all():
    print(f"Dataset: {dataset.name}")
```

### ìœ íš¨ì„± ê²€ì‚¬

```python
# typeê³¼ query_type ë¶ˆì¼ì¹˜ ì‹œ ì—ëŸ¬
MetricSpec(
    name="test",
    owner="test@test.com",
    team="@test",
    query_type="DML",  # ì—ëŸ¬! Metricì€ SELECTë§Œ ê°€ëŠ¥
    query_statement="INSERT INTO t SELECT 1",
)
# ValueError: Metric 'test' must have query_type='SELECT'

DatasetSpec(
    name="test",
    owner="test@test.com",
    team="@test",
    query_type="SELECT",  # ì—ëŸ¬! Datasetì€ DMLë§Œ ê°€ëŠ¥
    query_statement="SELECT 1",
)
# ValueError: Dataset 'test' must have query_type='DML'
```

---

## ì—…ê³„ í‘œì¤€ ì°¸ê³ 

| í‘œì¤€/ë„êµ¬ | ì°¸ê³  í¬ì¸íŠ¸ | ì ìš© |
|-----------|------------|------|
| [Open Semantic Interchange (OSI)](https://opensemanticinterchange.org/) | ë²¤ë” ì¤‘ë¦½ YAML í‘œì¤€ | Spec íŒŒì¼ êµ¬ì¡° |
| [dbt MetricFlow](https://docs.getdbt.com/docs/build/about-metricflow) | semantic_models + metrics | ë©”íƒ€ë°ì´í„° í•„ë“œ |
| [Databricks Unity Catalog](https://docs.databricks.com/aws/en/metric-views/) | `catalog.schema.table` ë„¤ì„ìŠ¤í˜ì´ìŠ¤ | 3ë ˆë²¨ ì‹ë³„ì |
| [SQLMesh](https://sqlmesh.readthedocs.io/en/stable/concepts/models/overview/) | MODEL DDL + external YAML | í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹ |

---

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
project-interface-cli/
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ src/dli/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ __main__.py          # python -m dli ì§€ì›
â”‚   â”œâ”€â”€ main.py              # Typer CLI ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ models/          # ëª¨ë¸ íŒ¨í‚¤ì§€ (ë¶„ë¦¬ë¨)
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py  # í•˜ìœ„ í˜¸í™˜ re-exports
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py      # ê¸°ë³¸ Enums, QueryParameter, StatementDefinition
â”‚   â”‚   â”‚   â”œâ”€â”€ spec.py      # SpecBase ì¶”ìƒ í´ë˜ìŠ¤
â”‚   â”‚   â”‚   â”œâ”€â”€ metric.py    # MetricSpec, MetricDefinition, DimensionDefinition
â”‚   â”‚   â”‚   â”œâ”€â”€ dataset.py   # DatasetSpec
â”‚   â”‚   â”‚   â””â”€â”€ results.py   # ValidationResult, ExecutionResult
â”‚   â”‚   â”œâ”€â”€ discovery.py     # DLI_HOME íƒìƒ‰, íŒŒì¼ ë¡œë“œ
â”‚   â”‚   â”œâ”€â”€ registry.py      # Dataset ë ˆì§€ìŠ¤íŠ¸ë¦¬
â”‚   â”‚   â”œâ”€â”€ renderer.py      # Jinja2 ë Œë”ëŸ¬
â”‚   â”‚   â”œâ”€â”€ templates.py     # Safe í…œí”Œë¦¿ ì»¨í…ìŠ¤íŠ¸ (dbt/SQLMesh í˜¸í™˜)
â”‚   â”‚   â”œâ”€â”€ validator.py     # SQLGlot ê²€ì¦
â”‚   â”‚   â”œâ”€â”€ executor.py      # ì‹¤í–‰ ì¶”ìƒí™”
â”‚   â”‚   â””â”€â”€ service.py       # í†µí•© ì„œë¹„ìŠ¤
â”‚   â””â”€â”€ adapters/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ bigquery.py
â””â”€â”€ tests/
    â”œâ”€â”€ cli/                 # CLI í…ŒìŠ¤íŠ¸ (ì‹ ê·œ)
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ test_main.py     # 32 CLI ì»¤ë§¨ë“œ í…ŒìŠ¤íŠ¸
    â”œâ”€â”€ core/
    â”‚   â”œâ”€â”€ test_models.py
    â”‚   â”œâ”€â”€ test_discovery.py
    â”‚   â”œâ”€â”€ test_registry.py
    â”‚   â”œâ”€â”€ test_renderer.py
    â”‚   â”œâ”€â”€ test_templates.py
    â”‚   â”œâ”€â”€ test_validator.py
    â”‚   â”œâ”€â”€ test_executor.py
    â”‚   â””â”€â”€ test_service.py
    â””â”€â”€ fixtures/
        â””â”€â”€ sample_project/
```

---

## DLI_HOME ë””ë ‰í† ë¦¬ êµ¬ì¡°

### ìœ ì—°í•œ êµ¬ì¡° ì§€ì›

```
$DLI_HOME/
â”œâ”€â”€ dli.yaml                          # í”„ë¡œì íŠ¸ ì„¤ì • (í•„ìˆ˜)
â”œâ”€â”€ datasets/                         # ë°ì´í„°ì…‹ ë£¨íŠ¸
â”‚   â”‚
â”‚   â”‚  # ì˜µì…˜ A: Flat êµ¬ì¡° (ì†Œê·œëª¨)
â”‚   â”œâ”€â”€ dataset.iceberg.analytics.daily_clicks.yaml
â”‚   â”œâ”€â”€ daily_clicks.sql
â”‚   â”‚
â”‚   â”‚  # ì˜µì…˜ B: Domain ê¸°ë°˜ êµ¬ì¡° (ê¶Œì¥)
â”‚   â”œâ”€â”€ feed/
â”‚   â”‚   â”œâ”€â”€ dataset.iceberg.analytics.daily_clicks.yaml
â”‚   â”‚   â”œâ”€â”€ daily_clicks.sql
â”‚   â”‚   â”œâ”€â”€ daily_clicks_pre.sql
â”‚   â”‚   â””â”€â”€ daily_clicks_post.sql
â”‚   â”‚
â”‚   â”‚  # ì˜µì…˜ C: Catalog/Schema ê³„ì¸µ (ëŒ€ê·œëª¨)
â”‚   â””â”€â”€ iceberg/
â”‚       â””â”€â”€ analytics/
â”‚           â””â”€â”€ daily_clicks/
â”‚               â”œâ”€â”€ dataset.yaml
â”‚               â”œâ”€â”€ main.sql
â”‚               â”œâ”€â”€ pre.sql
â”‚               â””â”€â”€ post.sql
â”‚
â””â”€â”€ templates/                        # ê³µí†µ Jinja2 ë§¤í¬ë¡œ
    â””â”€â”€ macros.sql
```

### dli.yaml (í”„ë¡œì íŠ¸ ì„¤ì •)

```yaml
version: "1"

project:
  name: "dataops-metrics"
  description: "Data Analytics Metrics Project"

discovery:
  datasets_dir: "datasets"
  metrics_dir: "metrics"
  dataset_patterns:
    - "dataset.*.yaml"
    - "dataset.yaml"
  metric_patterns:
    - "metric.*.yaml"
    - "metric.yaml"
  sql_patterns:
    - "*.sql"

defaults:
  dialect: "trino"
  timeout_seconds: 3600
  retry_count: 2

environments:
  dev:
    connection_string: "trino://localhost:8080/iceberg"
  prod:
    connection_string: "trino://trino-prod.internal:8080/iceberg"
```

---

## Spec íŒŒì¼ ìŠ¤í‚¤ë§ˆ

```yaml
# dataset.{catalog}.{schema}.{table}.yaml ë˜ëŠ” metric.{catalog}.{schema}.{table}.yaml

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. ê¸°ë³¸ ì‹ë³„ì (Required)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
name: "iceberg.analytics.daily_clicks"    # catalog.schema.table
description: "1ì¸ë‹¹ item í‰ê·  í´ë¦­ìˆ˜"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. ì†Œìœ ê¶Œ ë° ë„ë©”ì¸ (Required)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
owner: "henrykim@example.com"
team: "@data-analytics"
domains:
  - "feed"
  - "engagement"
tags:
  - "daily"
  - "kpi"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. ë²„ì „ ê´€ë¦¬ (Optional)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
versions:
  - version: "v1"
    started_at: "2015-12-01"
    ended_at: "2022-05-31"
    description: "ì´ˆê¸° ë²„ì „"
  - version: "v2"
    started_at: "2022-06-01"
    ended_at: null              # null = í˜„ì¬ í™œì„±
    description: "Window Function ì ìš©"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. ì¿¼ë¦¬ íƒ€ì… (Required)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
query_type: "DML"               # SELECT | DML

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5. íŒŒë¼ë¯¸í„° (Optional)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
parameters:
  - name: "execution_date"
    type: "date"
    required: true
    description: "ì‹¤í–‰ ê¸°ì¤€ ë‚ ì§œ"
  - name: "lookback_days"
    type: "integer"
    required: false
    default: 7

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 6. Pre Statements (Optional)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
pre_statements:
  - name: "delete_partition"
    sql: |
      DELETE FROM iceberg.analytics.daily_clicks
      WHERE dt = '{{ execution_date }}'
  - name: "analyze_source"
    file: "analyze_source.sql"
    continue_on_error: true

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 7. Main Query (Required: íƒì¼)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë°©ì‹ A: ì¸ë¼ì¸ SQL
query_statement: |
  INSERT INTO iceberg.analytics.daily_clicks
  SELECT ...

# ë°©ì‹ B: íŒŒì¼ ì°¸ì¡° (IDE ìë™ì™„ì„± ì§€ì›)
query_file: "daily_clicks.sql"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 8. Post Statements (Optional)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
post_statements:
  - name: "optimize"
    file: "optimize.sql"
  - name: "expire_snapshots"
    file: "expire_snapshots.sql"
    continue_on_error: true

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 9. ì‹¤í–‰ ì„¤ì • (Optional)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
execution:
  timeout_seconds: 3600
  retry_count: 2
  retry_delay_seconds: 60
  dialect: "trino"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 10. ì˜ì¡´ì„± (Optional)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
depends_on:
  - "iceberg.raw.user_events"
  - "iceberg.dim.users"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 11. ì¶œë ¥ ìŠ¤í‚¤ë§ˆ (Optional, SELECT ê¶Œì¥)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
schema:
  - name: "dt"
    type: "date"
  - name: "user_id"
    type: "string"
  - name: "click_count"
    type: "integer"
```

---

## êµ¬í˜„ëœ ëª¨ë“ˆ

### 1. models.py

Pydantic ê¸°ë°˜ ë°ì´í„° ëª¨ë¸:

- `QueryType`: SELECT | DML enum
- `ParameterType`: string, integer, float, date, boolean, list
- `QueryParameter`: íŒŒë¼ë¯¸í„° ì •ì˜ ë° íƒ€ì… ë³€í™˜
- `StatementDefinition`: Pre/Post SQL ì •ì˜
- `DatasetVersion`: ë²„ì „ ì •ë³´
- `ExecutionConfig`: ì‹¤í–‰ ì„¤ì •
- `DatasetSpec`: Spec íŒŒì¼ ì „ì²´ êµ¬ì¡°
- `ValidationResult`: SQL ê²€ì¦ ê²°ê³¼
- `ExecutionResult`: ë‹¨ì¼ SQL ì‹¤í–‰ ê²°ê³¼
- `DatasetExecutionResult`: 3ë‹¨ê³„ ì‹¤í–‰ ì „ì²´ ê²°ê³¼

```python
from dli.core import DatasetSpec, QueryType, QueryParameter, ParameterType

spec = DatasetSpec(
    name="iceberg.analytics.daily_clicks",
    owner="henry@example.com",
    team="@analytics",
    domains=["feed"],
    tags=["daily", "kpi"],
    query_type=QueryType.DML,
    parameters=[
        QueryParameter(name="execution_date", type=ParameterType.DATE, required=True),
        QueryParameter(name="lookback_days", type=ParameterType.INTEGER, default=7),
    ],
    query_statement="INSERT INTO t SELECT * FROM s WHERE dt = '{{ execution_date }}'",
)
```

### 2. discovery.py

DLI_HOME íƒìƒ‰ ë° í”„ë¡œì íŠ¸ ì„¤ì • ë¡œë“œ:

- `ProjectConfig`: dli.yaml íŒŒì‹±
- `DatasetDiscovery`: Spec íŒŒì¼ íƒìƒ‰ ë° ë¡œë“œ
- `get_dli_home()`: DLI_HOME í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” í˜„ì¬ ë””ë ‰í† ë¦¬
- `load_project()`: í”„ë¡œì íŠ¸ ì„¤ì • ë¡œë“œ

```python
from dli.core import load_project, DatasetDiscovery

config = load_project(Path("/path/to/dli_home"))
discovery = DatasetDiscovery(config)

for spec in discovery.discover_all():
    print(f"{spec.name}: {spec.description}")
```

### 3. registry.py

Dataset ìºì‹± ë° ë‹¤ì°¨ì› ê²€ìƒ‰:

```python
from dli.core import DatasetRegistry

registry = DatasetRegistry(config)

# ê²€ìƒ‰
datasets = registry.search(domain="feed", tag="kpi")
dataset = registry.get("iceberg.analytics.daily_clicks")

# ë©”íƒ€ë°ì´í„° ì¡°íšŒ
catalogs = registry.get_catalogs()
domains = registry.get_domains()
```

### 4. renderer.py

Jinja2 ê¸°ë°˜ SQL ë Œë”ëŸ¬:

```python
from dli.core import SQLRenderer

renderer = SQLRenderer()
sql = renderer.render(
    "SELECT * FROM t WHERE dt = '{{ execution_date }}'",
    parameters=[QueryParameter(name="execution_date", type=ParameterType.DATE)],
    values={"execution_date": "2025-01-01"},
)
```

**ì»¤ìŠ¤í…€ í•„í„°**:
- `sql_string`: SQL ë¬¸ìì—´ ì´ìŠ¤ì¼€ì´í”„ (`'value'`)
- `sql_list`: ë¦¬ìŠ¤íŠ¸ë¥¼ SQL IN ì ˆë¡œ (`(1, 2, 3)`)
- `sql_date`: ë‚ ì§œ í¬ë§· (`DATE '2025-01-01'`)
- `sql_identifier`: ì‹ë³„ì ì´ìŠ¤ì¼€ì´í”„ (`"table_name"`)

### 5. validator.py

SQLGlot ê¸°ë°˜ SQL ê²€ì¦:

```python
from dli.core import SQLValidator

validator = SQLValidator(dialect="trino")
result = validator.validate("SELECT * FROM users")

if result.is_valid:
    tables = validator.extract_tables("SELECT * FROM users JOIN orders")
    formatted = validator.format_sql("select * from users")
```

### 6. executor.py

3ë‹¨ê³„ ì‹¤í–‰ ì—”ì§„ (Pre â†’ Main â†’ Post):

- `BaseExecutor`: ì¶”ìƒ ì‹¤í–‰ ì¸í„°í˜ì´ìŠ¤
- `MockExecutor`: í…ŒìŠ¤íŠ¸ìš© Mock ì‹¤í–‰ê¸°
- `DatasetExecutor`: 3ë‹¨ê³„ ì‹¤í–‰ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°

```python
from dli.core import MockExecutor, DatasetExecutor

executor = MockExecutor()
dataset_executor = DatasetExecutor(executor)

result = dataset_executor.execute(
    spec,
    rendered_sqls={
        "pre": ["DELETE FROM t WHERE dt = '2025-01-01'"],
        "main": "INSERT INTO t SELECT ...",
        "post": ["OPTIMIZE TABLE t"],
    },
)

print(f"Success: {result.success}")
print(f"Pre results: {len(result.pre_results)}")
print(f"Main result: {result.main_result}")
print(f"Post results: {len(result.post_results)}")
```

### 7. service.py

í†µí•© ì„œë¹„ìŠ¤ ë ˆì´ì–´:

```python
from dli.core import DatasetService, MockExecutor

service = DatasetService(
    project_path=Path("/path/to/dli_home"),
    executor=MockExecutor(),
)

# ë°ì´í„°ì…‹ ëª©ë¡
datasets = service.list_datasets(domain="feed")

# ê²€ì¦
results = service.validate("iceberg.analytics.daily_clicks", {"execution_date": "2025-01-01"})

# ì‹¤í–‰
result = service.execute(
    "iceberg.analytics.daily_clicks",
    {"execution_date": "2025-01-01"},
    dry_run=False,
)
```

### 8. metric_service.py

ë©”íŠ¸ë¦­ ì‹¤í–‰ ì„œë¹„ìŠ¤ (SELECT ì¿¼ë¦¬ ì „ìš©):

```python
from dli.core import MetricService, MockExecutor

service = MetricService(
    project_path=Path("/path/to/dli_home"),
    executor=MockExecutor(),
)

# ë©”íŠ¸ë¦­ ëª©ë¡
metrics = service.list_metrics(domain="reporting")

# ê²€ì¦
results = service.validate("iceberg.reporting.user_summary", {"date": "2025-01-01"})

# ì‹¤í–‰ (SELECT ê²°ê³¼ ë°˜í™˜)
result = service.execute(
    "iceberg.reporting.user_summary",
    {"date": "2025-01-01"},
)

if result.success:
    print(f"Rows: {result.rows}")
    print(f"Columns: {result.columns}")
    print(f"Row count: {result.row_count}")
```

---

## Library API (Airflow ì—°ë™)

dliëŠ” CLI ë¿ë§Œ ì•„ë‹ˆë¼ **Python ë¼ì´ë¸ŒëŸ¬ë¦¬**ë¡œë„ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.
Airflowì˜ PythonOperatorì—ì„œ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì„¤ì¹˜

```bash
# ê¸°ë³¸ ì„¤ì¹˜
pip install dataops-cli

# Airflow í™˜ê²½ì—ì„œ ì‚¬ìš© ì‹œ
pip install dataops-cli[airflow]

# BigQuery ì‹¤í–‰ ì‹œ
pip install dataops-cli[bigquery]
```

### Airflow DAG ì˜ˆì‹œ

```python
from datetime import datetime
from airflow import DAG
from airflow.operators.python import PythonOperator

from dli.core import DatasetService, MetricService

def run_dataset(ds: str, **context):
    """Dataset ì‹¤í–‰ (INSERT/UPDATE/DELETE/MERGE)."""
    service = DatasetService(project_path="/opt/airflow/dli_home")
    result = service.execute(
        "iceberg.analytics.daily_clicks",
        {"execution_date": ds},
    )
    if not result.success:
        raise Exception(result.error_message)
    return {"success": True, "main_rows": result.main_result.row_count}

def run_metric(ds: str, **context):
    """Metric ì‹¤í–‰ (SELECT)."""
    service = MetricService(project_path="/opt/airflow/dli_home")
    result = service.execute(
        "iceberg.reporting.user_summary",
        {"date": ds},
    )
    if not result.success:
        raise Exception(result.error_message)
    # XComìœ¼ë¡œ ê²°ê³¼ ì „ë‹¬
    return {"rows": result.rows, "row_count": result.row_count}

with DAG(
    dag_id="dli_example",
    start_date=datetime(2025, 1, 1),
    schedule="@daily",
) as dag:

    dataset_task = PythonOperator(
        task_id="run_daily_clicks",
        python_callable=run_dataset,
    )

    metric_task = PythonOperator(
        task_id="run_user_summary",
        python_callable=run_metric,
    )

    dataset_task >> metric_task
```

### ì£¼ìš” API

| í´ë˜ìŠ¤ | ìš©ë„ | ì¿¼ë¦¬ íƒ€ì… |
|--------|------|----------|
| `DatasetService` | Dataset ì‹¤í–‰ (ë°ì´í„° ì²˜ë¦¬) | DML (INSERT/UPDATE/DELETE/MERGE) |
| `MetricService` | Metric ì‹¤í–‰ (ë¶„ì„ ì¿¼ë¦¬) | SELECT |

### DatasetService ë©”ì„œë“œ

| ë©”ì„œë“œ | ì„¤ëª… |
|--------|------|
| `list_datasets()` | ë°ì´í„°ì…‹ ëª©ë¡ (í•„í„°ë§ ì§€ì›) |
| `get_dataset(name)` | ë°ì´í„°ì…‹ ì¡°íšŒ |
| `validate(name, params)` | SQL ê²€ì¦ (Pre, Main, Post) |
| `render_sql(name, params)` | SQL ë Œë”ë§ |
| `execute(name, params)` | ì‹¤í–‰ (skip_pre, skip_post, dry_run ì˜µì…˜) |

### MetricService ë©”ì„œë“œ

| ë©”ì„œë“œ | ì„¤ëª… |
|--------|------|
| `list_metrics()` | ë©”íŠ¸ë¦­ ëª©ë¡ (í•„í„°ë§ ì§€ì›) |
| `get_metric(name)` | ë©”íŠ¸ë¦­ ì¡°íšŒ |
| `validate(name, params)` | SQL ê²€ì¦ |
| `render_sql(name, params)` | SQL ë Œë”ë§ |
| `execute(name, params)` | ì‹¤í–‰ (ê²°ê³¼ í–‰ ë°˜í™˜) |

### ì‹¤í–‰ ê²°ê³¼ ëª¨ë¸

```python
# Dataset ì‹¤í–‰ ê²°ê³¼
class DatasetExecutionResult:
    dataset_name: str
    success: bool
    pre_results: list[ExecutionResult]
    main_result: ExecutionResult | None
    post_results: list[ExecutionResult]
    error_message: str | None

# Metric ì‹¤í–‰ ê²°ê³¼
class MetricExecutionResult:
    metric_name: str
    success: bool
    rows: list[dict[str, Any]]      # SELECT ê²°ê³¼
    row_count: int
    columns: list[str]
    error_message: str | None
    execution_time_ms: float | None
```

---

## í…ŒìŠ¤íŠ¸ Fixtures

### ìƒ˜í”Œ í”„ë¡œì íŠ¸ (`tests/fixtures/sample_project/`)

```
sample_project/
â”œâ”€â”€ dli.yaml                                              # í”„ë¡œì íŠ¸ ì„¤ì •
â”œâ”€â”€ metrics/
â”‚   â””â”€â”€ reporting/
â”‚       â”œâ”€â”€ metric.iceberg.reporting.user_summary.yaml    # Metric Spec
â”‚       â””â”€â”€ user_summary.sql                              # SQL íŒŒì¼
â”œâ”€â”€ datasets/
â”‚   â””â”€â”€ feed/
â”‚       â”œâ”€â”€ dataset.iceberg.analytics.daily_clicks.yaml   # Dataset Spec
â”‚       â””â”€â”€ daily_clicks.sql                              # SQL íŒŒì¼
```

### í…ŒìŠ¤íŠ¸ í˜„í™©

| íŒŒì¼ | í…ŒìŠ¤íŠ¸ ìˆ˜ | ì„¤ëª… |
|------|----------|------|
| `cli/test_main.py` | 32 | CLI ì»¤ë§¨ë“œ í…ŒìŠ¤íŠ¸ (version, validate, render, info) |
| `cli/test_list_cmd.py` | 28 | List ì»¤ë§¨ë“œ í…ŒìŠ¤íŠ¸ (í•„í„°, í¬ë§·, ì—ëŸ¬) |
| `test_models.py` | 69 | ë°ì´í„° ëª¨ë¸ + SpecType/MetricSpec/DatasetSpec + Name Validation |
| `test_discovery.py` | 30 | ProjectConfig + SpecDiscovery + DatasetDiscovery |
| `test_registry.py` | 30 | ë ˆì§€ìŠ¤íŠ¸ë¦¬ í…ŒìŠ¤íŠ¸ (DatasetSpec + MetricSpec) |
| `test_renderer.py` | 19 | SQL ë Œë”ë§ í…ŒìŠ¤íŠ¸ |
| `test_templates.py` | 71 | Safe í…œí”Œë¦¿ ì»¨í…ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸ |
| `test_validator.py` | 26 | SQL ê²€ì¦ í…ŒìŠ¤íŠ¸ |
| `test_executor.py` | 20 | ì‹¤í–‰ ì—”ì§„ í…ŒìŠ¤íŠ¸ |
| `test_service.py` | 31 | DatasetService í†µí•© í…ŒìŠ¤íŠ¸ |
| `test_metric_service.py` | 37 | MetricService í†µí•© í…ŒìŠ¤íŠ¸ (Airflow ì—°ë™) |
| **í•©ê³„** | **393** | core + CLI + library í…ŒìŠ¤íŠ¸ |

---

## Safe Templating (dbt/SQLMesh í˜¸í™˜)

ì„ì˜ì˜ Python ì½”ë“œ ì‹¤í–‰ì„ ë°©ì§€í•˜ëŠ” ì•ˆì „í•œ í…œí”Œë¦¿ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

### ì§€ì› ë³€ìˆ˜ (Phase 1)

| ë³€ìˆ˜ | ì„¤ëª… | ì˜ˆì‹œ |
|------|------|------|
| `ds` | ì‹¤í–‰ ë‚ ì§œ (YYYY-MM-DD) | `2025-01-15` |
| `ds_nodash` | ì‹¤í–‰ ë‚ ì§œ (YYYYMMDD) | `20250115` |
| `execution_date` | `ds` alias | `2025-01-15` |
| `yesterday_ds` | ì–´ì œ ë‚ ì§œ | `2025-01-14` |
| `tomorrow_ds` | ë‚´ì¼ ë‚ ì§œ | `2025-01-16` |

### ì§€ì› í•¨ìˆ˜ (Phase 1)

| í•¨ìˆ˜ | ì„¤ëª… | ì˜ˆì‹œ |
|------|------|------|
| `var(name, default)` | í”„ë¡œì íŠ¸ ë³€ìˆ˜ ì¡°íšŒ | `{{ var('env', 'dev') }}` |
| `date_add(date, days)` | ë‚ ì§œ ë”í•˜ê¸° | `{{ date_add(ds, 7) }}` |
| `date_sub(date, days)` | ë‚ ì§œ ë¹¼ê¸° | `{{ date_sub(ds, 7) }}` |
| `ref(dataset)` | ë°ì´í„°ì…‹ ì°¸ì¡° | `{{ ref('users') }}` |
| `env_var(name, default)` | í™˜ê²½ë³€ìˆ˜ ì¡°íšŒ | `{{ env_var('DB_HOST') }}` |

### ì‚¬ìš© ì˜ˆì‹œ

```sql
-- SQL í…œí”Œë¦¿
SELECT *
FROM {{ ref('raw_events') }}
WHERE dt BETWEEN '{{ date_sub(ds, 7) }}' AND '{{ ds }}'
  AND country = '{{ var("target_country", "KR") }}'
```

---

## Metric ì •ì˜ (dbt MetricFlow í˜¸í™˜)

SELECT íƒ€ì… ì¿¼ë¦¬ì— ëŒ€í•œ ë©”íŠ¸ë¦­ ì •ì˜ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.

### ì§€ì› ì§‘ê³„ íƒ€ì… (Phase 1)

| íƒ€ì… | SQL | ì„¤ëª… |
|------|-----|------|
| `count` | `COUNT(*)` | í–‰ ìˆ˜ |
| `count_distinct` | `COUNT(DISTINCT col)` | ê³ ìœ  ê°’ ìˆ˜ |
| `sum` | `SUM(col)` | í•©ê³„ |
| `avg` | `AVG(col)` | í‰ê·  |
| `min` | `MIN(col)` | ìµœì†Œê°’ |
| `max` | `MAX(col)` | ìµœëŒ€ê°’ |

### ì§€ì› Dimension íƒ€ì… (Phase 1)

| íƒ€ì… | ì„¤ëª… |
|------|------|
| `categorical` | ë²”ì£¼í˜• (country, status ë“±) |
| `time` | ì‹œê°„í˜• (dt, created_at ë“±) |

### Spec ì˜ˆì‹œ

```yaml
# spec.iceberg.reporting.user_summary.yaml
name: "iceberg.reporting.user_summary"
query_type: "SELECT"

metrics:
  - name: "user_count"
    aggregation: "count_distinct"
    expression: "user_id"
    description: "ì‚¬ìš©ì ìˆ˜"
  - name: "total_clicks"
    aggregation: "sum"
    expression: "click_count"
  - name: "avg_session"
    aggregation: "avg"
    expression: "session_duration_ms"
    filters:
      - "session_duration_ms > 0"

dimensions:
  - name: "country"
    type: "categorical"
    expression: "country_code"
  - name: "dt"
    type: "time"
    expression: "dt"
```

### Python ì‚¬ìš© ì˜ˆì‹œ

```python
from dli.core import MetricDefinition, AggregationType

metric = MetricDefinition(
    name="user_count",
    aggregation=AggregationType.COUNT_DISTINCT,
    expression="user_id",
)
print(metric.to_sql())  # COUNT(DISTINCT user_id)
```

---

## ì½”ë“œ í’ˆì§ˆ ê°œì„ ì‚¬í•­

expert-python Agent ë¦¬ë·° í›„ ì ìš©:

### 1. Type Alias ìˆ˜ì • (`models.py`)
- `Spec = SpecBase` â†’ `Spec = MetricSpec | DatasetSpec` (Union íƒ€ì…)
- Type Unionìœ¼ë¡œ ì‹¤ì œ êµ¬í˜„ íƒ€ì… ë°˜ì˜

### 2. Name Validation ê°•í™” (`models.py`)
- ì„ í–‰/í›„í–‰ ì (`.`) ê²€ì‚¬ ì¶”ê°€
- ì—°ì† ì (`..`) ê²€ì‚¬ ì¶”ê°€
- ê³µë°± ì „ìš© íŒŒíŠ¸ ê²€ì‚¬ ì¶”ê°€
- íŒŒíŠ¸ ì•/ë’¤ ê³µë°± ê²€ì‚¬ ì¶”ê°€

### 3. DRY ì›ì¹™ ì ìš© (`discovery.py`)
- `_load_yaml_file()`: ê³µí†µ YAML ë¡œë”©
- `_load_spec()`: í†µí•© spec ë¡œë”©
- `_detect_spec_type()`: íƒ€ì… ê°ì§€
- `_set_type_defaults()`: ê¸°ë³¸ê°’ ì„¤ì •
- `_discover_specs_in_dir()`: ë²”ìš© ë””ë ‰í† ë¦¬ íƒìƒ‰
- Magic string ì œê±° â†’ Enum ê°’ ì‚¬ìš©

### 4. ì¤‘ë³µ ì œê±° ë° íƒ€ì… ì•ˆì „ì„±
- `seen_paths: set[Path]`ë¡œ ì¤‘ë³µ ì²˜ë¦¬
- `typing.cast()` ì‚¬ìš©ìœ¼ë¡œ pyright íƒ€ì… ì²´í¬ í†µê³¼
- ë¶ˆí•„ìš”í•œ import ì •ë¦¬

### 5. Pydantic íŒ¨í„´ ê°œì„ 
- `PrivateAttr` ì‚¬ìš©ìœ¼ë¡œ private í•„ë“œ ì •ì˜ ê°œì„ 
- Public `base_dir`, `spec_path` í”„ë¡œí¼í‹° ì¶”ê°€
- `set_paths()` ë©”ì„œë“œë¡œ ê¹”ë”í•œ ì´ˆê¸°í™”

### 6. ì˜ˆì™¸ ì²˜ë¦¬ ê°œì„ 
- ê´‘ë²”ìœ„í•œ `Exception` ëŒ€ì‹  êµ¬ì²´ì  ì˜ˆì™¸ íƒ€ì… ì‚¬ìš©
- `(OSError, ValueError, yaml.YAMLError, ValidationError)` ë“±

### 7. Python íŒ¨í„´ ë§¤ì¹­ í™œìš©
```python
match parsed:
    case exp.Select():
        return "SELECT"
    case exp.Insert():
        return "INSERT"
```

---

## CLI ì»¤ë§¨ë“œ (Typer ê¸°ë°˜)

### ì§€ì› ì»¤ë§¨ë“œ

```bash
# ë²„ì „ ì •ë³´
dli version                    # ë²„ì „ ìƒì„¸ í‘œì‹œ
dli --version / -v             # ë²„ì „ í”Œë˜ê·¸

# SQL ê²€ì¦
dli validate <path>            # SQL íŒŒì¼ ê²€ì¦
dli validate query.sql --dialect trino --strict

# ìŠ¤í™ ëª©ë¡
dli list                       # ëª¨ë“  spec í‘œì‹œ
dli list --type metric         # Metricë§Œ í‘œì‹œ
dli list --format json         # JSON ì¶œë ¥

# í…œí”Œë¦¿ ë Œë”ë§
dli render template.sql --param key=value --date 2025-01-01 --output out.sql

# í™˜ê²½ ì •ë³´
dli info                       # í”Œë«í¼, ì˜ì¡´ì„± ì •ë³´
```

### CLI ì•„í‚¤í…ì²˜

```python
# src/dli/main.py - Typer ì•±
from typer import Typer, Option, Argument
from rich.console import Console

app = Typer(name="dli", help="DataOps Interface CLI")

@app.command()
def version(): ...

@app.command()
def validate(path: Path, dialect: str = "trino", strict: bool = False): ...

@app.command()
def render(path: Path, param: list[str], date: str, output: Path): ...

# src/dli/__main__.py - python -m dli ì§€ì›
from dli.main import app
app()
```

---

## Models íŒ¨í‚¤ì§€ êµ¬ì¡°

ê¸°ì¡´ `models.py` (750 lines)ë¥¼ ì—­í• ë³„ë¡œ ë¶„ë¦¬:

| íŒŒì¼ | ë¼ì¸ ìˆ˜ | ë‚´ìš© |
|------|--------|------|
| `models/__init__.py` | 81 | í•˜ìœ„ í˜¸í™˜ re-exports (`from dli.core.models import *` ì§€ì›) |
| `models/base.py` | 185 | `QueryType`, `SpecType`, `ParameterType`, `QueryParameter`, `StatementDefinition` |
| `models/spec.py` | 241 | `SpecBase` ì¶”ìƒ ê¸°ë°˜ í´ë˜ìŠ¤ |
| `models/metric.py` | 201 | `AggregationType`, `MetricDefinition`, `DimensionDefinition`, `MetricSpec` |
| `models/dataset.py` | 73 | `DatasetSpec` (DML ì „ìš©) |
| `models/results.py` | 86 | `ValidationResult`, `ExecutionResult`, `DatasetExecutionResult` |

### í•˜ìœ„ í˜¸í™˜ì„±

```python
# ê¸°ì¡´ import ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥
from dli.core.models import DatasetSpec, MetricSpec, SpecType
from dli.core import QueryType, ValidationResult
```

---

## í”„ë¡œì íŠ¸ êµ¬ì¡° í‰ê°€ (Senior Engineer Analysis)

### í˜„ì¬ ìƒíƒœ í‰ê°€

| ì§€í‘œ | ê°’ | í‰ê°€ |
|------|---|------|
| ì†ŒìŠ¤ ì½”ë“œ | 4,551 lines / 27 files | **ì ì •** |
| í…ŒìŠ¤íŠ¸ ì½”ë“œ | 3,500+ lines / 11 files | **ì–‘í˜¸** |
| í‰ê·  íŒŒì¼ í¬ê¸° | 169 lines | **ê±´ê°•í•¨** |
| ê°€ì¥ í° íŒŒì¼ | templates.py (505 lines) | **í—ˆìš© ë²”ìœ„** |
| í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ | 86% | **ì–‘í˜¸** |

### ì—…ê³„ ê¸°ì¤€ ë¹„êµ

| CLI ë„êµ¬ | Lines | Files | Avg Size |
|----------|-------|-------|----------|
| httpie | ~15,000 | 40+ | 375 |
| typer | ~8,000 | 30 | 267 |
| **dli (í˜„ì¬)** | **4,551** | **27** | **169** |

### íŒë‹¨: âœ… í˜„ì¬ êµ¬ì¡° ì ì ˆí•¨

**ì¶”ê°€ ë¦¬íŒ©í† ë§ ë¶ˆí•„ìš”** - ë‹¤ìŒ ì¡°ê±´ì„ ëª¨ë‘ ì¶©ì¡±:

1. **íŒŒì¼ í¬ê¸°ê°€ ê±´ê°•í•œ ë²”ìœ„** (ìµœëŒ€ 505 lines < 700 lines ê¸°ì¤€)
2. **ëª¨ë“ˆ ì‘ì§‘ë„ ë†’ìŒ** (ê´€ë ¨ í´ë˜ìŠ¤ê°€ í•¨ê»˜ ìœ„ì¹˜)
3. **ê´€ì‹¬ì‚¬ ë¶„ë¦¬ ì™„ë£Œ** (commands/, core/, adapters/)
4. **í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€** (models/__init__.py re-exports)

### ë³´ì•ˆ ê°œì„ ì‚¬í•­ (ì ìš© ì™„ë£Œ)

| ì´ìŠˆ | ì‹¬ê°ë„ | ìƒíƒœ |
|------|-------|------|
| SQL date filter injection | Critical | âœ… ìˆ˜ì •ë¨ |
| Type hints for dict returns | High | ğŸ”„ ê°œì„  ê¶Œì¥ |
| Error context in file loading | Medium | ğŸ”„ ê°œì„  ê¶Œì¥ |

---

## Day 1 ì²´í¬ë¦¬ìŠ¤íŠ¸

- [x] models.py â†’ **models/ íŒ¨í‚¤ì§€ ë¶„ë¦¬**
- [x] discovery.py (ProjectConfig, SpecDiscovery, DatasetDiscovery)
- [x] registry.py (DatasetRegistry)
- [x] renderer.py (SQLRenderer)
- [x] templates.py (TemplateContext, SafeJinjaEnvironment)
- [x] validator.py (SQLValidator)
- [x] executor.py (BaseExecutor, MockExecutor, DatasetExecutor)
- [x] service.py (DatasetService)
- [x] **metric_service.py (MetricService) - Airflow ì—°ë™ìš©**
- [x] **main.py (Typer CLI ì—”íŠ¸ë¦¬í¬ì¸íŠ¸)**
- [x] **__main__.py (python -m dli ì§€ì›)**
- [x] ìƒ˜í”Œ íŒŒì¼ (dli.yaml, dataset.yaml, metric.yaml, .sql)
- [x] Safe Templating (dbt/SQLMesh í˜¸í™˜ ë³€ìˆ˜ ë° í•¨ìˆ˜)
- [x] Metric ì •ì˜ (MetricDefinition, DimensionDefinition)
- [x] **Metric/Dataset ë¶„ë¦¬ (SpecType, MetricSpec, DatasetSpec)**
- [x] **metrics_dir ì„¤ì • ë° metric/dataset íŒŒì¼ íŒ¨í„´**
- [x] **metrics/ ë° datasets/ ìƒ˜í”Œ íŒŒì¼**
- [x] **CLI ì»¤ë§¨ë“œ í…ŒìŠ¤íŠ¸ (60 tests)**
- [x] **Library API í…ŒìŠ¤íŠ¸ (37 tests)**
- [x] **TypedDict íƒ€ì… íŒíŠ¸ ì¶”ê°€**
- [x] ì „ì²´ í…ŒìŠ¤íŠ¸ (393 tests passed)
- [x] ì½”ë“œ ë¦¬ë·° ë° ë¦¬íŒ©í† ë§

---

## í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
# ì „ì²´ í…ŒìŠ¤íŠ¸
cd project-interface-cli
uv run pytest tests/core/ -v

# ì»¤ë²„ë¦¬ì§€
uv run pytest tests/core/ --cov=dli.core --cov-report=term-missing

# íƒ€ì… ì²´í¬
uv run pyright src/dli/core/

# ë¦°íŒ…
uv run ruff check src/dli/core/
```

---

## ë‹¤ìŒ ë‹¨ê³„ (Day 2: CLI)

Day 2ì—ì„œëŠ” Typer ê¸°ë°˜ CLI ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤:

```bash
# í”„ë¡œì íŠ¸ ê´€ë¦¬
dli init [--home PATH]
dli config show

# ë°ì´í„°ì…‹ ê´€ë¦¬
dli dataset list [--catalog CATALOG] [--domain DOMAIN] [--tag TAG]
dli dataset show <dataset_name>
dli dataset validate <dataset_name> -p key=value

# ì‹¤í–‰
dli run <dataset_name> -p execution_date=2025-01-01 [--dry-run]
dli run <dataset_name> -p execution_date=2025-01-01 --phase pre
dli run <dataset_name> -p execution_date=2025-01-01 --skip-pre --skip-post
```

---

## ì°¸ê³  ìë£Œ

- [Open Semantic Interchange (OSI)](https://opensemanticinterchange.org/) - YAML í‘œì¤€
- [dbt MetricFlow](https://docs.getdbt.com/docs/build/about-metricflow) - Semantic Layer
- [dbt Jinja Functions](https://docs.getdbt.com/reference/dbt-jinja-functions) - í…œí”Œë¦¿ í•¨ìˆ˜
- [SQLMesh Macros](https://sqlmesh.readthedocs.io/en/stable/concepts/macros/sqlmesh_macros/) - ë§¤í¬ë¡œ ì‹œìŠ¤í…œ
- [SQLglot Documentation](https://sqlglot.com/sqlglot.html) - SQL íŒŒì‹±
