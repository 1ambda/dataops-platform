# FEATURE: SQL Transpile ê¸°ëŠ¥

> **Version:** 1.2.0
> **Status:** Refactored to Subcommands
> **Last Updated:** 2026-01-01

### Recent Updates (2026-01-01)

| Item | Status | Description |
|------|--------|-------------|
| **Refactoring to Subcommands** | âœ… Done | `dli dataset transpile` / `dli metric transpile` |
| **~~Top-level Command~~** | âš ï¸ **Removed** | `dli transpile` removed in v1.2.0 |
| **Jinja Integration** | âœ… Done | `TranspileEngine.transpile(sql, jinja_context=...)` ì§€ì› |
| **--transpile-retry CLI** | âœ… Done | `--transpile-retry [0-5]` ì˜µì…˜ ì¶”ê°€ |

---

## 1. ê°œìš”

### 1.1 ëª©ì 

`dli transpile` ë° `dli dataset run` ì»¤ë§¨ë“œëŠ” SQL ë³€í™˜(Transpile) ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ì‚¬ìš©ìì˜ SQLì„ Basecamp Serverì—ì„œ ì •ì˜ëœ ê·œì¹™ì— ë”°ë¼ ë³€í™˜í•˜ì—¬ ì‹¤í–‰í•˜ê±°ë‚˜, ë””ë²„ê¹… ëª©ì ìœ¼ë¡œ ë³€í™˜ëœ SQLì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### 1.2 í•µì‹¬ ì›ì¹™

| ì›ì¹™ | ì„¤ëª… |
|------|------|
| **ì„œë²„ ê·œì¹™ ê¸°ë°˜** | Transpile ê·œì¹™ì€ Basecamp Serverì—ì„œ ì¡°íšŒ, CLIëŠ” SQLGlotìœ¼ë¡œ ë³€í™˜ ìˆ˜í–‰ |
| **ì•”ì‹œì  ì ìš©** | `dataset run` ì‹¤í–‰ ì‹œ ìë™ìœ¼ë¡œ Transpile ì ìš© |
| **Graceful Degradation** | ê·œì¹™ ì¡°íšŒ ì‹¤íŒ¨ ì‹œ ì›ë³¸ SQL ì‹¤í–‰ + ê²½ê³  ì¶œë ¥ |
| **í™•ì¥ ê°€ëŠ¥ ì„¤ê³„** | Multi-dialect, Full Metric Expansion ë“± í–¥í›„ í™•ì¥ ê³ ë ¤ |

### 1.3 ì£¼ìš” ê¸°ëŠ¥

- **í…Œì´ë¸” ì¹˜í™˜ (Table Substitution)**: ì†ŒìŠ¤ í…Œì´ë¸”ì„ íƒ€ê²Ÿ í…Œì´ë¸”ë¡œ ì¹˜í™˜ (Explicit Mapping)
- **SQL ìµœì í™” ê°€ì´ë“œ**: CTE êµ¬ì¡°, LIMIT ë¯¸ì‚¬ìš© ë“± ê²½ê³  ì¶œë ¥ (Advisory Only)
- **Semantic Layer**: `METRIC(name)` í•¨ìˆ˜ë¥¼ ì‹¤ì œ SQL í‘œí˜„ì‹ìœ¼ë¡œ ì¹˜í™˜
- **ë¼ì´ë¸ŒëŸ¬ë¦¬ API**: `TranspileEngine` í´ë˜ìŠ¤ë¡œ í”„ë¡œê·¸ë˜ë§¤í‹± ì‚¬ìš© ì§€ì›

### 1.4 ìœ ì‚¬ ë„êµ¬ ì°¸ì¡°

| ë„êµ¬ | ì°¸ì¡° í¬ì¸íŠ¸ | ì¶œì²˜ |
|------|-------------|------|
| **[SQLGlot](https://github.com/tobymao/sqlglot)** | AST ê¸°ë°˜ SQL íŒŒì‹±, 31ê°œ ë‹¤ì´ì–¼ë ‰íŠ¸ ë³€í™˜ | Python ë¼ì´ë¸ŒëŸ¬ë¦¬ |
| **[SQLMesh](https://sqlmesh.com/)** | AST ë ˆë²¨ ì‹œë§¨í‹± ì´í•´, Column-level Lineage | Tobiko Data |
| **[dbt Semantic Layer](https://www.getdbt.com/blog/dbt-semantic-layer)** | ë©”íŠ¸ë¦­ ì •ì˜, YAML ê¸°ë°˜ ë©”íŠ¸ë¦­ ê´€ë¦¬ | dbt Labs |
| **[Cube.dev](https://cube.dev/)** | Headless Semantic Layer, LookML ëŒ€ì•ˆ | Open Source |

---

## 2. ì•„í‚¤í…ì²˜

### 2.1 ì»´í¬ë„ŒíŠ¸ ê´€ê³„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          CLI Flow                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ User SQL    â”‚â”€â”€â”€â–¶â”‚ Jinja Render     â”‚â”€â”€â”€â–¶â”‚ TranspileEngineâ”‚  â”‚
â”‚  â”‚ (Inline/    â”‚    â”‚ (Local)          â”‚    â”‚ (SQLGlot)     â”‚  â”‚
â”‚  â”‚  File)      â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚          â”‚
â”‚                                                     â–¼          â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚                              â”‚ Basecamp Server API          â”‚  â”‚
â”‚                              â”‚ - GET /transpile/rules       â”‚  â”‚
â”‚                              â”‚ - GET /metrics/{name}/sql    â”‚  â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          UI Flow                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ User SQL    â”‚â”€â”€â”€â–¶â”‚ Basecamp Server  â”‚â”€â”€â”€â–¶â”‚ Basecamp      â”‚  â”‚
â”‚  â”‚ (Web UI)    â”‚    â”‚ API              â”‚    â”‚ Parser        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ (SQLGlot)     â”‚  â”‚
â”‚                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  Note: CLIì™€ ParserëŠ” ì§ì ‘ í†µì‹ í•˜ì§€ ì•ŠìŒ                         â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 í•µì‹¬ ê²°ì • ì‚¬í•­

| í•­ëª© | ê²°ì • | ê·¼ê±° |
|------|------|------|
| Transpile ì‹¤í–‰ ìœ„ì¹˜ | CLI ë‚´ SQLGlot ì§ì ‘ ì‚¬ìš© | ë„¤íŠ¸ì›Œí¬ ì™•ë³µ ìµœì†Œí™”, ì˜¤í”„ë¼ì¸ ë¶€ë¶„ ì§€ì› |
| ê·œì¹™ ì €ì¥ì†Œ | Basecamp Server | ì¤‘ì•™ ì§‘ì¤‘ì‹ ê´€ë¦¬, ê·œì¹™ ë³€ê²½ ì‹œ CLI ì¬ë°°í¬ ë¶ˆí•„ìš” |
| ê·œì¹™ ìºì‹± | ì—†ìŒ (Always Fetch) | í•­ìƒ ìµœì‹  ê·œì¹™ ë³´ì¥, ë‹¨ìˆœí™” |
| CLI â†” Parser í†µì‹  | ë¶ˆê°€ | ì•„í‚¤í…ì²˜ ë¶„ë¦¬, UI ê²½ìœ  ì‹œì—ë§Œ Parser ì‚¬ìš© |
| ê°œë°œ ìˆœì„œ | Mock-first (CLI ì„  ê°œë°œ) | Server API ë¯¸ì™„ì„± ìƒíƒœì—ì„œ CLI ë…ë¦½ ê°œë°œ ê°€ëŠ¥ |
| ì„±ëŠ¥ ìµœì í™” | ê³ ë ¤í•˜ì§€ ì•ŠìŒ | BigQuery/Trino ì¿¼ë¦¬(ì´ˆ~ë¶„) ëŒ€ë¹„ Transpile ì§€ì—°(~3ì´ˆ)ì€ ë¬´ì‹œ ê°€ëŠ¥ |

### 2.3 ê¸°ì¡´ ì‹œìŠ¤í…œ í†µí•© ì§€ì 

| í†µí•© ì˜ì—­ | ê¸°ì¡´ íŒ¨í„´ | ìƒˆ ê¸°ëŠ¥ ì ìš© |
|-----------|-----------|-------------|
| **CLI ì»¤ë§¨ë“œ** | `commands/dataset.py`, `workflow.py` | `commands/transpile.py` ì‹ ê·œ + `dataset.py` í™•ì¥ |
| **ì¶œë ¥ ìœ í‹¸ë¦¬í‹°** | `commands/utils.py` (print_error, print_sql) | Rich íŒ¨í„´ ì¬ì‚¬ìš© |
| **ì˜µì…˜/Enum** | `base.py` (ListOutputFormat, SourceType) | `Dialect` enum ì¶”ê°€ |
| **API í´ë¼ì´ì–¸íŠ¸** | `core/client.py` (BasecampClient) | `transpile_get_rules()`, `transpile_get_metric_sql()` ë©”ì„œë“œ ì¶”ê°€ |
| **Core ëª¨ë“ˆ** | `core/workflow/`, `core/quality/` êµ¬ì¡° | `core/transpile/` ì‹ ê·œ ëª¨ë“ˆ |

### 2.4 ê°œë°œ ë¶ˆí™•ì‹¤ì„± ë° í•´ê²° ì „ëµ

| ë¶ˆí™•ì‹¤ì„± | ì‹¬ê°ë„ | í•´ê²° ì „ëµ |
|----------|--------|-----------|
| Server API ë¯¸êµ¬í˜„ | ğŸ”´ ë†’ìŒ | Mock ë°ì´í„°ë¡œ CLI ì„  ê°œë°œ â†’ ë‚˜ì¤‘ì— í†µí•© |
| SQLglot ë²„ì „ ë™ê¸°í™” | ğŸŸ¡ ì¤‘ê°„ | Parser(28.5)ì™€ ë™ì¼ ë²„ì „ ê¶Œì¥, í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸ í•„ìˆ˜ |
| METRIC() í•¨ìˆ˜ íŒŒì‹± | ğŸŸ¡ ì¤‘ê°„ | SQLglot ì»¤ìŠ¤í…€ í•¨ìˆ˜ vs ë¬¸ìì—´ ì¹˜í™˜ â†’ ë¬¸ìì—´ ì¹˜í™˜ ìš°ì„  (ë‹¨ìˆœì„±) |
| Jinja â†’ Transpile ìˆœì„œ | ğŸŸ¢ ë‚®ìŒ | í˜„ì¬ ìŠ¤í™ëŒ€ë¡œ Jinja ë¨¼ì € â†’ Transpile ì ìš© |
| ê·œì¹™ ì¶©ëŒ ì²˜ë¦¬ | ğŸŸ¢ ë‚®ìŒ | ì—ëŸ¬ ë°œìƒ (ì¶©ëŒ ë°©ì§€) - ê·œì¹™ ìƒì„± ì‹œ ê²€ì¦ |

---

## 3. Use Cases

### 3.1 Use-case 1: í…Œì´ë¸” ì¹˜í™˜ (Table Substitution)

ì‚¬ìš©ìì˜ SQL ë‚´ í…Œì´ë¸”ì„ ê·œì¹™ì— ë”°ë¼ ë‹¤ë¥¸ í…Œì´ë¸”ë¡œ ì¹˜í™˜í•©ë‹ˆë‹¤.

**ì˜ˆì‹œ:**
```sql
-- ì›ë³¸ SQL
SELECT * FROM analytics.users WHERE created_at > '2024-01-01'

-- ì¹˜í™˜ ê·œì¹™: analytics.users â†’ analytics.users_v2
-- ë³€í™˜ í›„
SELECT * FROM analytics.users_v2 WHERE created_at > '2024-01-01'
```

**ê·œì¹™ í˜•ì‹ (Explicit Mapping Table):**
```json
{
  "rules": [
    {
      "id": "rule-001",
      "type": "table_substitution",
      "source": "analytics.users",
      "target": "analytics.users_v2",
      "enabled": true,
      "description": "Users table migration to v2"
    }
  ]
}
```

### 3.2 Use-case 2: SQL ìµœì í™” ê°€ì´ë“œ (Advisory)

SQL íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ ê°œì„  ê¶Œê³ ì‚¬í•­ì„ ê²½ê³ ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤. **SQL ìì²´ëŠ” ë³€ê²½í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.**

| ê°ì§€ íŒ¨í„´ | ê²½ê³  ë©”ì‹œì§€ |
|-----------|-------------|
| `SELECT *` | `Warning: Consider specifying columns instead of SELECT *` |
| LIMIT ì—†ëŠ” ëŒ€ìš©ëŸ‰ ì¡°íšŒ | `Warning: No LIMIT clause detected. Consider adding LIMIT for safety.` |
| ì¤‘ë³µ CTE ì •ì˜ | `Warning: Duplicate CTE 'cte_name' detected. Consider refactoring.` |
| ë¹„íš¨ìœ¨ì  ì„œë¸Œì¿¼ë¦¬ | `Warning: Correlated subquery detected. Consider using JOIN.` |

### 3.3 Use-case 3: Semantic Layer (METRIC í•¨ìˆ˜)

`METRIC(name)` ê°€ìƒ í•¨ìˆ˜ì™€ `__semantic.__table` ê°€ìƒ í…Œì´ë¸”ì„ ì§€ì›í•©ë‹ˆë‹¤.

**ì˜ˆì‹œ:**
```sql
-- ì›ë³¸ SQL (ê°€ìƒ ë¬¸ë²•)
SELECT
  ds,
  METRIC(total_orders_from_active_customers)
FROM __semantic.__table
GROUP BY ds

-- ë³€í™˜ í›„ (Serverì—ì„œ metric SQL ì¡°íšŒ)
SELECT
  ds,
  SUM(CASE WHEN customer_status = 'active' THEN order_count ELSE 0 END) AS total_orders_from_active_customers
FROM analytics.orders
GROUP BY ds
```

**MVP ë²”ìœ„:**
- `METRIC(name)` â†’ Simple Substitution (Server-resolved SQL í‘œí˜„ì‹ìœ¼ë¡œ ì¹˜í™˜)
- í™•ì¥ ê°€ëŠ¥ ì„¤ê³„: dimensions, time_grains, filters ì§€ì› (Phase 2+)

### 3.4 METRIC() í•¨ìˆ˜ íŒŒì‹± ì•Œê³ ë¦¬ì¦˜

> **âš ï¸ P0 ì„¤ê³„ ê²°ì •: íŒŒì‹± ë°©ì‹ ì„ íƒ**
>
> | ë°©ì‹ | ì¥ì  | ë‹¨ì  | ê²°ì • |
> |------|------|------|------|
> | SQLGlot ì»¤ìŠ¤í…€ í•¨ìˆ˜ | AST ì •í™•ì„±, ìœ„ì¹˜ ì •ë³´ | ë³µì¡í•œ êµ¬í˜„, SQLGlot ë²„ì „ ì¢…ì† | âŒ |
> | ì •ê·œì‹ ë¬¸ìì—´ ì¹˜í™˜ | ë‹¨ìˆœí•¨, ë¹ ë¥¸ êµ¬í˜„ | Edge case ì·¨ì•½ | âœ… MVP |
>
> **MVPëŠ” ì •ê·œì‹ ë¬¸ìì—´ ì¹˜í™˜ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.** (Phase 2ì—ì„œ SQLGlot ì»¤ìŠ¤í…€ í•¨ìˆ˜ ê³ ë ¤)

#### 3.4.1 íŒŒì‹± ì•Œê³ ë¦¬ì¦˜ (MVP)

```python
import re
from typing import NamedTuple

class MetricMatch(NamedTuple):
    """METRIC() í•¨ìˆ˜ ë§¤ì¹˜ ê²°ê³¼"""
    full_match: str      # "METRIC(revenue)"
    metric_name: str     # "revenue"
    start_pos: int       # ì‹œì‘ ìœ„ì¹˜
    end_pos: int         # ë ìœ„ì¹˜

# ì •ê·œì‹ íŒ¨í„´: METRIC('name') ë˜ëŠ” METRIC("name") ë˜ëŠ” METRIC(name)
METRIC_PATTERN = re.compile(
    r"METRIC\s*\(\s*(?:'([^']+)'|\"([^\"]+)\"|([a-zA-Z_][a-zA-Z0-9_]*))\s*\)",
    re.IGNORECASE
)

def find_metric_functions(sql: str) -> list[MetricMatch]:
    """SQLì—ì„œ METRIC() í•¨ìˆ˜ë¥¼ ëª¨ë‘ ì°¾ì•„ ë°˜í™˜"""
    matches = []
    for match in METRIC_PATTERN.finditer(sql):
        # ì„¸ ê°€ì§€ ìº¡ì²˜ ê·¸ë£¹ ì¤‘ í•˜ë‚˜ì—ì„œ ì´ë¦„ ì¶”ì¶œ
        metric_name = match.group(1) or match.group(2) or match.group(3)
        matches.append(MetricMatch(
            full_match=match.group(0),
            metric_name=metric_name,
            start_pos=match.start(),
            end_pos=match.end(),
        ))
    return matches

def expand_metrics(sql: str, metric_resolver: Callable[[str], str | None]) -> tuple[str, list[str]]:
    """
    METRIC() í•¨ìˆ˜ë¥¼ ì‹¤ì œ SQL í‘œí˜„ì‹ìœ¼ë¡œ ì¹˜í™˜

    Returns:
        tuple[str, list[str]]: (ì¹˜í™˜ëœ SQL, ì—ëŸ¬ ëª©ë¡)
    """
    matches = find_metric_functions(sql)
    errors: list[str] = []

    # MVP ì œí•œ: SQLë‹¹ 1ê°œì˜ METRIC() í•¨ìˆ˜ë§Œ í—ˆìš©
    if len(matches) > 1:
        errors.append(f"MVP limitation: Only 1 METRIC() per SQL allowed, found {len(matches)}")
        return sql, errors

    if not matches:
        return sql, errors

    # ì—­ìˆœìœ¼ë¡œ ì¹˜í™˜ (ìœ„ì¹˜ ì¸ë±ìŠ¤ ë³´ì¡´)
    result = sql
    for match in reversed(matches):
        expression = metric_resolver(match.metric_name)
        if expression is None:
            errors.append(f"Metric '{match.metric_name}' not found")
            continue
        result = result[:match.start_pos] + expression + result[match.end_pos:]

    return result, errors
```

#### 3.4.2 Edge Case ì²˜ë¦¬

| Case | ì…ë ¥ | ì²˜ë¦¬ |
|------|------|------|
| ë¬¸ìì—´ ë‚´ METRIC | `"SELECT 'METRIC(x)' FROM t"` | ë¬´ì‹œ (ë¬¸ìì—´ ë¦¬í„°ëŸ´) - **MVP: ë¯¸ì§€ì›, Phase 2** |
| ì£¼ì„ ë‚´ METRIC | `"-- METRIC(x)\nSELECT 1"` | ë¬´ì‹œ (ì£¼ì„) - **MVP: ë¯¸ì§€ì›, Phase 2** |
| ì¤‘ì²© ê´„í˜¸ | `METRIC((revenue))` | ì—ëŸ¬ (ì˜ëª»ëœ ë¬¸ë²•) |
| ê³µë°± í¬í•¨ | `METRIC( revenue )` | ì •ìƒ ì²˜ë¦¬ |
| ëŒ€ì†Œë¬¸ì í˜¼ìš© | `Metric(Revenue)` | ì •ìƒ ì²˜ë¦¬ (case-insensitive ë§¤ì¹­, nameì€ ì›ë³¸ ìœ ì§€) |
| ë¯¸ì¡´ì¬ ë©”íŠ¸ë¦­ | `METRIC(unknown)` | **ì—ëŸ¬ ë°˜í™˜** (Silent ì•„ë‹˜) |
| ë³µìˆ˜ METRIC | `METRIC(a) + METRIC(b)` | **MVP: ì—ëŸ¬** (1ê°œë§Œ í—ˆìš©) |

#### 3.4.3 ì—ëŸ¬ ë©”ì‹œì§€ ì˜ˆì‹œ

```python
# ë¯¸ì¡´ì¬ ë©”íŠ¸ë¦­
TranspileError: Metric 'unknown_metric' not found.
  Available metrics: revenue, orders, users (use `dli metric list` to see all)

# MVP ì œí•œ ì´ˆê³¼
TranspileError: MVP limitation: Only 1 METRIC() function per SQL allowed.
  Found 2 METRIC() calls: METRIC(revenue), METRIC(orders)
  Hint: Split into separate queries or wait for Phase 2 support.
```

---

## 4. CLI ì„¤ê³„

### 4.1 ì»¤ë§¨ë“œ êµ¬ì¡°

#### 4.1.1 `dli dataset run` (ì•”ì‹œì  Transpile)

> **âš ï¸ ì„¤ê³„ ê²°ì •: ê¸°ì¡´ `dataset run` ì‹œê·¸ë‹ˆì²˜ì™€ì˜ í˜¸í™˜ì„±**
>
> ê¸°ì¡´ `run_dataset(name: str)` ë©”ì„œë“œëŠ” Dataset Spec ì´ë¦„ìœ¼ë¡œ ì‹¤í–‰í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.
> ìƒˆë¡œìš´ `--sql` ì˜µì…˜ì€ **ë³„ë„ì˜ ì‹¤í–‰ ê²½ë¡œ**ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤:
> - `dli dataset run <name>` â†’ ê¸°ì¡´: Spec ê¸°ë°˜ ì‹¤í–‰ (ë³€ê²½ ì—†ìŒ)
> - `dli dataset run --sql "..."` â†’ ì‹ ê·œ: Ad-hoc SQL ì‹¤í–‰ (Transpile ì ìš©)
>
> ë‘ ì˜µì…˜ì€ ìƒí˜¸ ë°°íƒ€ì ì´ë©°, ë™ì‹œ ì‚¬ìš© ì‹œ ì—ëŸ¬ ë°˜í™˜í•©ë‹ˆë‹¤.

```bash
# ê¸°ì¡´ ë°©ì‹ (Spec ê¸°ë°˜ - ë³€ê²½ ì—†ìŒ)
dli dataset run my_dataset_spec

# ì‹ ê·œ ë°©ì‹ (Ad-hoc SQL - Transpile ì ìš©)
dli dataset run --sql "SELECT * FROM analytics.users"

# íŒŒì¼ ê¸°ë°˜ ì‹¤í–‰
dli dataset run -f query.sql

# Transpile ê´€ë ¨ ì˜µì…˜ (--sql ë˜ëŠ” -f ì‚¬ìš© ì‹œì—ë§Œ ìœ íš¨)
dli dataset run --sql "..." --transpile-strict    # Strict ëª¨ë“œ (ë³€í™˜ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬)
dli dataset run --sql "..." --transpile-retry 3   # ì¬ì‹œë„ íšŸìˆ˜ (ê¸°ë³¸: 1)
dli dataset run --sql "..." --no-transpile        # Transpile ë¹„í™œì„±í™”
```

**êµ¬í˜„ ì‹œê·¸ë‹ˆì²˜:**
```python
@dataset_app.command("run")
def run_dataset(
    name: Annotated[str | None, typer.Argument(help="Dataset spec name")] = None,
    sql: Annotated[str | None, typer.Option("--sql", help="Ad-hoc SQL (mutually exclusive with name)")] = None,
    file: Annotated[Path | None, typer.Option("-f", "--file", help="SQL file path")] = None,
    transpile_strict: Annotated[bool, typer.Option("--transpile-strict")] = False,
    # ...
):
    # ìƒí˜¸ ë°°íƒ€ ê²€ì¦
    if name and (sql or file):
        raise typer.BadParameter("Cannot use both spec name and --sql/--file")
    if not name and not sql and not file:
        raise typer.BadParameter("Either spec name or --sql/--file required")
```

#### 4.1.2 `dli dataset transpile` (Spec-based Transpile)

```bash
# Transpile dataset SQL
dli dataset transpile iceberg.analytics.daily_clicks

# ì˜µì…˜
dli dataset transpile iceberg.analytics.daily_clicks --validate
dli dataset transpile iceberg.analytics.daily_clicks --strict
dli dataset transpile iceberg.analytics.daily_clicks --format json
dli dataset transpile iceberg.analytics.daily_clicks --show-rules
dli dataset transpile iceberg.analytics.daily_clicks --dialect trino
```

#### 4.1.3 `dli metric transpile` (Spec-based Transpile)

```bash
# Transpile metric SQL
dli metric transpile iceberg.analytics.daily_active_users

# ì˜µì…˜
dli metric transpile iceberg.analytics.daily_active_users --validate
dli metric transpile iceberg.analytics.daily_active_users --strict
dli metric transpile iceberg.analytics.daily_active_users --format json
```

#### 4.1.4 ~~`dli transpile`~~ (Deprecated in v1.2.0)

âš ï¸ **This command has been removed.** Use resource-specific subcommands instead:

| Old Usage | New Usage |
|-----------|-----------|
| `dli transpile "SELECT ..."` | Use `TranspileAPI` or `dataset run --sql` |
| `dli transpile -f query.sql` | Use `TranspileAPI` or `dataset run --sql` |

### 4.2 ê³µí†µ ì˜µì…˜

| ì˜µì…˜ | ë‹¨ì¶• | ì„¤ëª… | ê¸°ë³¸ê°’ |
|------|------|------|--------|
| `--transpile-strict` | | ë³€í™˜ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë°˜í™˜ | `false` |
| `--transpile-retry` | | API ì¬ì‹œë„ íšŸìˆ˜ | `1` |
| `--no-transpile` | | Transpile ë¹„í™œì„±í™” | `false` |
| `--dialect` | `-d` | ì…ë ¥ SQL ë‹¤ì´ì–¼ë ‰íŠ¸ | `trino` |

### 4.3 Transpile ì„œë¸Œì»¤ë§¨ë“œ ì „ìš© ì˜µì…˜

| ì˜µì…˜ | ì„¤ëª… |
|------|------|
| `--validate` | SQLGlot ë¬¸ë²• ê²€ì¦ ìˆ˜í–‰ |
| `--show-rules` | ì ìš©ëœ ê·œì¹™ ìƒì„¸ ì¶œë ¥ |
| `--format` | ì¶œë ¥ í˜•ì‹ (`table`/`json`) |

### 4.4 ì¶œë ¥ ì˜ˆì‹œ

#### ì„±ê³µ ì‹œ (Silent + Log)
```
$ dli dataset run --sql "SELECT * FROM analytics.users"
[INFO] Transpile applied: 1 table substitution, 2 warnings
[WARN] No LIMIT clause detected. Consider adding LIMIT for safety.
[WARN] Consider specifying columns instead of SELECT *

Executing query...
âœ“ Query completed in 2.3s (1,234 rows)
```

#### `dli dataset transpile` (Spec-based)
```
$ dli dataset transpile iceberg.analytics.daily_clicks --show-rules

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Transpile Result: iceberg.analytics.daily_clicks            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Original SQL:                                               â”‚
â”‚   SELECT * FROM analytics.users                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Transpiled SQL:                                             â”‚
â”‚   SELECT * FROM analytics.users_v2                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Applied Rules:                                              â”‚
â”‚   â€¢ [rule-001] Table Substitution: analytics.users â†’ users_v2â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Warnings:                                                   â”‚
â”‚   âš  No LIMIT clause detected                                â”‚
â”‚   âš  Consider specifying columns instead of SELECT *         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5. ë¼ì´ë¸ŒëŸ¬ë¦¬ API

### 5.1 TranspileEngine í´ë˜ìŠ¤

```python
from dli.core.transpile import TranspileEngine, TranspileConfig, TranspileResult

# ì„¤ì • ìƒì„±
config = TranspileConfig(
    dialect="trino",
    strict_mode=False,
    validate=True,
    retry_count=1,
)

# ì—”ì§„ ì´ˆê¸°í™”
engine = TranspileEngine(config)

# SQL ë³€í™˜
result: TranspileResult = engine.transpile(
    sql="SELECT * FROM analytics.users",
    context={"environment": "production"},  # ì„ íƒì  ì»¨í…ìŠ¤íŠ¸
)

# ê²°ê³¼ ì ‘ê·¼
print(result.sql)           # ë³€í™˜ëœ SQL
print(result.applied_rules) # ì ìš©ëœ ê·œì¹™ ëª©ë¡
print(result.warnings)      # ê²½ê³  ëª©ë¡
print(result.metadata)      # ë©”íƒ€ë°ì´í„° (audit trail)
print(result.to_json())     # JSON ì§ë ¬í™”
```

### 5.2 ë°ì´í„° ëª¨ë¸

```python
from pydantic import BaseModel, Field
from datetime import datetime
from enum import Enum

__all__ = [
    "TranspileConfig",
    "TranspileResult",
    "TranspileRule",
    "TranspileWarning",
    "RuleType",
    "WarningType",
    "Dialect",
]


class Dialect(str, Enum):
    """ì§€ì› SQL ë‹¤ì´ì–¼ë ‰íŠ¸"""
    TRINO = "trino"
    BIGQUERY = "bigquery"


class RuleType(str, Enum):
    """Transpile ê·œì¹™ íƒ€ì…"""
    TABLE_SUBSTITUTION = "table_substitution"
    METRIC_EXPANSION = "metric_expansion"


class WarningType(str, Enum):
    """ê²½ê³  íƒ€ì…"""
    NO_LIMIT = "no_limit"
    SELECT_STAR = "select_star"
    DUPLICATE_CTE = "duplicate_cte"
    CORRELATED_SUBQUERY = "correlated_subquery"


class TranspileConfig(BaseModel):
    """Transpile ì—”ì§„ ì„¤ì •"""
    dialect: Dialect = Field(default=Dialect.TRINO, description="ì…ë ¥ SQL ë‹¤ì´ì–¼ë ‰íŠ¸")
    strict_mode: bool = Field(default=False, description="Strict ëª¨ë“œ (ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸)")
    validate: bool = Field(default=False, description="ë¬¸ë²• ê²€ì¦ ìˆ˜í–‰")
    retry_count: int = Field(default=1, ge=0, le=5, description="API ì¬ì‹œë„ íšŸìˆ˜")
    server_url: str | None = Field(default=None, description="Basecamp Server URL (None=ìë™)")


class TranspileRule(BaseModel):
    """ì ìš©ëœ Transpile ê·œì¹™"""
    id: str = Field(..., description="ê·œì¹™ ID")
    type: RuleType = Field(..., description="ê·œì¹™ íƒ€ì…")
    source: str = Field(..., description="ì›ë³¸ (í…Œì´ë¸”ëª… ë˜ëŠ” í•¨ìˆ˜ëª…)")
    target: str = Field(..., description="ë³€í™˜ ê²°ê³¼")
    description: str | None = Field(default=None, description="ê·œì¹™ ì„¤ëª…")


class TranspileWarning(BaseModel):
    """Transpile ê²½ê³ """
    type: WarningType = Field(..., description="ê²½ê³  íƒ€ì…")
    message: str = Field(..., description="ê²½ê³  ë©”ì‹œì§€")
    line: int | None = Field(default=None, description="í•´ë‹¹ ë¼ì¸ ë²ˆí˜¸")
    column: int | None = Field(default=None, description="í•´ë‹¹ ì»¬ëŸ¼ ë²ˆí˜¸")


class TranspileMetadata(BaseModel):
    """Audit Trail ë©”íƒ€ë°ì´í„°"""
    original_sql: str = Field(..., description="ì›ë³¸ SQL")
    transpiled_at: datetime = Field(..., description="ë³€í™˜ ì‹œê°")
    dialect: Dialect = Field(..., description="ì‚¬ìš©ëœ ë‹¤ì´ì–¼ë ‰íŠ¸")
    rules_version: str | None = Field(default=None, description="ê·œì¹™ ë²„ì „ (Server ì œê³µ)")
    duration_ms: int = Field(..., description="ë³€í™˜ ì†Œìš” ì‹œê°„ (ms)")


class TranspileResult(BaseModel):
    """Transpile ê²°ê³¼"""
    success: bool = Field(..., description="ì„±ê³µ ì—¬ë¶€")
    sql: str = Field(..., description="ë³€í™˜ëœ SQL (ì‹¤íŒ¨ ì‹œ ì›ë³¸)")
    applied_rules: list[TranspileRule] = Field(default_factory=list, description="ì ìš©ëœ ê·œì¹™")
    warnings: list[TranspileWarning] = Field(default_factory=list, description="ê²½ê³  ëª©ë¡")
    metadata: TranspileMetadata = Field(..., description="ë©”íƒ€ë°ì´í„°")
    error: str | None = Field(default=None, description="ì—ëŸ¬ ë©”ì‹œì§€ (ì‹¤íŒ¨ ì‹œ)")

    def to_json(self) -> str:
        """JSON ì§ë ¬í™”"""
        return self.model_dump_json(indent=2)
```

---

## 6. Basecamp API

### 6.1 ì—”ë“œí¬ì¸íŠ¸

| ë™ì‘ | Method | Endpoint | ì„¤ëª… |
|------|--------|----------|------|
| ê·œì¹™ ì¡°íšŒ | GET | `/api/v1/transpile/rules` | ì „ì²´ Transpile ê·œì¹™ ëª©ë¡ |
| ë©”íŠ¸ë¦­ SQL ì¡°íšŒ | GET | `/api/v1/metrics/{name}/sql` | ë©”íŠ¸ë¦­ì˜ SQL í‘œí˜„ì‹ ì¡°íšŒ |

### 6.2 ìš”ì²­/ì‘ë‹µ ì˜ˆì‹œ

#### GET /api/v1/transpile/rules

**Request:**
```http
GET /api/v1/transpile/rules HTTP/1.1
Authorization: Bearer <token>
```

**Response:**
```json
{
  "rules": [
    {
      "id": "rule-001",
      "type": "table_substitution",
      "source": "analytics.users",
      "target": "analytics.users_v2",
      "enabled": true,
      "description": "Users table migration to v2",
      "created_at": "2025-01-01T00:00:00Z"
    }
  ],
  "version": "2025-01-01-001"
}
```

#### GET /api/v1/metrics/{name}/sql

**Request:**
```http
GET /api/v1/metrics/total_orders_from_active_customers/sql HTTP/1.1
Authorization: Bearer <token>
```

**Response:**
```json
{
  "name": "total_orders_from_active_customers",
  "sql_expression": "SUM(CASE WHEN customer_status = 'active' THEN order_count ELSE 0 END)",
  "source_table": "analytics.orders",
  "description": "Total orders from active customers"
}
```

### 6.3 í´ë¼ì´ì–¸íŠ¸ ë©”ì„œë“œ (BasecampClient í™•ì¥)

```python
# client.pyì— ì¶”ê°€
def transpile_get_rules(self) -> ServerResponse:
    """Transpile ê·œì¹™ ì¡°íšŒ"""
    if self.mock_mode:
        return ServerResponse(success=True, data=self._mock_data.get("transpile_rules", []))
    return self._get("/api/v1/transpile/rules")

def transpile_get_metric_sql(self, metric_name: str) -> ServerResponse:
    """ë©”íŠ¸ë¦­ SQL í‘œí˜„ì‹ ì¡°íšŒ"""
    if self.mock_mode:
        metrics = self._mock_data.get("metrics", {})
        if metric_name in metrics:
            return ServerResponse(success=True, data=metrics[metric_name])
        return ServerResponse(success=False, error=f"Metric '{metric_name}' not found", status_code=404)
    return self._get(f"/api/v1/metrics/{metric_name}/sql")
```

---

## 7. Jinja Template ì§€ì›

### 7.1 ì§€ì› ë²”ìœ„

`dli dataset run` ì‹¤í–‰ ì‹œ Jinja Templateì„ **ë¡œì»¬ CLIì—ì„œ ë Œë”ë§**í•©ë‹ˆë‹¤.

```sql
-- query.sql (Jinja Template)
SELECT
  {{ column_list | default('*') }}
FROM {{ ref('users') }}
WHERE created_at > '{{ start_date }}'
{% if limit %}
LIMIT {{ limit }}
{% endif %}
```

```bash
# ì‹¤í–‰
dli dataset run -f query.sql \
  --var column_list="id, name, email" \
  --var start_date="2024-01-01" \
  --var limit=100
```

### 7.2 ì§€ì› í•¨ìˆ˜

| í•¨ìˆ˜ | ì„¤ëª… | ì˜ˆì‹œ |
|------|------|------|
| `ref(name)` | í…Œì´ë¸” ì°¸ì¡° (dbt í˜¸í™˜) | `{{ ref('users') }}` |
| `var(name, default)` | ë³€ìˆ˜ ì°¸ì¡° | `{{ var('limit', 100) }}` |
| `env(name)` | í™˜ê²½ë³€ìˆ˜ ì°¸ì¡° | `{{ env('DB_NAME') }}` |

### 7.3 ë Œë”ë§ ìˆœì„œ

```
1. Jinja Template ë Œë”ë§ (CLI ë¡œì»¬)
2. Transpile ê·œì¹™ ì ìš© (SQLGlot)
3. SQL ì‹¤í–‰
```

---

## 8. ì—ëŸ¬ ì²˜ë¦¬

### 8.1 ì—ëŸ¬ ìœ í˜• ë° ì²˜ë¦¬

| ìƒí™© | ê¸°ë³¸ ë™ì‘ | Strict ëª¨ë“œ |
|------|-----------|-------------|
| Server ì—°ê²° ì‹¤íŒ¨ | ì›ë³¸ SQL ì‹¤í–‰ + ê²½ê³  | ì—ëŸ¬ ë°˜í™˜ |
| ê·œì¹™ ì¡°íšŒ ì‹¤íŒ¨ | ì›ë³¸ SQL ì‹¤í–‰ + ê²½ê³  | ì—ëŸ¬ ë°˜í™˜ |
| ë©”íŠ¸ë¦­ ì¡°íšŒ ì‹¤íŒ¨ | ì›ë³¸ SQL ì‹¤í–‰ + ê²½ê³  | ì—ëŸ¬ ë°˜í™˜ |
| SQL íŒŒì‹± ì‹¤íŒ¨ | ì›ë³¸ SQL ì‹¤í–‰ + ê²½ê³  | ì—ëŸ¬ ë°˜í™˜ |
| ë¬¸ë²• ê²€ì¦ ì‹¤íŒ¨ | ê²½ê³  ì¶œë ¥ (ì‹¤í–‰ ê³„ì†) | ì—ëŸ¬ ë°˜í™˜ |

### 8.2 ì˜ˆì™¸ ê³„ì¸µ êµ¬ì¡°

> **âš ï¸ P0 ìš”êµ¬ì‚¬í•­: ì™„ì „í•œ ì˜ˆì™¸ ê³„ì¸µ ì •ì˜**
>
> êµ¬í˜„ìê°€ ì˜ˆì™¸ ì²˜ë¦¬ë¥¼ ëª…í™•íˆ í•  ìˆ˜ ìˆë„ë¡ ëª¨ë“  ì˜ˆì™¸ íƒ€ì…ì„ ì •ì˜í•©ë‹ˆë‹¤.

```python
from typing import Any


class TranspileError(Exception):
    """Transpile ê´€ë ¨ ê¸°ë³¸ ì—ëŸ¬"""

    def __init__(self, message: str, details: dict[str, Any] | None = None):
        self.message = message
        self.details = details or {}
        super().__init__(message)


# === ë„¤íŠ¸ì›Œí¬ ê´€ë ¨ ì—ëŸ¬ ===

class NetworkError(TranspileError):
    """ë„¤íŠ¸ì›Œí¬ í†µì‹  ì—ëŸ¬ (ì—°ê²° ì‹¤íŒ¨, DNS ì˜¤ë¥˜ ë“±)"""

    def __init__(self, message: str = "Network connection failed", cause: Exception | None = None):
        super().__init__(message, {"cause": str(cause) if cause else None})
        self.cause = cause


class TimeoutError(TranspileError):
    """API ìš”ì²­ íƒ€ì„ì•„ì›ƒ"""

    def __init__(self, timeout_seconds: float, endpoint: str):
        super().__init__(
            f"Request to {endpoint} timed out after {timeout_seconds}s",
            {"timeout_seconds": timeout_seconds, "endpoint": endpoint}
        )
        self.timeout_seconds = timeout_seconds
        self.endpoint = endpoint


class RuleFetchError(TranspileError):
    """ê·œì¹™ ì¡°íšŒ ì‹¤íŒ¨ (ì„œë²„ ì‘ë‹µ ì—ëŸ¬)"""

    def __init__(self, status_code: int | None = None, detail: str | None = None):
        message = "Failed to fetch transpile rules from server"
        if status_code:
            message += f" (HTTP {status_code})"
        if detail:
            message += f": {detail}"
        super().__init__(message, {"status_code": status_code, "detail": detail})
        self.status_code = status_code


# === ê²€ì¦ ê´€ë ¨ ì—ëŸ¬ ===

class ValidationError(TranspileError):
    """ì…ë ¥ê°’ ê²€ì¦ ì‹¤íŒ¨"""

    def __init__(self, field: str, value: Any, reason: str):
        super().__init__(
            f"Validation failed for '{field}': {reason}",
            {"field": field, "value": value, "reason": reason}
        )
        self.field = field
        self.value = value
        self.reason = reason


class SqlParseError(TranspileError):
    """SQL íŒŒì‹± ì‹¤íŒ¨ (SQLGlot ì—ëŸ¬)"""

    def __init__(self, sql: str, detail: str, line: int | None = None, column: int | None = None):
        message = f"Failed to parse SQL: {detail}"
        if line:
            message += f" (line {line}"
            if column:
                message += f", column {column}"
            message += ")"
        super().__init__(message, {"sql": sql, "line": line, "column": column})
        self.sql = sql
        self.line = line
        self.column = column


class SqlValidationError(ValidationError):
    """SQL ë¬¸ë²• ê²€ì¦ ì‹¤íŒ¨ (--validate ì˜µì…˜)"""

    def __init__(self, sql: str, errors: list[str]):
        super().__init__(
            field="sql",
            value=sql[:100] + "..." if len(sql) > 100 else sql,
            reason=f"{len(errors)} validation error(s)"
        )
        self.errors = errors


# === ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì—ëŸ¬ ===

class MetricNotFoundError(TranspileError):
    """ë©”íŠ¸ë¦­ ì—†ìŒ"""

    def __init__(self, metric_name: str, available_metrics: list[str] | None = None):
        message = f"Metric '{metric_name}' not found"
        if available_metrics:
            message += f". Available: {', '.join(available_metrics[:5])}"
            if len(available_metrics) > 5:
                message += f" (+{len(available_metrics) - 5} more)"
        super().__init__(message, {"metric_name": metric_name, "available": available_metrics})
        self.metric_name = metric_name
        self.available_metrics = available_metrics


class MetricLimitExceededError(TranspileError):
    """METRIC() í•¨ìˆ˜ ê°œìˆ˜ ì œí•œ ì´ˆê³¼ (MVP: 1ê°œ)"""

    def __init__(self, found_count: int, max_allowed: int = 1):
        super().__init__(
            f"MVP limitation: Only {max_allowed} METRIC() per SQL allowed, found {found_count}",
            {"found_count": found_count, "max_allowed": max_allowed}
        )
        self.found_count = found_count
        self.max_allowed = max_allowed


class RuleConflictError(TranspileError):
    """ê·œì¹™ ì¶©ëŒ (ë™ì¼ ì†ŒìŠ¤ì— ë³µìˆ˜ ê·œì¹™)"""

    def __init__(self, source: str, conflicting_rules: list[str]):
        super().__init__(
            f"Conflicting rules for '{source}': {', '.join(conflicting_rules)}",
            {"source": source, "rules": conflicting_rules}
        )
        self.source = source
        self.conflicting_rules = conflicting_rules
```

**ì˜ˆì™¸ ì‚¬ìš© ê°€ì´ë“œ:**

| ìƒí™© | ì˜ˆì™¸ íƒ€ì… | Strict ëª¨ë“œ |
|------|-----------|-------------|
| ì„œë²„ ì—°ê²° ë¶ˆê°€ | `NetworkError` | ì¦‰ì‹œ raise |
| API ì‘ë‹µ ì§€ì—° | `TimeoutError` | ì¦‰ì‹œ raise |
| ì„œë²„ 4xx/5xx | `RuleFetchError` | ì¦‰ì‹œ raise |
| ì˜ëª»ëœ SQL êµ¬ë¬¸ | `SqlParseError` | ì¦‰ì‹œ raise |
| ë¬¸ë²• ê²€ì¦ ì‹¤íŒ¨ | `SqlValidationError` | ì¦‰ì‹œ raise |
| ì…ë ¥ íŒŒë¼ë¯¸í„° ì˜¤ë¥˜ | `ValidationError` | í•­ìƒ raise |
| ë©”íŠ¸ë¦­ ë¯¸ì¡´ì¬ | `MetricNotFoundError` | ì¦‰ì‹œ raise |
| METRIC() 2ê°œ+ | `MetricLimitExceededError` | í•­ìƒ raise |

### 8.3 Retry ë¡œì§

```python
def fetch_rules_with_retry(self, retry_count: int = 1) -> list[TranspileRule]:
    """ì¬ì‹œë„ ë¡œì§ì„ í¬í•¨í•œ ê·œì¹™ ì¡°íšŒ"""
    last_error = None
    for attempt in range(retry_count + 1):
        try:
            response = self.client.transpile_get_rules()
            if response.success:
                return [TranspileRule(**r) for r in response.data["rules"]]
            last_error = response.error
        except Exception as e:
            last_error = str(e)
            if attempt < retry_count:
                logger.warning(f"Retry {attempt + 1}/{retry_count}: {last_error}")
                time.sleep(0.5 * (attempt + 1))  # Exponential backoff

    logger.warning(f"Failed to fetch rules after {retry_count + 1} attempts: {last_error}")
    return []  # Graceful degradation
```

---

## 9. ë³´ì•ˆ

### 9.1 ê¸°ë³¸ ë°©ì–´ ì „ëµ

| í•­ëª© | êµ¬í˜„ | ë¹„ê³  |
|------|------|------|
| SQL Injection | SQLGlot AST íŒŒì‹± | ë¬¸ìì—´ ì¡°ì‘ ì•„ë‹Œ êµ¬ì¡°ì  ë³€í™˜ |
| ìœ„í—˜ ë¬¸ë²• ê°ì§€ | `DROP`, `TRUNCATE` ê²½ê³  | Advisory only (ì°¨ë‹¨ì€ ì„œë²„/DB ì±…ì„) |
| ê¶Œí•œ ê´€ë¦¬ | BigQuery/Trino ìœ„ì„ | CLIëŠ” ê¶Œí•œ ê²€ì¦ ë¯¸ìˆ˜í–‰ |

### 9.2 êµ¬í˜„ ê°€ì´ë“œ

```python
def detect_dangerous_patterns(self, parsed: exp.Expression) -> list[TranspileWarning]:
    """ìœ„í—˜ íŒ¨í„´ ê°ì§€ (Advisory)"""
    warnings = []
    dangerous_statements = (exp.Drop, exp.Truncate, exp.Delete)

    for stmt in parsed.find_all(*dangerous_statements):
        warnings.append(TranspileWarning(
            type=WarningType.DANGEROUS_STATEMENT,
            message=f"Detected {stmt.__class__.__name__} statement",
            line=stmt.meta.get("line"),
        ))

    return warnings
```

---

## 10. ë¡œê¹…

### 10.1 ë¡œê¹… êµ¬ì¡°

| ë ˆë²¨ | ì¶œë ¥ ìœ„ì¹˜ | ë‚´ìš© |
|------|-----------|------|
| INFO | Console | ë³€í™˜ ìš”ì•½ (ì ìš© ê·œì¹™ ìˆ˜, ê²½ê³  ìˆ˜) |
| WARNING | Console | ìµœì í™” ê¶Œê³ , ìœ„í—˜ íŒ¨í„´ ê°ì§€ |
| DEBUG | File | ìƒì„¸ ë³€í™˜ ë‚´ì—­, API ìš”ì²­/ì‘ë‹µ |
| ERROR | Console + File | ë³€í™˜ ì‹¤íŒ¨, API ì˜¤ë¥˜ |

### 10.2 ë¡œê·¸ íŒŒì¼

```
~/.dli/logs/transpile-YYYY-MM-DD.log
```

### 10.3 ë¡œê·¸ í¬ë§·

```json
{
  "timestamp": "2025-01-01T12:00:00.000Z",
  "level": "DEBUG",
  "event": "transpile_complete",
  "data": {
    "original_sql": "SELECT * FROM users",
    "transpiled_sql": "SELECT * FROM users_v2",
    "applied_rules": ["rule-001"],
    "warnings": ["no_limit"],
    "duration_ms": 45
  }
}
```

---

## 11. êµ¬í˜„ ì „ëµ (Mock-First Approach)

### 11.0 ê°œë°œ ìˆœì„œ

```
Phase 0: í™˜ê²½ ì¤€ë¹„ (ì„ í–‰ ì¡°ê±´)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”œâ”€ [ ] pyproject.tomlì— sqlglot ì˜ì¡´ì„± ì¶”ê°€
â”œâ”€ [ ] core/transpile/ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
â””â”€ [ ] Mock ê·œì¹™ ë°ì´í„° êµ¬ì¡° ì •ì˜

Phase 1: CLI Mock ëª¨ë“œ ê°œë°œ (Server ì˜ì¡´ ì—†ìŒ) â† í˜„ì¬ ë‹¨ê³„
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”œâ”€ TranspileEngine í•µì‹¬ ë¡œì§ êµ¬í˜„
â”œâ”€ Mock ê·œì¹™ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
â”œâ”€ CLI ì»¤ë§¨ë“œ (`dli transpile`) ì™„ì„±
â””â”€ ë‹¨ìœ„/í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ

Phase 2: Server API ê°œë°œ (ë³„ë„ ì§„í–‰)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”œâ”€ /api/v1/transpile/rules ì—”ë“œí¬ì¸íŠ¸
â”œâ”€ /api/v1/metrics/{name}/sql ì—”ë“œí¬ì¸íŠ¸
â””â”€ ê·œì¹™ ì €ì¥ì†Œ êµ¬í˜„

Phase 3: CLI â†” Server ì—°ë™
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”œâ”€ Mock Client â†’ Real Client êµì²´
â”œâ”€ í†µí•© í…ŒìŠ¤íŠ¸ ì¶”ê°€
â””â”€ Graceful Degradation ê²€ì¦
```

### 11.1 Mock ëª¨ë“œ ì„¤ê³„

> **âš ï¸ P0 ìš”êµ¬ì‚¬í•­: Protocol ì‹œê·¸ë‹ˆì²˜ì— ì—ëŸ¬ íƒ€ì… ëª…ì‹œ**
>
> êµ¬í˜„ìê°€ ì˜ˆì™¸ ì²˜ë¦¬ ë¡œì§ì„ ëª…í™•íˆ ì‘ì„±í•  ìˆ˜ ìˆë„ë¡ ë©”ì„œë“œë³„ ë°œìƒ ê°€ëŠ¥ ì˜ˆì™¸ë¥¼ ë¬¸ì„œí™”í•©ë‹ˆë‹¤.

```python
# core/transpile/client.py

from typing import Protocol
from pathlib import Path

from .models import TranspileRule, MetricDefinition
from .exceptions import (
    NetworkError,
    TimeoutError,
    RuleFetchError,
    MetricNotFoundError,
    ValidationError,
)


class TranspileRuleClient(Protocol):
    """
    ê·œì¹™ ì¡°íšŒ ì¸í„°í˜ì´ìŠ¤ (ì˜ì¡´ì„± ì—­ì „)

    êµ¬í˜„ì²´:
    - MockTranspileClient: í…ŒìŠ¤íŠ¸/ê°œë°œìš© (Phase 1)
    - BasecampTranspileClient: ìš´ì˜ìš© (Phase 3)
    """

    def get_rules(self, project_id: str) -> list[TranspileRule]:
        """
        í”„ë¡œì íŠ¸ì˜ Transpile ê·œì¹™ ëª©ë¡ ì¡°íšŒ

        Args:
            project_id: í”„ë¡œì íŠ¸ ì‹ë³„ì

        Returns:
            TranspileRule ëª©ë¡ (ë¹ˆ ë¦¬ìŠ¤íŠ¸ ê°€ëŠ¥)

        Raises:
            NetworkError: ì„œë²„ ì—°ê²° ì‹¤íŒ¨
            TimeoutError: ìš”ì²­ íƒ€ì„ì•„ì›ƒ (ê¸°ë³¸ 10ì´ˆ)
            RuleFetchError: ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜ (4xx/5xx)
            ValidationError: project_id í˜•ì‹ ì˜¤ë¥˜
        """
        ...

    def get_metric(self, name: str) -> MetricDefinition:
        """
        ë©”íŠ¸ë¦­ ì •ì˜ ì¡°íšŒ

        Args:
            name: ë©”íŠ¸ë¦­ ì´ë¦„ (case-sensitive)

        Returns:
            MetricDefinition (expression, source_table í¬í•¨)

        Raises:
            NetworkError: ì„œë²„ ì—°ê²° ì‹¤íŒ¨
            TimeoutError: ìš”ì²­ íƒ€ì„ì•„ì›ƒ (ê¸°ë³¸ 10ì´ˆ)
            MetricNotFoundError: ë©”íŠ¸ë¦­ ë¯¸ì¡´ì¬ (404)
            RuleFetchError: ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜ (4xx/5xx, 404 ì œì™¸)
            ValidationError: name í˜•ì‹ ì˜¤ë¥˜ (ë¹ˆ ë¬¸ìì—´, íŠ¹ìˆ˜ë¬¸ì ë“±)
        """
        ...


class MockTranspileClient:
    """
    Phase 1: ë¡œì»¬ íŒŒì¼ ê¸°ë°˜ Mock í´ë¼ì´ì–¸íŠ¸

    í…ŒìŠ¤íŠ¸ ë° Server ë¯¸êµ¬í˜„ ìƒíƒœì—ì„œ CLI ê°œë°œìš©.
    YAML/JSON íŒŒì¼ì—ì„œ ê·œì¹™ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    """

    def __init__(self, rules_file: Path | None = None):
        self._rules_file = rules_file or Path("tests/fixtures/transpile_rules.yaml")
        self._rules: dict[str, list[TranspileRule]] = {}
        self._metrics: dict[str, MetricDefinition] = {}
        self._load_mock_data()

    def _load_mock_data(self) -> None:
        """Mock ë°ì´í„° ë¡œë“œ (YAML/JSON ì§€ì›)"""
        if not self._rules_file.exists():
            return
        # êµ¬í˜„: yaml.safe_load() ë˜ëŠ” json.load()

    def get_rules(self, project_id: str) -> list[TranspileRule]:
        """Mock: ë¡œì»¬ íŒŒì¼ì—ì„œ ê·œì¹™ ë°˜í™˜ (ì˜ˆì™¸ ë°œìƒ ì—†ìŒ)"""
        if not project_id:
            raise ValidationError("project_id", project_id, "cannot be empty")
        return self._rules.get(project_id, [])

    def get_metric(self, name: str) -> MetricDefinition:
        """Mock: ë¡œì»¬ íŒŒì¼ì—ì„œ ë©”íŠ¸ë¦­ ë°˜í™˜"""
        if not name:
            raise ValidationError("name", name, "cannot be empty")
        if name not in self._metrics:
            raise MetricNotFoundError(name, list(self._metrics.keys()))
        return self._metrics[name]


class BasecampTranspileClient:
    """
    Phase 3: Basecamp Server ì—°ë™ í´ë¼ì´ì–¸íŠ¸

    ì‹¤ì œ Server APIì™€ í†µì‹ í•©ë‹ˆë‹¤.
    """

    DEFAULT_TIMEOUT = 10.0  # seconds

    def __init__(self, base_url: str, token: str, timeout: float = DEFAULT_TIMEOUT):
        self._base_url = base_url.rstrip("/")
        self._token = token
        self._timeout = timeout

    def get_rules(self, project_id: str) -> list[TranspileRule]:
        """Server APIì—ì„œ ê·œì¹™ ì¡°íšŒ"""
        if not project_id:
            raise ValidationError("project_id", project_id, "cannot be empty")

        try:
            response = httpx.get(
                f"{self._base_url}/api/v1/transpile/rules",
                params={"project_id": project_id},
                headers={"Authorization": f"Bearer {self._token}"},
                timeout=self._timeout,
            )
        except httpx.ConnectError as e:
            raise NetworkError("Failed to connect to Basecamp Server", cause=e)
        except httpx.TimeoutException:
            raise TimeoutError(self._timeout, "/api/v1/transpile/rules")

        if response.status_code != 200:
            raise RuleFetchError(response.status_code, response.text)

        return [TranspileRule(**r) for r in response.json()["rules"]]

    def get_metric(self, name: str) -> MetricDefinition:
        """Server APIì—ì„œ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        if not name:
            raise ValidationError("name", name, "cannot be empty")

        try:
            response = httpx.get(
                f"{self._base_url}/api/v1/metrics/{name}/sql",
                headers={"Authorization": f"Bearer {self._token}"},
                timeout=self._timeout,
            )
        except httpx.ConnectError as e:
            raise NetworkError("Failed to connect to Basecamp Server", cause=e)
        except httpx.TimeoutException:
            raise TimeoutError(self._timeout, f"/api/v1/metrics/{name}/sql")

        if response.status_code == 404:
            raise MetricNotFoundError(name)
        if response.status_code != 200:
            raise RuleFetchError(response.status_code, response.text)

        return MetricDefinition(**response.json())
```

### 11.2 Mock ë°ì´í„° êµ¬ì¡°

```yaml
# tests/fixtures/transpile_rules.yaml
project_default:
  rules:
    - id: "rule-001"
      type: table_substitution
      source: "raw.events"
      target: "warehouse.events_v2"
      enabled: true

  metrics:
    revenue:
      expression: "SUM(amount * quantity)"
      source_table: "analytics.orders"
      description: "Total revenue"
```

### 11.3 í™˜ê²½ë³„ Client ì„ íƒ

```python
def get_transpile_client() -> TranspileRuleClient:
    """í™˜ê²½ì— ë”°ë¼ ì ì ˆí•œ Client ë°˜í™˜"""
    if settings.TRANSPILE_MODE == "mock":
        return MockTranspileClient(rules_file=settings.MOCK_RULES_PATH)
    else:
        return BasecampTranspileClient(
            base_url=settings.BASECAMP_URL,
            token=settings.BASECAMP_TOKEN,
        )
```

---

## 12. êµ¬í˜„ ê°€ì´ë“œ

### 12.1 ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
src/dli/
â”œâ”€â”€ commands/
â”‚   â”œâ”€â”€ dataset.py         # dataset run ì»¤ë§¨ë“œ (Transpile í†µí•©)
â”‚   â””â”€â”€ transpile.py       # transpile ì»¤ë§¨ë“œ (NEW)
â””â”€â”€ core/
    â””â”€â”€ transpile/
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ engine.py      # TranspileEngine í´ë˜ìŠ¤
        â”œâ”€â”€ models.py      # Pydantic ëª¨ë¸
        â”œâ”€â”€ rules.py       # ê·œì¹™ ì ìš© ë¡œì§
        â”œâ”€â”€ metrics.py     # ë©”íŠ¸ë¦­ í™•ì¥ ë¡œì§
        â”œâ”€â”€ warnings.py    # ê²½ê³  ê°ì§€ ë¡œì§
        â””â”€â”€ jinja.py       # Jinja ë Œë”ë§ (ì„ íƒì )
```

### 11.2 ì°¸ì¡° íŒ¨í„´

| êµ¬í˜„ í•­ëª© | ì°¸ì¡° íŒŒì¼ |
|-----------|-----------|
| CLI ì»¤ë§¨ë“œ êµ¬ì¡° | `commands/dataset.py`, `commands/workflow.py` |
| Rich ì¶œë ¥ | `commands/utils.py` |
| API í´ë¼ì´ì–¸íŠ¸ ë©”ì„œë“œ | `core/client.py` |
| Pydantic ëª¨ë¸ | `core/workflow/models.py` |
| SQLGlot ì‚¬ìš© | `project-basecamp-parser/src/parser/sql_parser.py` |

### 11.3 í…ŒìŠ¤íŠ¸ ì°¸ì¡°

| í…ŒìŠ¤íŠ¸ í•­ëª© | ì°¸ì¡° íŒŒì¼ |
|-------------|-----------|
| CLI í…ŒìŠ¤íŠ¸ | `tests/cli/test_workflow_cmd.py` |
| ëª¨ë¸ í…ŒìŠ¤íŠ¸ | `tests/core/workflow/test_models.py` |
| SQLGlot í…ŒìŠ¤íŠ¸ | `project-basecamp-parser/tests/test_sql_parser.py` |

---

## 12. êµ¬í˜„ ìš°ì„ ìˆœìœ„

### Phase 1 (MVP)

- [ ] `TranspileEngine` í´ë˜ìŠ¤ êµ¬í˜„
- [ ] í…Œì´ë¸” ì¹˜í™˜ (Table Substitution) ê¸°ëŠ¥
- [ ] `METRIC()` í•¨ìˆ˜ Simple Substitution
- [ ] `dli transpile` ì»¤ë§¨ë“œ (Inline SQL + File)
- [ ] `dli dataset run` Transpile í†µí•©
- [ ] Server API í´ë¼ì´ì–¸íŠ¸ (`transpile_get_rules`, `transpile_get_metric_sql`)
- [ ] Graceful Degradation (ê·œì¹™ ì¡°íšŒ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì‹¤í–‰)
- [ ] ê¸°ë³¸ ê²½ê³  ì¶œë ¥ (SELECT *, LIMIT ë¯¸ì‚¬ìš©)
- [ ] Strict Mode ì˜µì…˜
- [ ] Mock ëª¨ë“œ ì§€ì›

### Phase 2

- [ ] Jinja Template ë Œë”ë§
- [ ] ì¶”ê°€ ê²½ê³  íŒ¨í„´ (ì¤‘ë³µ CTE, ìƒê´€ ì„œë¸Œì¿¼ë¦¬)
- [ ] `--validate` ì˜µì…˜ (ë¬¸ë²• ê²€ì¦)
- [ ] ìƒì„¸ ë¡œê¹… (File ë¡œê·¸)
- [ ] BigQuery ë‹¤ì´ì–¼ë ‰íŠ¸ ì§€ì›

### Phase 3+

- [ ] Full Metric Expansion (dimensions, time_grains, filters)
- [ ] Column-level Lineage
- [ ] Cost Estimation
- [ ] Multi-statement Support
- [ ] Custom Rule DSL

---

## 13. í…ŒìŠ¤íŠ¸ ì „ëµ

> **âš ï¸ P0 ìš”êµ¬ì‚¬í•­: í…ŒìŠ¤íŠ¸ ì „ëµ ëª…ì„¸**
>
> êµ¬í˜„ ì „ í…ŒìŠ¤íŠ¸ êµ¬ì¡°ì™€ ì»¤ë²„ë¦¬ì§€ ëª©í‘œë¥¼ ì •ì˜í•©ë‹ˆë‹¤.

### 13.1 í…ŒìŠ¤íŠ¸ êµ¬ì¡°

```
tests/
â”œâ”€â”€ cli/
â”‚   â”œâ”€â”€ test_transpile_cmd.py      # CLI ì»¤ë§¨ë“œ í†µí•© í…ŒìŠ¤íŠ¸
â”‚   â””â”€â”€ test_dataset_run_sql.py    # dataset run --sql ì˜µì…˜ í…ŒìŠ¤íŠ¸
â”œâ”€â”€ core/
â”‚   â””â”€â”€ transpile/
â”‚       â”œâ”€â”€ test_engine.py         # TranspileEngine ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
â”‚       â”œâ”€â”€ test_models.py         # Pydantic ëª¨ë¸ í…ŒìŠ¤íŠ¸
â”‚       â”œâ”€â”€ test_metrics.py        # METRIC() íŒŒì‹± í…ŒìŠ¤íŠ¸
â”‚       â”œâ”€â”€ test_rules.py          # ê·œì¹™ ì ìš© í…ŒìŠ¤íŠ¸
â”‚       â”œâ”€â”€ test_warnings.py       # ê²½ê³  ê°ì§€ í…ŒìŠ¤íŠ¸
â”‚       â”œâ”€â”€ test_exceptions.py     # ì˜ˆì™¸ í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸
â”‚       â””â”€â”€ test_client.py         # Protocol êµ¬í˜„ì²´ í…ŒìŠ¤íŠ¸
â””â”€â”€ fixtures/
    â””â”€â”€ transpile/
        â”œâ”€â”€ rules.yaml             # ê·œì¹™ Mock ë°ì´í„°
        â”œâ”€â”€ metrics.yaml           # ë©”íŠ¸ë¦­ Mock ë°ì´í„°
        â”œâ”€â”€ sql_samples/           # í…ŒìŠ¤íŠ¸ìš© SQL íŒŒì¼
        â”‚   â”œâ”€â”€ simple_select.sql
        â”‚   â”œâ”€â”€ with_metric.sql
        â”‚   â”œâ”€â”€ complex_cte.sql
        â”‚   â””â”€â”€ invalid_syntax.sql
        â””â”€â”€ expected/              # ì˜ˆìƒ ê²°ê³¼
            â”œâ”€â”€ simple_select_result.sql
            â””â”€â”€ with_metric_result.sql
```

### 13.2 í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ëª©í‘œ

| ëª¨ë“ˆ | ëª©í‘œ ì»¤ë²„ë¦¬ì§€ | ìš°ì„ ìˆœìœ„ |
|------|---------------|----------|
| `core/transpile/engine.py` | 90%+ | P0 |
| `core/transpile/metrics.py` | 95%+ | P0 |
| `core/transpile/rules.py` | 85%+ | P1 |
| `core/transpile/client.py` | 80%+ | P1 |
| `commands/transpile.py` | 75%+ | P2 |
| `core/transpile/warnings.py` | 70%+ | P2 |

**ì»¤ë²„ë¦¬ì§€ ì¸¡ì •:**
```bash
uv run pytest tests/core/transpile --cov=src/dli/core/transpile --cov-report=term-missing
```

### 13.3 í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ë¶„ë¥˜

#### 13.3.1 ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (Unit Tests)

**TranspileEngine:**
```python
class TestTranspileEngine:
    """TranspileEngine í•µì‹¬ ë¡œì§ í…ŒìŠ¤íŠ¸"""

    def test_transpile_simple_select(self, mock_client: MockTranspileClient):
        """ê¸°ë³¸ SELECT ë¬¸ ë³€í™˜"""
        engine = TranspileEngine(client=mock_client)
        result = engine.transpile("SELECT * FROM users")
        assert result.success is True
        assert "users_v2" in result.sql  # ê·œì¹™ì— ë”°ë¼ ì¹˜í™˜

    def test_transpile_with_metric(self, mock_client: MockTranspileClient):
        """METRIC() í•¨ìˆ˜ ì¹˜í™˜"""
        engine = TranspileEngine(client=mock_client)
        result = engine.transpile("SELECT METRIC(revenue) FROM __semantic.__table")
        assert result.success is True
        assert "METRIC" not in result.sql
        assert "SUM(" in result.sql  # ì‹¤ì œ í‘œí˜„ì‹ìœ¼ë¡œ ì¹˜í™˜

    def test_transpile_metric_not_found_strict(self, mock_client: MockTranspileClient):
        """Strict ëª¨ë“œì—ì„œ ë¯¸ì¡´ì¬ ë©”íŠ¸ë¦­ ì—ëŸ¬"""
        config = TranspileConfig(strict_mode=True)
        engine = TranspileEngine(client=mock_client, config=config)
        with pytest.raises(MetricNotFoundError) as exc_info:
            engine.transpile("SELECT METRIC(unknown) FROM t")
        assert "unknown" in str(exc_info.value)

    def test_transpile_metric_not_found_graceful(self, mock_client: MockTranspileClient):
        """Graceful ëª¨ë“œì—ì„œ ë¯¸ì¡´ì¬ ë©”íŠ¸ë¦­ ê²½ê³ """
        config = TranspileConfig(strict_mode=False)
        engine = TranspileEngine(client=mock_client, config=config)
        result = engine.transpile("SELECT METRIC(unknown) FROM t")
        assert result.success is True  # ì—ëŸ¬ ì—†ì´ ê³„ì†
        assert len(result.warnings) > 0

    def test_transpile_multiple_metrics_error(self, mock_client: MockTranspileClient):
        """MVP: ë³µìˆ˜ METRIC() ì—ëŸ¬"""
        engine = TranspileEngine(client=mock_client)
        with pytest.raises(MetricLimitExceededError):
            engine.transpile("SELECT METRIC(a), METRIC(b) FROM t")


class TestMetricParsing:
    """METRIC() í•¨ìˆ˜ íŒŒì‹± í…ŒìŠ¤íŠ¸"""

    @pytest.mark.parametrize("sql,expected_name", [
        ("METRIC(revenue)", "revenue"),
        ("METRIC('revenue')", "revenue"),
        ('METRIC("revenue")', "revenue"),
        ("METRIC( revenue )", "revenue"),
        ("metric(Revenue)", "Revenue"),  # case-insensitive match, preserve name
    ])
    def test_valid_metric_patterns(self, sql: str, expected_name: str):
        """ìœ íš¨í•œ METRIC íŒ¨í„´ íŒŒì‹±"""
        matches = find_metric_functions(sql)
        assert len(matches) == 1
        assert matches[0].metric_name == expected_name

    @pytest.mark.parametrize("sql", [
        "METRIC()",           # ë¹ˆ ì´ë¦„
        "METRIC((revenue))",  # ì¤‘ì²© ê´„í˜¸
        "METRIC(123abc)",     # ìˆ«ìë¡œ ì‹œì‘
    ])
    def test_invalid_metric_patterns(self, sql: str):
        """ë¬´íš¨í•œ METRIC íŒ¨í„´ ë¬´ì‹œ"""
        matches = find_metric_functions(sql)
        assert len(matches) == 0
```

#### 13.3.2 í†µí•© í…ŒìŠ¤íŠ¸ (Integration Tests)

**CLI í†µí•© í…ŒìŠ¤íŠ¸:**
```python
class TestTranspileCommand:
    """dli transpile ì»¤ë§¨ë“œ í†µí•© í…ŒìŠ¤íŠ¸"""

    def test_transpile_inline_sql(self, cli_runner: CliRunner):
        """ì¸ë¼ì¸ SQL ë³€í™˜"""
        result = cli_runner.invoke(app, ["transpile", "SELECT * FROM users"])
        assert result.exit_code == 0
        assert "Transpiled SQL" in result.output

    def test_transpile_file(self, cli_runner: CliRunner, tmp_path: Path):
        """íŒŒì¼ ê¸°ë°˜ SQL ë³€í™˜"""
        sql_file = tmp_path / "query.sql"
        sql_file.write_text("SELECT * FROM users")
        result = cli_runner.invoke(app, ["transpile", "-f", str(sql_file)])
        assert result.exit_code == 0

    def test_transpile_strict_mode_error(self, cli_runner: CliRunner):
        """Strict ëª¨ë“œ ì—ëŸ¬ ì¶œë ¥"""
        result = cli_runner.invoke(
            app, ["transpile", "SELECT METRIC(unknown) FROM t", "--strict"]
        )
        assert result.exit_code != 0
        assert "MetricNotFoundError" in result.output or "not found" in result.output

    def test_transpile_json_output(self, cli_runner: CliRunner):
        """JSON í˜•ì‹ ì¶œë ¥"""
        result = cli_runner.invoke(
            app, ["transpile", "SELECT * FROM users", "--format", "json"]
        )
        assert result.exit_code == 0
        data = json.loads(result.output)
        assert "sql" in data
        assert "applied_rules" in data


class TestDatasetRunSql:
    """dli dataset run --sql ì˜µì…˜ í…ŒìŠ¤íŠ¸"""

    def test_run_sql_basic(self, cli_runner: CliRunner):
        """ê¸°ë³¸ SQL ì‹¤í–‰ (Transpile ì ìš©)"""
        result = cli_runner.invoke(
            app, ["dataset", "run", "--sql", "SELECT 1"]
        )
        assert result.exit_code == 0

    def test_run_sql_mutual_exclusion(self, cli_runner: CliRunner):
        """nameê³¼ --sql ë™ì‹œ ì‚¬ìš© ì—ëŸ¬"""
        result = cli_runner.invoke(
            app, ["dataset", "run", "my_spec", "--sql", "SELECT 1"]
        )
        assert result.exit_code != 0
        assert "mutually exclusive" in result.output.lower() or "Cannot use both" in result.output

    def test_run_sql_no_transpile(self, cli_runner: CliRunner):
        """--no-transpile ì˜µì…˜"""
        result = cli_runner.invoke(
            app, ["dataset", "run", "--sql", "SELECT * FROM users", "--no-transpile"]
        )
        assert result.exit_code == 0
        assert "Transpile" not in result.output  # Transpile ë¹„í™œì„±í™” í™•ì¸
```

#### 13.3.3 ì˜ˆì™¸ í…ŒìŠ¤íŠ¸ (Exception Tests)

```python
class TestExceptions:
    """ì˜ˆì™¸ í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸"""

    def test_network_error_with_cause(self):
        """NetworkError ì›ì¸ ì˜ˆì™¸ í¬í•¨"""
        cause = ConnectionError("Connection refused")
        error = NetworkError("Failed to connect", cause=cause)
        assert error.cause is cause
        assert "Connection refused" in error.details["cause"]

    def test_timeout_error_details(self):
        """TimeoutError ìƒì„¸ ì •ë³´"""
        error = TimeoutError(10.0, "/api/v1/transpile/rules")
        assert error.timeout_seconds == 10.0
        assert "/api/v1/transpile/rules" in str(error)

    def test_metric_not_found_suggestions(self):
        """MetricNotFoundError ê°€ìš© ë©”íŠ¸ë¦­ ì œì•ˆ"""
        error = MetricNotFoundError("revenu", ["revenue", "orders", "users"])
        assert "revenu" in str(error)
        assert "revenue" in str(error)  # ì œì•ˆ í¬í•¨

    def test_validation_error_fields(self):
        """ValidationError í•„ë“œ ì •ë³´"""
        error = ValidationError("project_id", "", "cannot be empty")
        assert error.field == "project_id"
        assert error.reason == "cannot be empty"
```

### 13.4 Mock ì „ëµ

```python
# conftest.py

import pytest
from pathlib import Path
from dli.core.transpile.client import MockTranspileClient

@pytest.fixture
def mock_client() -> MockTranspileClient:
    """ê¸°ë³¸ Mock í´ë¼ì´ì–¸íŠ¸ (fixtures ë°ì´í„° ì‚¬ìš©)"""
    return MockTranspileClient(
        rules_file=Path(__file__).parent / "fixtures/transpile/rules.yaml"
    )

@pytest.fixture
def mock_client_empty() -> MockTranspileClient:
    """ë¹ˆ ê·œì¹™ Mock í´ë¼ì´ì–¸íŠ¸"""
    return MockTranspileClient(rules_file=None)

@pytest.fixture
def cli_runner() -> CliRunner:
    """Typer CLI í…ŒìŠ¤íŠ¸ ëŸ¬ë„ˆ"""
    return CliRunner()
```

### 13.5 í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ê°€ì´ë“œ

```bash
# ì „ì²´ Transpile í…ŒìŠ¤íŠ¸
uv run pytest tests/core/transpile -v

# íŠ¹ì • í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤
uv run pytest tests/core/transpile/test_engine.py::TestTranspileEngine -v

# ì»¤ë²„ë¦¬ì§€ í¬í•¨
uv run pytest tests/core/transpile --cov=src/dli/core/transpile --cov-report=html

# CLI í†µí•© í…ŒìŠ¤íŠ¸ë§Œ
uv run pytest tests/cli/test_transpile_cmd.py -v

# ë¹ ë¥¸ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (Mock only)
uv run pytest tests/core/transpile -m "not integration" -v
```

### 13.6 CI íŒŒì´í”„ë¼ì¸ í†µí•©

```yaml
# .github/workflows/test.yml (ì¶”ê°€)
jobs:
  test-transpile:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
      - name: Install uv
        run: pip install uv
      - name: Install dependencies
        run: cd project-interface-cli && uv sync
      - name: Run Transpile tests
        run: |
          cd project-interface-cli
          uv run pytest tests/core/transpile --cov=src/dli/core/transpile --cov-fail-under=80
      - name: Upload coverage
        uses: codecov/codecov-action@v4
        with:
          files: project-interface-cli/coverage.xml
```

---

## Appendix: ì»¤ë§¨ë“œ ìš”ì•½

```bash
# dli dataset run (ì•”ì‹œì  Transpile)
dli dataset run --sql "SELECT ..."          # ê¸°ë³¸ (Transpile ìë™)
dli dataset run -f query.sql                # íŒŒì¼ ê¸°ë°˜
dli dataset run --sql "..." --transpile-strict
dli dataset run --sql "..." --transpile-retry 3
dli dataset run --sql "..." --no-transpile

# dli transpile (ë””ë²„ê¹…ìš©)
dli transpile "SELECT ..."                  # Inline SQL
dli transpile -f query.sql                  # íŒŒì¼ ê¸°ë°˜
dli transpile "..." --validate              # ë¬¸ë²• ê²€ì¦
dli transpile "..." --strict                # Strict ëª¨ë“œ
dli transpile "..." --format json           # JSON ì¶œë ¥
dli transpile "..." --show-rules            # ê·œì¹™ ìƒì„¸
dli transpile "..." --dialect bigquery      # ë‹¤ì´ì–¼ë ‰íŠ¸ ì§€ì •
```

---

## Appendix: ê²°ì • ì‚¬í•­ (ì¸í„°ë·° ê¸°ë°˜)

### A.1 ì•„í‚¤í…ì²˜ ê²°ì •

| í•­ëª© | ê²°ì • | Trade-off ë¶„ì„ | ìµœì¢… ê·¼ê±° |
|------|------|----------------|-----------|
| Transpile ì‹¤í–‰ ìœ„ì¹˜ | CLI ë‚´ SQLGlot | ë„¤íŠ¸ì›Œí¬ í˜¸ì¶œ vs ì˜¤í”„ë¼ì¸ ì§€ì› | ë„¤íŠ¸ì›Œí¬ ìµœì†Œí™”, CLI ë…ë¦½ì„± |
| ê·œì¹™ ì €ì¥ì†Œ | Basecamp Server | ì¤‘ì•™ì§‘ì¤‘ vs ë¶„ì‚° | ì¤‘ì•™ ì§‘ì¤‘ ê´€ë¦¬, ê·œì¹™ ì¼ê´€ì„± |
| ìºì‹± | ì—†ìŒ (Always Fetch) | ì„±ëŠ¥ vs ë‹¨ìˆœì„± | ë‹¨ìˆœì„± ìš°ì„ , BigQuery/Trino ëŒ€ë¹„ ë¬´ì‹œ ê°€ëŠ¥ |
| ê°œë°œ ìˆœì„œ | Mock-first | ì§ë ¬ vs ë³‘ë ¬ ê°œë°œ | Server ì—†ì´ CLI ë…ë¦½ ê°œë°œ ê°€ëŠ¥ |
| ì„±ëŠ¥ ìµœì í™” | ê³ ë ¤í•˜ì§€ ì•ŠìŒ | ìµœì í™” vs ë¹ ë¥¸ ê°œë°œ | ì¿¼ë¦¬ ì‹¤í–‰(ì´ˆ~ë¶„) ëŒ€ë¹„ Transpile(~3ì´ˆ) ë¬´ì‹œ |

### A.2 ê¸°ëŠ¥ ì •ì±… ê²°ì •

| í•­ëª© | ê²°ì • | Trade-off ë¶„ì„ | ìµœì¢… ê·¼ê±° |
|------|------|----------------|-----------|
| í…Œì´ë¸” ì¹˜í™˜ ë°©ì‹ | Explicit Mapping | ìë™ê°ì§€ vs ëª…ì‹œì  ë§¤í•‘ | ëª…í™•ì„±, ì˜ˆì¸¡ ê°€ëŠ¥ì„± |
| Metric í•´ì„ | Server-resolved | CLI ë‚´ì¥ vs Server ìœ„ì„ | CLI metric ë¡œì§ ë¯¸ë³´ìœ , ì¤‘ì•™ ê´€ë¦¬ |
| Fallback | Graceful (ê¸°ë³¸) | Silent vs Fail-fast | UX ìš°ì„ , Strict ì˜µì…˜ìœ¼ë¡œ ì„ íƒ ê°€ëŠ¥ |
| SQL ìµœì í™” | Advisory Only | ìë™ìˆ˜ì • vs ê²½ê³ ë§Œ | SQL ë³€ê²½ ì—†ì´ ê²½ê³ ë§Œ, ì•ˆì „ì„± |
| METRIC ê°œìˆ˜ | SQLë‹¹ 1ê°œ (MVP) | ë‹¨ì¼ vs ë³µìˆ˜ ì§€ì› | MVP ë‹¨ìˆœí™”, ì¶”í›„ í™•ì¥ ê°€ëŠ¥ |
| ë¯¸ì¡´ì¬ ë©”íŠ¸ë¦­ | ì—ëŸ¬ ë°œìƒ | Silent vs ëª…ì‹œì  ì˜¤ë¥˜ | ë””ë²„ê¹… ìš©ì´ì„± |

### A.3 ê¸°ìˆ  ìŠ¤íƒ ê²°ì •

| í•­ëª© | ê²°ì • | ê·¼ê±° |
|------|------|------|
| Jinja | CLI ë¡œì»¬ ë Œë”ë§ | dataset run ì‹œ í…œí”Œë¦¿ ì§€ì› |
| ê²€ì¦ | transpile: ì˜µì…˜, run: ìë™ | ë””ë²„ê¹… vs ì‹¤í–‰ êµ¬ë¶„ |
| ë¡œê¹… | Console ìš”ì•½ + File ìƒì„¸ | UX + ì¬í˜„ì„± |
| ë³´ì•ˆ | ë¹„ìš© íš¨ìœ¨ì  ë°©ì–´ | DB/ì„œë²„ ê¶Œí•œ ìœ„ì„ |
| ë‹¤ì´ì–¼ë ‰íŠ¸ | Trino (MVP), BigQuery (Phase 2) | í˜„ì¬ Adapter ê¸°ì¤€ |
| ë¼ì´ë¸ŒëŸ¬ë¦¬ API | TranspileEngine í´ë˜ìŠ¤ | í™•ì¥ì„±, ì„¤ì • ì¬ì‚¬ìš© |
| ê²°ê³¼ íƒ€ì… | TranspileResult + JSON | êµ¬ì¡°í™” + ì§ë ¬í™” |
| SQLglot ë²„ì „ | Parserì™€ ë™ì¼ (28.5 ê¶Œì¥) | í˜¸í™˜ì„± ë³´ì¥ |

---

## Appendix: ì™¸ë¶€ ì°¸ì¡°

### SQLGlot
- [GitHub Repository](https://github.com/tobymao/sqlglot)
- [API Documentation](https://sqlglot.com/sqlglot.html)
- [SQL Transpilation Guide](https://deepwiki.com/tobymao/sqlglot/5-sql-transpilation)

### Semantic Layer
- [dbt Semantic Layer](https://www.getdbt.com/blog/dbt-semantic-layer)
- [Cube.dev Documentation](https://cube.dev/docs)
- [SQLMesh Overview](https://tobikodata.com/sqlmesh_for_dbt_1.html)

### Metric Store
- [MetricFlow (dbt)](https://docs.getdbt.com/docs/build/build-metrics-intro)
- [Sidemantic (Universal Metrics Layer)](https://github.com/sidequery/sidemantic)

---

## Appendix: Implementation Agent Review

### ë„ë©”ì¸ êµ¬í˜„ì ë¦¬ë·° (feature-interface-cli)

**ë¦¬ë·°ì–´**: `feature-interface-cli` Agent
**ë¦¬ë·° ì¼ì**: 2025-12-30
**í•µì‹¬ ê´€ì **: "ì‹ ê·œ ê¸°ëŠ¥ì„ ì–´ë–»ê²Œ ë¹ ë¥´ê²Œ ì¶”ê°€í•˜ëŠ”ê°€?"

| Priority | Issue | Resolution |
|----------|-------|------------|
| P0 | `dataset run --sql` ì˜µì…˜ì´ ê¸°ì¡´ `run_dataset(name)` ì‹œê·¸ë‹ˆì²˜ì™€ ì¶©ëŒ | âœ… Section 4.1.1ì— ìƒí˜¸ ë°°íƒ€ì  ì˜µì…˜ ì„¤ê³„ ë° êµ¬í˜„ ì‹œê·¸ë‹ˆì²˜ ì¶”ê°€ |
| P0 | METRIC() í•¨ìˆ˜ íŒŒì‹± ì•Œê³ ë¦¬ì¦˜ ë¯¸ëª…ì‹œ ("ë¬¸ìì—´ ì¹˜í™˜ ì„ í˜¸"ë§Œ ì–¸ê¸‰) | âœ… Section 3.4 ì‹ ê·œ ì¶”ê°€: ì •ê·œì‹ íŒ¨í„´, ì•Œê³ ë¦¬ì¦˜ ì½”ë“œ, Edge case í…Œì´ë¸” |
| P0 | í…ŒìŠ¤íŠ¸ ì „ëµ ì„¹ì…˜ ì™„ì „ ëˆ„ë½ | âœ… Section 13 ì‹ ê·œ ì¶”ê°€: í…ŒìŠ¤íŠ¸ êµ¬ì¡°, ì»¤ë²„ë¦¬ì§€ ëª©í‘œ, ë‹¨ìœ„/í†µí•©/ì˜ˆì™¸ í…ŒìŠ¤íŠ¸ ì½”ë“œ ì˜ˆì‹œ, CI ì„¤ì • |
| P1 | Mock ë°ì´í„° íŒŒì¼ ê²½ë¡œ í•˜ë“œì½”ë”© | Section 11.2ì— fixtures ê²½ë¡œ íŒ¨í„´ ëª…ì‹œ |
| P2 | CLI ì¶œë ¥ í˜•ì‹ ìƒì„¸ ë¯¸ì •ì˜ | Section 4.4ì— Rich ì¶œë ¥ ì˜ˆì‹œ í¬í•¨ |

### ê¸°ìˆ  ì‹œë‹ˆì–´ ë¦¬ë·° (expert-python)

**ë¦¬ë·°ì–´**: `expert-python` Agent
**ë¦¬ë·° ì¼ì**: 2025-12-30
**í•µì‹¬ ê´€ì **: "ë‚´ë¶€ êµ¬ì¡° ê°œì„ ê³¼ ì‹œìŠ¤í…œ í™•ì¥ ê°€ëŠ¥ì„±"

| Priority | Issue | Resolution |
|----------|-------|------------|
| P0 | ì˜ˆì™¸ ê³„ì¸µ ë¶ˆì™„ì „ (NetworkError, ValidationError, TimeoutError ëˆ„ë½) | âœ… Section 8.2 í™•ì¥: 9ê°œ ì˜ˆì™¸ í´ë˜ìŠ¤ ì •ì˜ (ë„¤íŠ¸ì›Œí¬/ê²€ì¦/ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ë¥˜) |
| P0 | Protocol ì‹œê·¸ë‹ˆì²˜ì— ì—ëŸ¬ íƒ€ì… ë¯¸ëª…ì‹œ | âœ… Section 11.1 í™•ì¥: `get_rules()`, `get_metric()` Raises ë¬¸ì„œí™” |
| P1 | API ì‘ë‹µ Pydantic ëª¨ë¸ ë¯¸ì •ì˜ | Section 5.2ì— TranspileResult, TranspileRule ë“± ëª¨ë¸ ì •ì˜ë¨ |
| P1 | ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´ ë¶ˆëª…í™• | âœ… Section 11.1ì— Protocol ê¸°ë°˜ DI íŒ¨í„´ ë° Mock/Real í´ë¼ì´ì–¸íŠ¸ ì˜ˆì‹œ ì¶”ê°€ |
| P2 | ëª¨ë“ˆ êµ¬ì¡° í‰ë©´ì  (models/, client/, processors/ ê¶Œì¥) | Section 12.1ì— core/transpile/ êµ¬ì¡° ëª…ì‹œ, Phase 2ì—ì„œ ì„¸ë¶„í™” ê³ ë ¤ |
| P2 | tenacity, structlog ë“± í˜„ëŒ€ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš© ê¶Œì¥ | Phase 2 ê³ ë ¤ì‚¬í•­ìœ¼ë¡œ ê¸°ë¡ |

### ë¦¬ë·° ìš”ì•½

| ì§€í‘œ | ê°’ |
|------|-----|
| ì´ P0 ì´ìŠˆ | 5ê°œ |
| í•´ê²°ëœ P0 | 5ê°œ (100%) |
| ì´ P1/P2 ì´ìŠˆ | 6ê°œ |
| í•´ê²°/ë°˜ì˜ëœ P1/P2 | 4ê°œ |

> **ê²°ë¡ **: ëª¨ë“  P0 ì´ìŠˆê°€ FEATURE ë¬¸ì„œì— ë°˜ì˜ë˜ì–´ êµ¬í˜„ ì¤€ë¹„ ì™„ë£Œ.

---

**Last Updated:** 2025-12-30
