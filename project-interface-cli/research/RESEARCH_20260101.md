# DataOps CLI Gap Analysis Research

> **Date:** 2026-01-01
> **Version:** dli v0.6.0
> **Author:** AI Research Assistant
> **Purpose:** Industry CLI Tool Comparison & Gap Identification

---

## 1. Executive Summary (핵심 발견 요약)

### 1.1 연구 목적

dli CLI v0.6.0의 현재 기능을 업계 표준 CLI 도구들(Databricks CLI, BigQuery bq CLI, dbt CLI, SQLMesh CLI)과 비교하여 기능 격차를 식별하고, 향후 개발 우선순위를 수립한다.

### 1.2 핵심 발견 사항

| 영역 | dli 현황 | 산업 표준 | Gap 수준 |
|------|----------|-----------|----------|
| **Selection Syntax** | 단순 이름 기반 | dbt/SQLMesh: Graph operators (+, @), Tag selectors | Critical |
| **Environment Management** | 단일 환경 | SQLMesh: Multi-environment (dev/staging/prod) | High |
| **Schema/Data Diff** | 없음 | SQLMesh: table_diff, schema diff | High |
| **Source Freshness** | 없음 | dbt: source freshness monitoring | Medium |
| **Snapshot/SCD** | 없음 | dbt: snapshot (SCD Type 2) | Medium |
| **Secrets Management** | 없음 | Databricks: secrets scope | Medium |
| **ML Integration** | 없음 | Databricks: experiments, models | Low |

### 1.3 우선순위별 구현 추천

```
P0 (Critical - 1-2주):
├── Selection Syntax (graph operators, tag selectors)
├── Environment Management (dev/staging/prod)
└── Debug/Diagnose Command

P1 (High - 2-4주):
├── Table/Schema Diff
├── Source Freshness
├── Init/Scaffold Command
└── Retry Command

P2 (Medium - 4-8주):
├── Snapshot (SCD Type 2)
├── Scheduled Queries
├── Format Command
└── Secrets Management
```

---

## 2. Industry CLI Analysis (산업별 CLI 분석)

### 2.1 Databricks CLI

> **Source:** [Databricks CLI Commands](https://docs.databricks.com/aws/en/dev-tools/cli/commands)

#### 2.1.1 Command Groups 개요

| Category | Command Groups | Description |
|----------|----------------|-------------|
| **Workspace** | `fs`, `workspace`, `repos` | 파일 시스템, 노트북, Git 관리 |
| **Compute** | `clusters`, `cluster-policies`, `instance-pools`, `libraries` | 클러스터 생명주기 관리 |
| **Jobs** | `jobs` | 작업 생성, 실행, 취소, 이력 조회 |
| **SQL** | `queries`, `warehouses`, `alerts` | SQL 웨어하우스 및 쿼리 관리 |
| **Unity Catalog** | `catalogs`, `schemas`, `tables`, `grants`, `storage-credentials` | 데이터 거버넌스 |
| **Secrets** | `secrets` | 자격 증명 보안 관리 |
| **ML** | `experiments`, `models`, `serving` | MLflow 통합 |
| **Bundles** | `bundle` | Asset Bundle 배포 |

#### 2.1.2 핵심 기능 상세

**Secrets Management:**
```bash
# Secret Scope 생성 및 관리
databricks secrets create-scope <scope-name>
databricks secrets put-secret <scope-name> <key-name>
databricks secrets list-scopes
databricks secrets get-secret <scope-name> <key-name> | jq -r .value | base64 --decode
```

**Unity Catalog Workspace Bindings:**
```bash
# Securable 바인딩 관리 (OPEN/ISOLATED)
databricks workspace-bindings get-bindings <securable-type> <securable-name>
databricks workspace-bindings update <catalog> --json '{"bindings": [...]}'
```

**Jobs Automation:**
```bash
databricks jobs create --json <job-config>
databricks jobs run-now <job-id>
databricks jobs cancel-run <run-id>
databricks jobs list-runs --job-id <job-id>
```

#### 2.1.3 dli 대비 차별화 기능

| Feature | Databricks CLI | dli v0.6.0 |
|---------|----------------|------------|
| Secrets Scope | O | X |
| Cluster Management | O | N/A (클라우드 독립) |
| Model Serving | O | X |
| Feature Store | O | X |
| Workspace Bindings | O | X (Unity Catalog 없음) |
| Asset Bundles | O | X |

---

### 2.2 BigQuery bq CLI

> **Source:** [bq CLI Reference](https://docs.cloud.google.com/bigquery/docs/reference/bq-cli-reference)

#### 2.2.1 Core Commands

| Command | Purpose | Key Flags |
|---------|---------|-----------|
| `bq mk` | Dataset/Table/View 생성 | `--dataset`, `--table`, `--view` |
| `bq rm` | 리소스 삭제 | `-r` (recursive), `-f` (force) |
| `bq query` | SQL 쿼리 실행 | `--nouse_legacy_sql`, `--dry_run` |
| `bq load` | 데이터 로드 | `--source_format`, `--schema` |
| `bq extract` | Cloud Storage로 내보내기 | `--destination_format` |
| `bq ls` | 리소스 목록 조회 | `--all`, `--filter` |
| `bq show` | 리소스 상세 정보 | `--schema`, `--format` |
| `bq head` | 테이블 미리보기 | `-n` (row count) |
| `bq wait` | 비동기 작업 대기 | `--fail_on_error` |
| `bq partition` | 파티션 테이블 변환 | |

#### 2.2.2 Scheduled Queries

```bash
# 스케줄된 쿼리 생성
bq query \
  --schedule='every 24 hours' \
  --display_name='daily_report' \
  --destination_table=project:dataset.table \
  --replace=true \
  'SELECT * FROM source_table WHERE date = @run_date'

# 스케줄 조회
bq ls --transfer_config --transfer_location=US
```

#### 2.2.3 Row-Level Security

```bash
# RLS 정책 목록 조회
bq ls --row_access_policies dataset.table

# RLS는 DDL로 관리
# CREATE ROW ACCESS POLICY filter_by_region
# ON dataset.table
# GRANT TO ('user:analyst@example.com')
# FILTER USING (region = 'US')
```

#### 2.2.4 Partitioning

```bash
# 파티션 테이블 생성
bq mk \
  --time_partitioning_field=date \
  --time_partitioning_type=DAY \
  --time_partitioning_expiration=7776000 \
  project:dataset.table

# 파티션 정보 조회
bq show --format=prettyjson project:dataset.table
```

#### 2.2.5 dli 대비 차별화 기능

| Feature | bq CLI | dli v0.6.0 |
|---------|--------|------------|
| Scheduled Queries | O | X (서버에서 관리) |
| Row-Level Security | O | X |
| Partition Management | O | 부분적 (transpile만) |
| Data Extract/Export | O (GCS) | O (local file) |
| Table Copy | O (`bq cp`) | X |
| ML Models | O (`--ml`) | X |
| IAM Policy | O (`bq get-iam-policy`) | X |

---

### 2.3 dbt CLI

> **Source:** [dbt Command Reference](https://docs.getdbt.com/reference/dbt-commands), [Graph Operators](https://docs.getdbt.com/reference/node-selection/graph-operators)

#### 2.3.1 Core Commands

| Command | Purpose | Read/Write |
|---------|---------|------------|
| `dbt run` | 모델 빌드 | Write |
| `dbt test` | 테스트 실행 | Read |
| `dbt build` | run + test + seed + snapshot 통합 | Write |
| `dbt compile` | SQL 컴파일 (실행 없음) | Read |
| `dbt parse` | 프로젝트 파싱 + 타이밍 | Read |
| `dbt debug` | 연결 및 설정 검증 | Read |
| `dbt docs` | 문서 생성 및 서빙 | Read |
| `dbt source` | 소스 관리 | Read |
| `dbt snapshot` | SCD Type 2 스냅샷 | Write |
| `dbt seed` | CSV 로드 | Write |
| `dbt deps` | 패키지 의존성 관리 | Read |
| `dbt clean` | 빌드 아티팩트 정리 | Read |
| `dbt clone` | 제로카피 클론 | Write |
| `dbt retry` | 실패 지점부터 재실행 | Write |

#### 2.3.2 Selection Syntax (Graph Operators)

**Plus (+) Operator:**
```bash
# 모델과 모든 후손 선택
dbt run --select "my_model+"

# 모델과 모든 조상 선택
dbt run --select "+my_model"

# 양방향 (조상 + 후손)
dbt run --select "+my_model+"

# 깊이 제한
dbt run --select "my_model+1"  # 1단계 후손만
dbt run --select "2+my_model"  # 2단계 조상까지
```

**At (@) Operator:**
```bash
# 모델 + 후손 + 후손의 조상
dbt run --select "@my_model"
```

**Set Operators:**
```bash
# 교집합 (쉼표로 구분, 공백 없음)
dbt run --select "tag:daily,state:modified"

# 합집합 (공백으로 구분)
dbt run --select "models/staging models/marts"
```

**Selector Methods:**
```bash
dbt run --select "tag:critical"        # 태그 기반
dbt run --select "source:snowplow"     # 소스 기반
dbt run --select "exposure:dashboard"  # Exposure 기반
dbt run --select "state:modified"      # 변경 상태 기반
dbt run --select "result:error"        # 이전 결과 기반
dbt run --select "path:models/core/*"  # 경로 기반
```

#### 2.3.3 Source Freshness

```bash
# 모든 소스 freshness 체크
dbt source freshness

# 특정 소스만 체크
dbt source freshness --select "source:snowplow"
dbt source freshness --select "source:snowplow.event"
```

**Configuration (sources.yml):**
```yaml
sources:
  - name: snowplow
    freshness:
      warn_after: {count: 12, period: hour}
      error_after: {count: 24, period: hour}
    loaded_at_field: _loaded_at
    tables:
      - name: events
```

#### 2.3.4 Snapshot (SCD Type 2)

```bash
# 스냅샷 실행
dbt snapshot
dbt snapshot --select "my_snapshot"
```

**Configuration:**
```yaml
{% snapshot orders_snapshot %}
{{
    config(
      target_database='analytics',
      target_schema='snapshots',
      unique_key='id',
      strategy='timestamp',
      updated_at='updated_at',
    )
}}
select * from {{ source('jaffle_shop', 'orders') }}
{% endsnapshot %}
```

#### 2.3.5 dbt show

```bash
# 모델 미리보기 (상위 5행)
dbt show --select "my_model"

# 행 수 지정
dbt show --select "my_model" --limit 10
```

#### 2.3.6 dli 대비 차별화 기능

| Feature | dbt CLI | dli v0.6.0 |
|---------|---------|------------|
| **Selection Syntax** | Graph operators (+, @) | X |
| **Tag/Source Selectors** | O | X |
| **State-based Selection** | O (`state:modified`) | X |
| **Source Freshness** | O | X |
| **Snapshot (SCD)** | O | X |
| **dbt show** | O | 부분적 (`dli run`) |
| **Retry from Failure** | O | X |
| **Clone** | O | X |
| **Parallel Execution** | O (threads) | 부분적 |
| **Debug Command** | O | X |
| **Init/Scaffold** | O | X |
| **Dependencies** | O (`dbt deps`) | X |

---

### 2.4 SQLMesh CLI

> **Source:** [SQLMesh CLI Reference](https://sqlmesh.readthedocs.io/en/stable/reference/cli/)

#### 2.4.1 Core Commands

| Command | Purpose | Key Options |
|---------|---------|-------------|
| `plan` | 로컬 변경 적용 | `--auto-apply`, `--no-prompts`, `--run` |
| `run` | 누락 구간 실행 | `--ignore-cron`, `--select-model` |
| `audit` | 데이터 품질 감사 | `--model`, `--start`, `--end` |
| `diff` | 로컬 vs 환경 비교 | (환경 인자 필수) |
| `format` | SQL 포맷팅 | `--transpile`, `--normalize`, `--check` |
| `table_diff` | 테이블 비교 | `--on`, `--skip-columns`, `--where` |
| `migrate` | 메타데이터 마이그레이션 | |
| `rollback` | 마이그레이션 롤백 | |
| `create_test` | 단위 테스트 생성 | `--query`, `--include-ctes` |
| `init` | 프로젝트 초기화 | `--template`, `--dlt-pipeline` |
| `info` | 프로젝트 정보 | `--skip-connection`, `--verbose` |
| `clean` | 캐시/아티팩트 정리 | |

#### 2.4.2 Plan Command (핵심)

```bash
# 기본 plan
sqlmesh plan

# 자동 적용
sqlmesh plan --auto-apply

# 프롬프트 없이 실행
sqlmesh plan --no-prompts

# 특정 모델만 포함
sqlmesh plan --select-model "my_model"

# 백필 건너뛰기
sqlmesh plan --skip-backfill

# Forward-only (비파괴적)
sqlmesh plan --forward-only
```

#### 2.4.3 Table Diff

```bash
# 환경 간 모델 비교
sqlmesh table_diff prod:dev --select-model "my_model"

# 여러 모델 비교
sqlmesh table_diff prod:dev --select-model "schema.*"

# 조건부 비교
sqlmesh table_diff prod:dev --where "date > '2025-01-01'" --limit 100
```

**Output:**
```
Schema Diff:
- Added: new_column (STRING)
- Removed: old_column
- Changed: amount (INT -> BIGINT)

Row Diff Summary:
- Rows in source only: 150
- Rows in target only: 23
- Rows with differences: 1,247
```

#### 2.4.4 Audit (데이터 품질)

```bash
# 모든 감사 실행
sqlmesh audit

# 특정 모델 감사
sqlmesh audit --model my_model

# 기간 지정
sqlmesh audit --start 2025-01-01 --end 2025-01-31
```

**Built-in Audits:**
- `not_null`
- `unique`
- `accepted_range`
- `accepted_values`
- `forall`

#### 2.4.5 Format Command

```bash
# 모든 SQL 포맷팅
sqlmesh format

# Dialect 변환
sqlmesh format --transpile bigquery

# 검증만 (수정 없음)
sqlmesh format --check

# 정규화 (소문자)
sqlmesh format --normalize
```

#### 2.4.6 Environment Management

```bash
# dev 환경으로 plan
sqlmesh plan dev

# prod에서 dev로 diff
sqlmesh diff prod:dev

# 환경별 run
sqlmesh run prod
```

#### 2.4.7 dli 대비 차별화 기능

| Feature | SQLMesh CLI | dli v0.6.0 |
|---------|-------------|------------|
| **Environment Management** | O (dev/staging/prod) | X (단일 환경) |
| **Table Diff** | O (schema + data) | X |
| **Audit (built-in)** | O | O (quality spec) |
| **Format Command** | O | X |
| **Plan (Virtual Env)** | O | X |
| **Forward-only Deploy** | O | X |
| **Migrate/Rollback** | O | X |
| **Create Test** | O | X |
| **Init Command** | O | X |
| **Model Selection** | O (`--select-model`) | X |

---

## 3. Gap Analysis (기능 격차 분석)

### 3.1 Gap Summary Matrix

| Gap ID | Feature | Priority | dbt | SQLMesh | bq | Databricks | Effort |
|--------|---------|----------|-----|---------|----|-----------:|--------|
| GAP-001 | Selection Syntax | P0 | O | O | - | - | 2주 |
| GAP-002 | Environment Management | P0 | O | O | - | - | 2주 |
| GAP-003 | Debug/Diagnose | P0 | O | - | - | - | 1주 |
| GAP-004 | Table/Schema Diff | P1 | - | O | - | - | 2주 |
| GAP-005 | Source Freshness | P1 | O | - | - | - | 2주 |
| GAP-006 | Init/Scaffold | P1 | O | O | - | - | 1주 |
| GAP-007 | Retry from Failure | P1 | O | - | - | - | 1주 |
| GAP-008 | Snapshot (SCD) | P2 | O | - | - | - | 3주 |
| GAP-009 | Scheduled Queries | P2 | - | - | O | - | 2주 |
| GAP-010 | Format Command | P2 | - | O | - | - | 1주 |
| GAP-011 | Secrets Management | P2 | - | - | - | O | 2주 |
| GAP-012 | Clone Command | P2 | O | - | - | - | 1주 |
| GAP-013 | ML Integration | P3 | - | - | O | O | 4주+ |

### 3.2 Detailed Gap Analysis

#### GAP-001: Selection Syntax (P0 - Critical)

**현황:**
- dli는 단순 이름 기반 선택만 지원
- `dli dataset run my_dataset` 형태

**목표:**
```bash
# Graph operators
dli dataset run "+my_dataset"      # 조상 포함
dli dataset run "my_dataset+"      # 후손 포함
dli dataset run "+my_dataset+"     # 양방향

# Tag selectors
dli dataset run --tag critical
dli dataset run --tag "tier::gold"

# Path selectors
dli dataset run --path "models/staging/*"

# State selectors (--state 필요)
dli dataset run --state modified
```

**구현 계획:**
1. `SelectionParser` 클래스 추가 (`core/selection/`)
2. Graph operator 파서 (`+`, `@`)
3. Tag/Path/State selector 파서
4. `--select` / `--exclude` 글로벌 옵션

**예상 노력:** 2주

---

#### GAP-002: Environment Management (P0 - Critical)

**현황:**
- 단일 환경 (`DLI_SERVER_URL`)
- 환경 전환은 환경 변수 수동 변경

**목표:**
```bash
# 환경 목록
dli env list

# 환경 전환
dli env use dev
dli env use prod

# 환경별 실행
dli dataset run my_dataset --env dev

# 환경 설정
dli env set dev --server-url https://dev.basecamp.example.com
```

**구현 계획:**
1. `~/.dli/environments.yaml` 설정 파일
2. `EnvAPI` 클래스
3. `dli env` 커맨드 그룹
4. `--env` 글로벌 옵션

**예상 노력:** 2주

---

#### GAP-003: Debug/Diagnose Command (P0 - Critical)

**현황:**
- `dli config status`로 서버 연결만 확인
- 상세 진단 없음

**목표:**
```bash
# 전체 진단
dli debug

# 출력 예시:
# ✓ Python version: 3.12.1
# ✓ dli version: 0.6.0
# ✓ Config file: ~/.dli/config.json
# ✓ Server URL: https://basecamp.example.com
# ✓ Server connection: OK (latency: 45ms)
# ✓ Authentication: OK (user: admin@example.com)
# ✓ Project path: /opt/airflow/dags/models
# ✓ Metrics found: 42
# ✓ Datasets found: 128
# ✗ BigQuery credentials: NOT CONFIGURED
# ✗ Trino connection: FAILED (Connection refused)
```

**구현 계획:**
1. `DebugAPI` 클래스
2. 연결 진단 로직
3. 설정 검증 로직
4. Rich 출력 포맷

**예상 노력:** 1주

---

#### GAP-004: Table/Schema Diff (P1 - High)

**현황:**
- 없음

**목표:**
```bash
# 환경 간 테이블 비교
dli diff my_dataset --source dev --target prod

# 스키마만 비교
dli diff my_dataset --schema-only

# 특정 컬럼 무시
dli diff my_dataset --skip-columns "updated_at,_etl_timestamp"

# 조건부 비교
dli diff my_dataset --where "date > '2025-01-01'" --limit 1000

# 출력:
# Schema Diff:
#   + new_column (STRING)
#   - removed_column
#   ~ changed_column: INT -> BIGINT
#
# Row Diff:
#   Source only: 150 rows
#   Target only: 23 rows
#   Different: 1,247 rows
```

**구현 계획:**
1. `DiffAPI` 클래스
2. Schema diff 로직
3. Row diff 로직 (sampling 기반)
4. 환경 참조 문법 (`dev:prod`)

**예상 노력:** 2주

---

#### GAP-005: Source Freshness (P1 - High)

**현황:**
- 없음

**목표:**
```bash
# 모든 소스 freshness 체크
dli source freshness

# 특정 소스만
dli source freshness --select "source:snowplow"

# 출력:
# Source              | Loaded At        | Age      | Status
# --------------------|------------------|----------|--------
# snowplow.events     | 2025-01-01 10:30 | 2h 30m   | WARN
# salesforce.accounts | 2025-01-01 08:00 | 5h 00m   | ERROR
# stripe.payments     | 2025-01-01 12:55 | 5m       | OK
```

**Configuration (source_spec.yaml):**
```yaml
version: "1.0"
kind: source
metadata:
  name: snowplow.events
spec:
  freshness:
    warn_after: {count: 12, period: hour}
    error_after: {count: 24, period: hour}
  loaded_at_field: _loaded_at
```

**구현 계획:**
1. Source spec 모델
2. `SourceAPI` 클래스
3. Freshness 계산 로직
4. `dli source freshness` 커맨드

**예상 노력:** 2주

---

#### GAP-006: Init/Scaffold Command (P1 - High)

**현황:**
- 없음 (수동으로 디렉토리 구조 생성)

**목표:**
```bash
# 새 프로젝트 초기화
dli init my_project

# 템플릿 선택
dli init my_project --template starter
dli init my_project --template advanced

# 생성되는 구조:
# my_project/
# ├── metrics/
# ├── datasets/
# ├── sources/
# ├── qualities/
# ├── dli_project.yaml
# └── .dli/
#     └── profiles.yaml
```

**구현 계획:**
1. 템플릿 시스템
2. `dli init` 커맨드
3. Interactive prompts (프로젝트 이름, 템플릿 등)

**예상 노력:** 1주

---

#### GAP-007: Retry from Failure (P1 - High)

**현황:**
- 없음 (실패 시 전체 재실행)

**목표:**
```bash
# 마지막 실패 지점부터 재시도
dli retry

# 출력:
# Retrying from last failure point...
# Skipping: dataset_a (already succeeded)
# Skipping: dataset_b (already succeeded)
# Running: dataset_c (previously failed)
# Running: dataset_d (downstream of failed)
```

**구현 계획:**
1. Run history 저장 (`~/.dli/run_results/`)
2. `RetryAPI` 클래스
3. 실패 지점 추적 로직

**예상 노력:** 1주

---

#### GAP-008: Snapshot (SCD Type 2) (P2 - Medium)

**현황:**
- 없음

**목표:**
```bash
# 스냅샷 실행
dli snapshot run orders_snapshot

# 스냅샷 목록
dli snapshot list

# 스냅샷 이력
dli snapshot history orders_snapshot
```

**Snapshot Spec:**
```yaml
version: "1.0"
kind: snapshot
metadata:
  name: orders_snapshot
  target_schema: snapshots
spec:
  unique_key: id
  strategy: timestamp
  updated_at: updated_at
  sql: |
    SELECT * FROM {{ source('shop', 'orders') }}
```

**예상 노력:** 3주

---

#### GAP-009: Scheduled Queries (P2 - Medium)

**현황:**
- 서버 기반 스케줄링 (workflow)
- CLI에서 직접 스케줄 관리 없음

**목표:**
```bash
# 스케줄 목록
dli schedule list

# 스케줄 생성
dli schedule create my_report \
  --cron "0 6 * * *" \
  --sql "SELECT * FROM analytics.daily"

# 스케줄 상태
dli schedule status my_report

# 스케줄 pause/unpause
dli schedule pause my_report
dli schedule unpause my_report
```

**예상 노력:** 2주

---

#### GAP-010: Format Command (P2 - Medium)

**현황:**
- 없음

**목표:**
```bash
# 모든 SQL 포맷
dli format

# 특정 파일
dli format --path datasets/staging/

# 검증만 (수정 없음)
dli format --check

# Dialect 변환
dli format --dialect bigquery

# 정규화 (소문자)
dli format --normalize
```

**구현 계획:**
1. SQLGlot 활용
2. `dli format` 커맨드
3. `--check` 모드 (CI용)

**예상 노력:** 1주

---

#### GAP-011: Secrets Management (P2 - Medium)

**현황:**
- 환경 변수 기반 (`DLI_*`)
- 보안 저장소 없음

**목표:**
```bash
# Secret 저장
dli secrets set DB_PASSWORD

# Secret 조회 (마스킹)
dli secrets list

# Secret 삭제
dli secrets delete DB_PASSWORD

# SQL에서 참조
# SELECT * FROM {{ secret('DB_HOST') }}
```

**구현 계획:**
1. `~/.dli/secrets` (암호화 파일)
2. Keyring 통합 (macOS Keychain, Windows Credential Manager)
3. `{{ secret('KEY') }}` 템플릿 함수

**예상 노력:** 2주

---

#### GAP-012: Clone Command (P2 - Medium)

**현황:**
- 없음

**목표:**
```bash
# 테이블 클론 (제로카피 가능한 경우)
dli clone my_dataset --from prod --to dev

# 스키마만 클론
dli clone my_dataset --schema-only
```

**예상 노력:** 1주

---

### 3.3 Feature Parity Score

| Category | dbt | SQLMesh | bq | Databricks | dli v0.6.0 |
|----------|-----|---------|----|-----------:|------------|
| Resource CRUD | 5/5 | 4/5 | 5/5 | 5/5 | 5/5 |
| SQL Execution | 5/5 | 5/5 | 5/5 | 4/5 | 4/5 |
| Selection Syntax | 5/5 | 4/5 | 1/5 | 2/5 | 1/5 |
| Environment Mgmt | 4/5 | 5/5 | 3/5 | 5/5 | 1/5 |
| Data Quality | 5/5 | 5/5 | 2/5 | 3/5 | 4/5 |
| Lineage | 4/5 | 4/5 | 2/5 | 4/5 | 4/5 |
| Schema Mgmt | 4/5 | 5/5 | 5/5 | 5/5 | 3/5 |
| DevOps | 4/5 | 4/5 | 3/5 | 5/5 | 2/5 |
| **Total** | **36/40** | **36/40** | **26/40** | **33/40** | **24/40** |

---

## 4. Recommendations (구현 제안)

### 4.1 P0: Critical (즉시 구현)

| Feature | Impact | Effort | ROI |
|---------|--------|--------|-----|
| Selection Syntax | 생산성 50% 향상 | 2주 | Very High |
| Environment Management | 배포 안정성 | 2주 | High |
| Debug Command | 온보딩/트러블슈팅 | 1주 | High |

### 4.2 P1: High (1개월 내)

| Feature | Impact | Effort | ROI |
|---------|--------|--------|-----|
| Table/Schema Diff | 데이터 검증 | 2주 | High |
| Source Freshness | 데이터 품질 | 2주 | High |
| Init Command | 온보딩 | 1주 | Medium |
| Retry Command | 안정성 | 1주 | Medium |

### 4.3 P2: Medium (3개월 내)

| Feature | Impact | Effort | ROI |
|---------|--------|--------|-----|
| Snapshot (SCD) | 데이터 이력 | 3주 | Medium |
| Scheduled Queries | 자동화 | 2주 | Medium |
| Format Command | 코드 품질 | 1주 | Low |
| Secrets Management | 보안 | 2주 | Medium |

---

## 5. Implementation Roadmap (구현 로드맵)

### 5.1 Phase 1: Foundation (4주)

```
Week 1-2: Selection Syntax
├── SelectionParser 구현
├── Graph operators (+, @)
├── Tag/Path selectors
└── --select/--exclude 글로벌 옵션

Week 3-4: Environment Management
├── environments.yaml 설정
├── EnvAPI 구현
├── dli env 커맨드
└── --env 글로벌 옵션
```

**Milestone:** dli v0.7.0
- Selection Syntax 지원
- Multi-environment 지원
- Debug 커맨드

### 5.2 Phase 2: Data Operations (4주)

```
Week 5-6: Table/Schema Diff
├── DiffAPI 구현
├── Schema comparison
├── Row sampling comparison
└── dli diff 커맨드

Week 7-8: Source Freshness
├── Source spec 모델
├── SourceAPI 구현
├── Freshness calculation
└── dli source freshness 커맨드
```

**Milestone:** dli v0.8.0
- Table diff 지원
- Source freshness 모니터링
- Init 커맨드
- Retry 커맨드

### 5.3 Phase 3: Advanced Features (6주)

```
Week 9-11: Snapshot
├── Snapshot spec 모델
├── SCD Type 2 구현
├── SnapshotAPI 구현
└── dli snapshot 커맨드

Week 12-14: Polish
├── Format 커맨드
├── Secrets 관리
├── Clone 커맨드
└── 문서화
```

**Milestone:** dli v0.9.0
- Snapshot (SCD Type 2)
- Format 커맨드
- Secrets 관리

### 5.4 Timeline Summary

```
2026 Q1:
├── v0.7.0 (1월): Selection + Environment + Debug
├── v0.8.0 (2월): Diff + Freshness + Init + Retry
└── v0.9.0 (3월): Snapshot + Format + Secrets

2026 Q2:
└── v1.0.0 (4월): 안정화, ML 통합 검토
```

---

## 6. Appendix

### A. Research Sources

- [Databricks CLI Commands](https://docs.databricks.com/aws/en/dev-tools/cli/commands)
- [bq CLI Reference](https://docs.cloud.google.com/bigquery/docs/reference/bq-cli-reference)
- [BigQuery Scheduling Queries](https://docs.cloud.google.com/bigquery/docs/scheduling-queries)
- [dbt Command Reference](https://docs.getdbt.com/reference/dbt-commands)
- [dbt Graph Operators](https://docs.getdbt.com/reference/node-selection/graph-operators)
- [dbt Source Freshness](https://docs.getdbt.com/docs/deploy/source-freshness)
- [SQLMesh CLI Reference](https://sqlmesh.readthedocs.io/en/stable/reference/cli/)
- [SQLMesh Table Diff Guide](https://sqlmesh.readthedocs.io/en/stable/guides/tablediff/)

### B. Glossary

| Term | Definition |
|------|------------|
| **Graph Operator** | DAG에서 조상/후손을 선택하는 연산자 (+, @) |
| **SCD Type 2** | Slowly Changing Dimension - 이력 추적 테이블 패턴 |
| **Source Freshness** | 소스 테이블의 데이터 최신성 모니터링 |
| **Zero-copy Clone** | 물리적 복사 없이 테이블을 참조하는 기술 |
| **Virtual Environment** | SQLMesh의 격리된 테스트 환경 개념 |

### C. dli v0.6.0 Current Commands Reference

```bash
# Version & Info
dli version
dli info

# Configuration
dli config show
dli config status

# Resources
dli metric list|get|run|validate|register <name>
dli dataset list|get|run|validate|register <name>

# Catalog
dli catalog <identifier>
dli catalog list [--owner] [--tag]
dli catalog search <query>

# Workflow
dli workflow run|backfill|stop|status|list|history|pause|unpause

# Quality
dli quality list|get|run|validate

# Query
dli query list|show|cancel

# Lineage
dli lineage show|upstream|downstream

# Transpile
dli transpile <sql> [--dialect] [--validate]

# Run
dli run --sql <file> --output <file> [--param key=value]
```

---

## Python Review (expert-python)

> **Reviewer:** expert-python
> **Date:** 2026-01-01

### 1. Python Best Practices Assessment

#### 1.1 Overall Design Alignment

The proposed features align well with dli's existing patterns:
- **Facade Pattern** for API classes (`EnvAPI`, `DiffAPI`, `SourceAPI`)
- **Pydantic models** for configuration and results
- **Dataclass exceptions** with `ErrorCode` enum
- **Type hints** throughout

#### 1.2 Pythonic Design Recommendations by Gap

| Gap ID | Feature | Recommendation |
|--------|---------|----------------|
| GAP-001 | Selection Syntax | Use `lark` or custom parser with `__contains__` protocol |
| GAP-002 | Environment Management | Follow `pathlib.Path` patterns, use `platformdirs` |
| GAP-003 | Debug Command | Implement as `health_check()` returning structured `DiagnosticResult` |
| GAP-004 | Table/Schema Diff | Consider `deepdiff` for structural comparison |
| GAP-005 | Source Freshness | Use `pendulum` for time calculations (already a dependency) |
| GAP-010 | Format Command | Leverage existing `sqlglot` integration |

---

### 2. Type Safety Considerations

#### 2.1 Selection Syntax (GAP-001)

```python
from __future__ import annotations
from typing import Protocol, runtime_checkable

@runtime_checkable
class Selectable(Protocol):
    """Protocol for objects that can be selected."""
    @property
    def name(self) -> str: ...
    @property
    def tags(self) -> set[str]: ...
    @property
    def path(self) -> Path: ...

class SelectionExpression:
    """Type-safe selection expression."""

    @classmethod
    def parse(cls, expr: str) -> SelectionExpression:
        """Parse selection syntax: '+model', 'model+', 'tag:critical'."""
        ...

    def matches(self, item: Selectable) -> bool:
        """Check if item matches this expression."""
        ...

    def __and__(self, other: SelectionExpression) -> SelectionExpression:
        """Intersection: expr1 & expr2"""
        ...

    def __or__(self, other: SelectionExpression) -> SelectionExpression:
        """Union: expr1 | expr2"""
        ...
```

**Key Type Patterns:**
- Use `Protocol` for duck typing (Selectable interface)
- Return `Self` from builder methods (Python 3.11+ or `typing_extensions`)
- Use `Literal` types for operator strings

#### 2.2 Environment Management (GAP-002)

```python
from typing import Literal

EnvironmentName = Literal["dev", "staging", "prod"] | str

class EnvironmentConfig(BaseModel):
    """Environment configuration with validation."""

    name: str = Field(..., min_length=1, max_length=50)
    server_url: HttpUrl
    default: bool = False

    model_config = ConfigDict(
        extra="forbid",  # Fail on unknown fields
        frozen=True,     # Immutable after creation
    )

class EnvironmentRegistry:
    """Type-safe environment registry."""

    def __init__(self, config_path: Path | None = None) -> None:
        self._config_path = config_path or self._default_path()
        self._environments: dict[str, EnvironmentConfig] = {}

    def get(self, name: str) -> EnvironmentConfig | None: ...
    def set(self, name: str, config: EnvironmentConfig) -> None: ...
    def current(self) -> EnvironmentConfig: ...
```

#### 2.3 New ErrorCode Assignments

Following existing convention in `exceptions.py`:

```python
# New Error Codes for proposed features
class ErrorCode(str, Enum):
    # ... existing codes ...

    # Selection Errors (DLI-10xx) - New range
    SELECTION_PARSE_ERROR = "DLI-1001"
    SELECTION_INVALID_OPERATOR = "DLI-1002"
    SELECTION_NO_MATCHES = "DLI-1003"

    # Environment Errors (DLI-11xx)
    ENV_NOT_FOUND = "DLI-1101"
    ENV_CONFIG_INVALID = "DLI-1102"
    ENV_ALREADY_EXISTS = "DLI-1103"

    # Diff Errors (DLI-12xx)
    DIFF_SCHEMA_MISMATCH = "DLI-1201"
    DIFF_ACCESS_DENIED = "DLI-1202"
    DIFF_TIMEOUT = "DLI-1203"

    # Source Errors (DLI-13xx)
    SOURCE_NOT_FOUND = "DLI-1301"
    SOURCE_FRESHNESS_STALE = "DLI-1302"

    # Snapshot Errors (DLI-14xx)
    SNAPSHOT_NOT_FOUND = "DLI-1401"
    SNAPSHOT_STRATEGY_INVALID = "DLI-1402"
```

---

### 3. Testing Strategies by Gap

#### 3.1 GAP-001: Selection Syntax

```python
# tests/core/selection/test_parser.py
import pytest
from dli.core.selection import SelectionExpression, SelectionParser

class TestSelectionParser:
    """Selection syntax parser tests."""

    @pytest.mark.parametrize("expr,expected_type", [
        ("+my_model", "ancestors"),
        ("my_model+", "descendants"),
        ("+my_model+", "both"),
        ("my_model+1", "descendants_limited"),
        ("2+my_model", "ancestors_limited"),
    ])
    def test_graph_operators(self, expr: str, expected_type: str) -> None:
        """Test graph operator parsing."""
        result = SelectionParser.parse(expr)
        assert result.operator_type == expected_type

    @pytest.mark.parametrize("expr,tag", [
        ("tag:critical", "critical"),
        ("tag:tier::gold", "tier::gold"),
    ])
    def test_tag_selectors(self, expr: str, tag: str) -> None:
        """Test tag selector parsing."""
        result = SelectionParser.parse(expr)
        assert tag in result.tags

    def test_intersection(self) -> None:
        """Test comma-separated intersection."""
        result = SelectionParser.parse("tag:daily,state:modified")
        assert result.requires_all(["tag:daily", "state:modified"])

    def test_union(self) -> None:
        """Test space-separated union."""
        result = SelectionParser.parse("models/staging models/marts")
        assert result.matches_any(["models/staging", "models/marts"])
```

**Test Fixtures (`conftest.py`):**

```python
@pytest.fixture
def sample_dag() -> dict[str, list[str]]:
    """Sample DAG for testing graph operators."""
    return {
        "staging_users": [],
        "staging_orders": [],
        "marts_users": ["staging_users"],
        "marts_orders": ["staging_orders", "marts_users"],
        "report_daily": ["marts_users", "marts_orders"],
    }

@pytest.fixture
def selectable_models(sample_dag: dict) -> list[MockSelectable]:
    """Generate selectable mock models from DAG."""
    return [MockSelectable(name=name, deps=deps) for name, deps in sample_dag.items()]
```

#### 3.2 GAP-002: Environment Management

```python
# tests/core/test_environment.py
import pytest
from pathlib import Path
from dli.core.environment import EnvironmentRegistry, EnvironmentConfig

class TestEnvironmentRegistry:
    """Environment management tests."""

    @pytest.fixture
    def temp_config(self, tmp_path: Path) -> Path:
        """Create temporary environment config."""
        config_file = tmp_path / ".dli" / "environments.yaml"
        config_file.parent.mkdir(parents=True)
        config_file.write_text("""
        environments:
          dev:
            server_url: https://dev.example.com
          prod:
            server_url: https://prod.example.com
        current: dev
        """)
        return config_file

    def test_list_environments(self, temp_config: Path) -> None:
        """Test listing available environments."""
        registry = EnvironmentRegistry(temp_config)
        envs = registry.list()
        assert {"dev", "prod"} == set(envs)

    def test_switch_environment(self, temp_config: Path) -> None:
        """Test switching environments."""
        registry = EnvironmentRegistry(temp_config)
        registry.use("prod")
        assert registry.current().name == "prod"

    def test_env_not_found(self, temp_config: Path) -> None:
        """Test error when environment not found."""
        registry = EnvironmentRegistry(temp_config)
        with pytest.raises(EnvironmentNotFoundError) as exc:
            registry.use("staging")
        assert exc.value.code == ErrorCode.ENV_NOT_FOUND
```

#### 3.3 GAP-003: Debug Command

```python
# tests/commands/test_debug.py
from typer.testing import CliRunner
from dli.main import app

runner = CliRunner()

class TestDebugCommand:
    """Debug command tests."""

    def test_debug_success(self, monkeypatch) -> None:
        """Test successful debug output."""
        # Mock all external dependencies
        monkeypatch.setenv("DLI_SERVER_URL", "https://test.example.com")
        result = runner.invoke(app, ["debug"])
        assert result.exit_code == 0
        assert "Python version" in result.output
        assert "dli version" in result.output

    def test_debug_server_unreachable(self, monkeypatch) -> None:
        """Test debug with unreachable server."""
        monkeypatch.setenv("DLI_SERVER_URL", "https://unreachable.example.com")
        result = runner.invoke(app, ["debug"])
        # Should still succeed but show warning
        assert result.exit_code == 0
        assert "Server connection" in result.output
        assert "FAILED" in result.output or "[yellow]" in result.output
```

#### 3.4 GAP-004: Table/Schema Diff

```python
# tests/api/test_diff.py
import pytest
from dli import DiffAPI, ExecutionContext, ExecutionMode

class TestDiffAPI:
    """Diff API tests."""

    @pytest.fixture
    def mock_diff_api(self) -> DiffAPI:
        return DiffAPI(context=ExecutionContext(execution_mode=ExecutionMode.MOCK))

    def test_schema_diff(self, mock_diff_api: DiffAPI) -> None:
        """Test schema comparison."""
        result = mock_diff_api.diff(
            "my_dataset",
            source_env="dev",
            target_env="prod",
            schema_only=True,
        )
        assert result.status == ResultStatus.SUCCESS
        assert hasattr(result, "schema_changes")

    def test_row_diff_with_limit(self, mock_diff_api: DiffAPI) -> None:
        """Test row comparison with limit."""
        result = mock_diff_api.diff(
            "my_dataset",
            source_env="dev",
            target_env="prod",
            limit=1000,
        )
        assert result.rows_compared <= 1000
```

#### 3.5 GAP-005: Source Freshness

```python
# tests/core/test_source_freshness.py
import pytest
from datetime import datetime, timedelta
from dli.core.source import FreshnessChecker, FreshnessStatus

class TestFreshnessChecker:
    """Source freshness tests."""

    def test_fresh_source(self) -> None:
        """Test source within freshness threshold."""
        checker = FreshnessChecker(
            warn_after=timedelta(hours=12),
            error_after=timedelta(hours=24),
        )
        loaded_at = datetime.now() - timedelta(hours=1)
        status = checker.check(loaded_at)
        assert status == FreshnessStatus.OK

    def test_stale_source_warning(self) -> None:
        """Test source with warning threshold exceeded."""
        checker = FreshnessChecker(
            warn_after=timedelta(hours=12),
            error_after=timedelta(hours=24),
        )
        loaded_at = datetime.now() - timedelta(hours=15)
        status = checker.check(loaded_at)
        assert status == FreshnessStatus.WARN

    def test_stale_source_error(self) -> None:
        """Test source with error threshold exceeded."""
        checker = FreshnessChecker(
            warn_after=timedelta(hours=12),
            error_after=timedelta(hours=24),
        )
        loaded_at = datetime.now() - timedelta(hours=30)
        status = checker.check(loaded_at)
        assert status == FreshnessStatus.ERROR
```

---

### 4. Recommended Libraries and Patterns

#### 4.1 Core Dependencies

| Feature | Library | Purpose | Version |
|---------|---------|---------|---------|
| Selection Parsing | `lark` | Grammar-based parsing | ^1.2.0 |
| Config Storage | `platformdirs` | Cross-platform config paths | ^4.0.0 |
| Time Calculations | `pendulum` | Timezone-aware datetime (existing) | - |
| Schema Comparison | `deepdiff` | Deep object comparison | ^8.0.0 |
| Secrets Storage | `keyring` | OS keychain integration | ^25.0.0 |
| SQL Formatting | `sqlglot` | SQL parsing/formatting (existing) | - |

#### 4.2 Alternative: Avoid `lark` Dependency

For simpler selection syntax, use regex-based parsing:

```python
import re
from dataclasses import dataclass, field
from typing import ClassVar

@dataclass
class SelectionParser:
    """Regex-based selection syntax parser."""

    GRAPH_PATTERN: ClassVar[re.Pattern] = re.compile(
        r'^(?P<ancestors>\d*\+)?(?P<name>[a-zA-Z_][a-zA-Z0-9_]*)(?P<descendants>\+\d*)?$'
    )
    TAG_PATTERN: ClassVar[re.Pattern] = re.compile(r'^tag:(?P<tag>.+)$')
    PATH_PATTERN: ClassVar[re.Pattern] = re.compile(r'^path:(?P<path>.+)$')
    STATE_PATTERN: ClassVar[re.Pattern] = re.compile(r'^state:(?P<state>modified|new|deleted)$')

    @classmethod
    def parse(cls, expr: str) -> SelectionExpression:
        """Parse a single selection expression."""
        # Try each pattern
        if match := cls.TAG_PATTERN.match(expr):
            return TagSelector(tag=match.group("tag"))
        if match := cls.PATH_PATTERN.match(expr):
            return PathSelector(pattern=match.group("path"))
        if match := cls.STATE_PATTERN.match(expr):
            return StateSelector(state=match.group("state"))
        if match := cls.GRAPH_PATTERN.match(expr):
            return GraphSelector(
                name=match.group("name"),
                ancestors=match.group("ancestors"),
                descendants=match.group("descendants"),
            )
        raise SelectionParseError(f"Invalid selection syntax: {expr}")
```

#### 4.3 Directory Structure for New Features

```
project-interface-cli/src/dli/
├── core/
│   ├── selection/           # GAP-001
│   │   ├── __init__.py
│   │   ├── parser.py        # SelectionParser
│   │   ├── expressions.py   # SelectionExpression subclasses
│   │   └── resolver.py      # DAG resolution
│   ├── environment/         # GAP-002
│   │   ├── __init__.py
│   │   ├── registry.py      # EnvironmentRegistry
│   │   └── config.py        # EnvironmentConfig
│   ├── diff/                # GAP-004
│   │   ├── __init__.py
│   │   ├── schema.py        # SchemaDiff
│   │   └── row.py           # RowDiff
│   ├── source/              # GAP-005
│   │   ├── __init__.py
│   │   ├── freshness.py     # FreshnessChecker
│   │   └── models.py        # SourceSpec
│   └── snapshot/            # GAP-008
│       ├── __init__.py
│       ├── strategy.py      # SCDStrategy
│       └── executor.py      # SnapshotExecutor
├── api/
│   ├── env.py               # EnvAPI
│   ├── diff.py              # DiffAPI
│   ├── source.py            # SourceAPI
│   └── snapshot.py          # SnapshotAPI
└── commands/
    ├── env.py               # dli env
    ├── debug.py             # dli debug
    ├── diff.py              # dli diff
    ├── source.py            # dli source
    └── init_cmd.py          # dli init (avoid 'init' conflict)
```

---

### 5. Implementation Priority Recommendations

Based on Python implementation complexity and value:

#### 5.1 Quick Wins (1 week each)

| Feature | Complexity | Reasoning |
|---------|------------|-----------|
| **GAP-003: Debug** | Low | Simple diagnostic gathering, no new dependencies |
| **GAP-010: Format** | Low | Leverage existing `sqlglot`, add CLI wrapper |
| **GAP-006: Init** | Low | Template-based scaffolding with `jinja2` |

#### 5.2 Medium Effort (2 weeks each)

| Feature | Complexity | Reasoning |
|---------|------------|-----------|
| **GAP-002: Environment** | Medium | Config file management, global option propagation |
| **GAP-007: Retry** | Medium | State persistence, DAG traversal |
| **GAP-005: Freshness** | Medium | Time calculations, source spec model |

#### 5.3 Higher Effort (3+ weeks)

| Feature | Complexity | Reasoning |
|---------|------------|-----------|
| **GAP-001: Selection** | High | Parser complexity, DAG integration |
| **GAP-004: Diff** | High | Cross-environment queries, sampling logic |
| **GAP-008: Snapshot** | High | SCD implementation, state management |

---

### 6. Anti-Patterns to Avoid

1. **Avoid mutable default arguments in Selection API:**
   ```python
   # BAD
   def select(models: list[str] = []) -> list[Model]: ...

   # GOOD
   def select(models: list[str] | None = None) -> list[Model]:
       models = models or []
   ```

2. **Avoid bare string environment names:**
   ```python
   # BAD
   def run(env: str = "dev") -> Result: ...

   # GOOD
   def run(env: EnvironmentConfig | str = "dev") -> Result:
       if isinstance(env, str):
           env = EnvironmentRegistry().get(env)
   ```

3. **Avoid synchronous blocking in diff operations:**
   ```python
   # Consider async for large diff operations
   async def diff_tables(source: str, target: str) -> DiffResult:
       async with asyncio.TaskGroup() as tg:
           source_schema = tg.create_task(fetch_schema(source))
           target_schema = tg.create_task(fetch_schema(target))
       return compare_schemas(source_schema.result(), target_schema.result())
   ```

4. **Always use `pathlib.Path` for file operations:**
   ```python
   # BAD
   config_path = os.path.expanduser("~/.dli/config.yaml")

   # GOOD
   from platformdirs import user_config_dir
   config_path = Path(user_config_dir("dli")) / "config.yaml"
   ```

---

### 7. Summary Recommendations

| Priority | Action Item |
|----------|-------------|
| P0 | Implement `SelectionParser` with regex-based approach first, upgrade to `lark` if needed |
| P0 | Add `platformdirs` for cross-platform config path resolution |
| P0 | Create `DiagnosticResult` model for structured debug output |
| P1 | Design `DiffResult` to be composable (schema + row diffs) |
| P1 | Use `pendulum` for freshness calculations (already a dependency) |
| P2 | Consider `keyring` for secrets but make it optional (not all systems have it) |
| P2 | Implement snapshot using strategy pattern for SCD Type 1/2/3 |

**Test Coverage Target:** 90%+ for core modules, 80%+ for commands.

---

## Implementation Review (feature-interface-cli)

> **Reviewer:** feature-interface-cli agent
> **Date:** 2026-01-01
> **Based on:** dli v0.6.0 codebase analysis

### 1. Technical Feasibility Summary

| Gap | Feasibility | Architecture Impact | Server Dependency |
|-----|-------------|---------------------|-------------------|
| GAP-001 Selection Syntax | High | New `core/selection/` module | No |
| GAP-002 Environment Management | High | Extend `ExecutionContext` | No |
| GAP-003 Debug Command | High | Reuse existing config checks | Partial |
| GAP-004 Table/Schema Diff | Medium | Engine-specific adapters needed | Yes |
| GAP-005 Source Freshness | Medium | New spec type | Yes (metadata) |
| GAP-006 Init/Scaffold | High | Template system | No |
| GAP-007 Retry Command | Medium | Run history persistence | Partial |
| GAP-008 Snapshot (SCD) | Low-Medium | Major new feature | Yes |
| GAP-009 Scheduled Queries | Low | Overlaps with workflow | Yes |
| GAP-010 Format Command | High | SQLGlot already available | No |
| GAP-011 Secrets Management | Medium | Platform-specific keyring | No |
| GAP-012 Clone Command | Medium | Engine-specific zero-copy | Partial |

---

### 2. Gap-by-Gap Technical Review

#### GAP-001: Selection Syntax (P0)

**Architecture Compatibility:**
- **Reusable:** `LineageClient` in `core/lineage/client.py` already provides dependency graph traversal
- **New:** `core/selection/` module with `SelectionParser`, `GraphOperator`, `SelectorMethod` classes
- **Impact:** Modify `dataset.py`, `metric.py`, `workflow.py` commands to accept `--select` option

**Effort Adjustment:** 2 weeks -> **3 weeks**
- Graph operator parsing is non-trivial
- Need extensive test cases for complex selections
- Integration with lineage client adds complexity

**Code Pattern:**
```python
# Proposed: core/selection/parser.py
class SelectionParser:
    def parse(self, expression: str) -> SelectionResult:
        """Parse '+my_model' or 'tag:critical,path:staging/*'"""
        ...

# Usage in commands/dataset.py
@dataset_app.command("run")
def run_dataset(
    name: str,
    select: Annotated[str | None, typer.Option("--select", "-s")] = None,
):
    if select:
        parser = SelectionParser(lineage_client=get_lineage_client())
        targets = parser.parse(select)
    ...
```

---

#### GAP-002: Environment Management (P0)

**Architecture Compatibility:**
- **Extend:** `ExecutionContext` already has `server_url`, add `environment: str` field
- **New:** `~/.dli/environments.yaml` config file support
- **New:** `EnvAPI` class and `dli env` command group

**Effort Estimate:** 2 weeks - **Accurate**

**Integration with Existing Code:**
```python
# Extend models/common.py
class ExecutionContext(BaseSettings):
    environment: str | None = Field(
        default=None,
        description="Active environment name (dev/staging/prod)",
    )

# New: commands/env.py
env_app = typer.Typer(name="env", help="Environment management")

@env_app.command("use")
def use_env(name: str) -> None:
    """Switch active environment."""
    ...
```

**Consideration:** Should integrate with existing `DLI_SERVER_URL` environment variable fallback.

---

#### GAP-003: Debug Command (P0)

**Architecture Compatibility:**
- **Reusable:** `dli config status` logic in `commands/config.py`
- **Reusable:** `BasecampClient` connection check
- **New:** Engine connection diagnostics (BigQuery/Trino)

**Priority Recommendation:** P0 -> **P1**
- Useful but not blocking core workflows
- Debug is a developer convenience, not user-critical

**Effort Estimate:** 1 week - **Accurate**

---

#### GAP-004: Table/Schema Diff (P1)

**Architecture Compatibility:**
- **Dependency:** Requires GAP-002 (Environment Management) for cross-environment comparison
- **New:** `DiffAPI` class with engine-specific adapters
- **Complex:** Schema comparison needs catalog metadata from different environments

**Effort Adjustment:** 2 weeks -> **3-4 weeks**
- Engine-specific INFORMATION_SCHEMA queries
- Row sampling comparison requires careful handling
- Cross-environment authentication complexity

**Server Dependency:** Likely needs new Basecamp Server API endpoint for schema metadata.

---

#### GAP-005: Source Freshness (P1)

**Architecture Compatibility:**
- **New:** `SourceSpec` model in `core/models/`
- **New:** `SourceAPI` class
- **Extend:** Quality framework could be reused for freshness checks

**Effort Estimate:** 2 weeks - **Accurate**

**Pattern Reuse:**
```python
# Similar to existing QualitySpec pattern
class SourceSpec(BaseModel):
    metadata: SourceMetadata
    spec: SourceFreshnessConfig
```

---

#### GAP-006: Init/Scaffold (P1)

**Architecture Compatibility:**
- **New:** Template system in `core/templates/`
- **Simple:** File generation with Jinja2 (already a dependency)

**Priority Recommendation:** P1 -> **P0**
- Critical for new user onboarding
- Low effort, high impact on adoption

**Effort Estimate:** 1 week - **Accurate**

---

#### GAP-007: Retry Command (P1)

**Architecture Compatibility:**
- **New:** Run history persistence (`~/.dli/run_results/`)
- **Dependency:** Works with workflow and ad-hoc run commands
- **Integration:** Must track per-model success/failure state

**Effort Adjustment:** 1 week -> **2 weeks**
- State persistence adds complexity
- Need to handle partial failures in DAG execution

---

#### GAP-008: Snapshot (SCD Type 2) (P2)

**Architecture Compatibility:**
- **Major Feature:** New spec type, execution engine, history tracking
- **Dependency:** Requires stable engine adapters
- **Complexity:** SCD merge logic is engine-specific

**Effort Estimate:** 3 weeks - **Accurate, possibly optimistic**

**Recommendation:** Consider deferring to v1.0.0+ as it's a specialized feature.

---

#### GAP-009: Scheduled Queries (P2)

**Architecture Compatibility:**
- **Overlap:** Already have `dli workflow run/backfill/pause/unpause` commands
- **Concern:** Duplicates workflow functionality

**Recommendation:** **Merge with workflow** or clarify distinction:
- Scheduled Queries = ad-hoc SQL with cron
- Workflow = DAG-based orchestration

If merged, remove from roadmap as separate GAP.

---

#### GAP-010: Format Command (P2)

**Architecture Compatibility:**
- **Available:** `sqlglot` already in dependencies (`core/transpile/`)
- **Simple:** Wrap existing transpile engine

**Effort Estimate:** 1 week - **Accurate, possibly 3-5 days**

```python
# Can reuse: core/transpile/engine.py
from dli.core.transpile import TranspileEngine

def format_sql(sql: str, dialect: str = "trino", normalize: bool = False) -> str:
    engine = TranspileEngine()
    return engine.format(sql, read=dialect, write=dialect, normalize=normalize)
```

---

#### GAP-011: Secrets Management (P2)

**Architecture Compatibility:**
- **New:** `~/.dli/secrets` encrypted file or keyring integration
- **Platform-specific:** macOS Keychain, Windows Credential Manager, Linux Secret Service
- **Template:** `{{ secret('KEY') }}` function in Jinja context

**Effort Estimate:** 2 weeks - **Accurate**

**Security Consideration:** Should use `keyring` library for cross-platform support.

---

#### GAP-012: Clone Command (P2)

**Architecture Compatibility:**
- **Engine-specific:** BigQuery and Snowflake support zero-copy clone
- **Simple:** Wrapper around `CREATE TABLE ... CLONE` DDL

**Effort Estimate:** 1 week - **Accurate**

---

### 3. Recommended Priority Adjustments

| Gap | Original | Recommended | Rationale |
|-----|----------|-------------|-----------|
| GAP-003 Debug | P0 | P1 | Developer convenience, not blocking |
| GAP-006 Init | P1 | **P0** | Critical for onboarding, low effort |
| GAP-009 Scheduled | P2 | **Remove/Merge** | Overlaps with workflow commands |

**Revised P0 List:**
1. Selection Syntax (GAP-001) - Core usability
2. Environment Management (GAP-002) - Multi-env deployment
3. Init/Scaffold (GAP-006) - Onboarding critical

---

### 4. Code Reuse Opportunities

| Existing Code | Reusable For |
|---------------|--------------|
| `core/lineage/client.py` | GAP-001 Selection Syntax (graph traversal) |
| `core/transpile/engine.py` | GAP-010 Format Command |
| `core/quality/` framework | GAP-005 Source Freshness |
| `commands/config.py` status | GAP-003 Debug Command |
| `models/common.py` ExecutionContext | GAP-002 Environment Management |
| `commands/workflow.py` | GAP-009 Scheduled Queries (merge) |

---

### 5. Missing Considerations in Research

#### 5.1 Server API Dependencies

| Gap | Requires New Server API |
|-----|-------------------------|
| GAP-004 Table Diff | Schema metadata endpoint |
| GAP-005 Source Freshness | Source metadata queries |
| GAP-007 Retry | Run history API |
| GAP-008 Snapshot | Snapshot execution API |

**Impact:** Some features need coordinated server-side development.

#### 5.2 Engine-Specific Behavior

| Feature | BigQuery | Trino | Snowflake |
|---------|----------|-------|-----------|
| Zero-copy Clone | Yes | No | Yes |
| Table Diff | INFORMATION_SCHEMA | system.metadata | INFORMATION_SCHEMA |
| Source Freshness | MAX(_PARTITIONTIME) | Custom | LAST_ALTERED |

**Recommendation:** Abstract engine differences in `core/engines/` adapter layer.

#### 5.3 Migration Path

- **ExecutionContext changes:** Backward compatible (new fields have defaults)
- **Config file location:** `~/.dli/` is new; document migration from env vars
- **Selection Syntax:** Additive feature, no breaking changes

#### 5.4 Testing Strategy Not Addressed

- How to test cross-environment features (GAP-004 Diff)?
- Mock adapters needed for engine-specific features
- Integration test requirements for server-dependent features

#### 5.5 Documentation Effort

Add **1 week** to each phase for documentation:
- Command reference updates
- User guide sections
- Migration guides

---

### 6. Revised Implementation Roadmap

```
Phase 1: Foundation (5 weeks, not 4)
Week 1-2: Environment Management (GAP-002)
Week 3:   Init/Scaffold (GAP-006) + Debug (GAP-003)
Week 4-5: Selection Syntax (GAP-001) - Part 1
Week 6:   Selection Syntax (GAP-001) - Part 2 + Testing

Milestone: dli v0.7.0
- Multi-environment support
- Project scaffolding
- Basic selection syntax (+, @)
- Debug diagnostics

Phase 2: Data Operations (5 weeks, not 4)
Week 7-8:   Source Freshness (GAP-005)
Week 9-11:  Table/Schema Diff (GAP-004)
Week 12:    Retry Command (GAP-007)

Milestone: dli v0.8.0
- Source freshness monitoring
- Cross-environment diff
- Retry from failure

Phase 3: Advanced (6 weeks)
Week 13:    Format Command (GAP-010)
Week 14-15: Secrets Management (GAP-011)
Week 16-17: Snapshot (GAP-008) - Part 1
Week 18:    Snapshot (GAP-008) - Part 2 + Clone (GAP-012)

Milestone: dli v0.9.0
- SQL formatting
- Secrets management
- SCD Type 2 snapshots
```

---

### 7. Risk Assessment

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| Server API not ready | Medium | High | Decouple LOCAL mode features |
| Engine-specific bugs | High | Medium | Comprehensive mock testing |
| Selection syntax complexity | Medium | High | Iterative rollout (basic -> advanced) |
| Breaking changes | Low | High | Deprecation warnings, migration guides |

---

### 8. Conclusion

The research document provides solid industry analysis and identifies genuine gaps. Key adjustments recommended:

1. **Swap Debug (P0) with Init (P1)** - Init is more critical for adoption
2. **Merge Scheduled Queries with Workflow** - Avoid feature duplication
3. **Add 1 week per phase for testing/docs** - Estimates are code-only
4. **Plan server API development in parallel** - Several features need backend support
5. **Create engine adapter abstraction** - Enable consistent behavior across BigQuery/Trino/Snowflake

**Overall Assessment:** The roadmap is ambitious but achievable with the recommended adjustments. Prioritize features that work in LOCAL mode first to decouple from server development timeline.

---

**Review End**

---

## Design Decisions (사용자 인터뷰 결과)

> **Date:** 2026-01-01
> **Interview Method:** AskUserQuestion Tool

> **Note:** 아래 기능들은 별도의 FEATURE 문서로 이동되었습니다.

### Feature Specifications (Migrated)

| Feature | Document | Status |
|---------|----------|--------|
| Debug Command | [DEBUG_FEATURE.md](./DEBUG_FEATURE.md) | ✅ Specification Complete |
| Format Command | [FORMAT_FEATURE.md](./FORMAT_FEATURE.md) | ✅ Specification Complete |
| Environment Management | [ENV_FEATURE.md](./ENV_FEATURE.md) | ✅ Specification Complete |

---

### 4. 조정된 우선순위

| Gap ID | Feature | 기존 | 조정 | 사유 |
|--------|---------|:----:|:----:|------|
| GAP-001 | Selection Syntax | P0 | P0 | 유지 |
| GAP-002 | Environment Mgmt | P0 | P0 | 유지 (디렉토리 기반) |
| GAP-003 | Debug Command | P0 | **P1** | 하향 (편의 기능) |
| GAP-006 | Init/Scaffold | P1 | **P0** | 상향 (온보딩 필수) |
| GAP-010 | Format Command | P2 | **P1** | 상향 (리소스 기반 설계) |

---

### 5. 최종 P0 기능 목록

```
P0 (Critical - v0.7.0):
├── GAP-001: Selection Syntax (graph operators, tag selectors)
├── GAP-002: Environment Management (디렉토리 기반 분리)
└── GAP-006: Init/Scaffold Command (온보딩)

P1 (High - v0.8.0):
├── GAP-003: Debug Command (연결 진단)
├── GAP-004: Table/Schema Diff
├── GAP-005: Source Freshness
├── GAP-007: Retry from Failure
└── GAP-010: Format Command (리소스 기반)
```

---

**Document Complete**
