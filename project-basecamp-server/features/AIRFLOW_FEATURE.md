# Airflow Integration Feature Specification

> **Version:** 2.0.0 | **Status:** âœ… Implemented | **Priority:** P5 Airflow
> **Dependencies:** WORKFLOW_RELEASE.md (100% complete)
>
> **ğŸ“¦ Data Source:** Self-managed JPA (ìƒíƒœ ì €ì¥) + External API (Airflow REST API - Airflow 3 ê¸°ì¤€)
> **Entities:** `WorkflowEntity`, `WorkflowRunEntity`, `AirflowClusterEntity`

---

## 1. Overview

### 1.1 Purpose

Basecamp Serverì™€ Apache Airflow ì‹¤ì œ ì—°ë™ì„ í†µí•œ í”„ë¡œë•ì…˜ ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ êµ¬í˜„.

| ì¸¡ë©´ | í˜„ì¬ ìƒíƒœ | ëª©í‘œ ìƒíƒœ |
|------|-----------|-----------|
| **DAG ì‹¤í–‰** | MockAirflowClient (ë©”ëª¨ë¦¬ ì‹œë®¬ë ˆì´ì…˜) | Airflow REST API (Airflow 3 ê¸°ì¤€) ì‹¤ì œ í˜¸ì¶œ |
| **YAML ì €ì¥** | InMemoryWorkflowStorage | S3 (AWS SDK) ì‹¤ì œ ì €ì¥ + S3 Mock (ë¡œì»¬) |
| **Spec Sync** | ì—†ìŒ | S3ì—ì„œ Dataset Spec ì£¼ê¸°ì  Sync |
| **í´ëŸ¬ìŠ¤í„° ê´€ë¦¬** | ì—†ìŒ | íŒ€ë³„ Airflow Cluster ê´€ë¦¬ |

### 1.2 Deployment Architecture

**í•µì‹¬ ì›ì¹™:** Basecamp ServerëŠ” í™˜ê²½ë³„ë¡œ ë°°í¬ë˜ë¯€ë¡œ, ë™ì¼ í™˜ê²½ ë‚´ì—ì„œ íŒ€ë³„ Clusterë§Œ ê´€ë¦¬í•©ë‹ˆë‹¤.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Environment-based Deployment                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   DEV Environment                      PROD Environment                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚   â”‚  Basecamp Server    â”‚             â”‚  Basecamp Server    â”‚              â”‚
â”‚   â”‚  (DEV)              â”‚             â”‚  (PROD)             â”‚              â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚              â”‚                                   â”‚                          â”‚
â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚       â–¼             â–¼                     â–¼             â–¼                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚   â”‚Team A â”‚    â”‚Team B â”‚             â”‚Team A â”‚    â”‚Team B â”‚               â”‚
â”‚   â”‚Airflowâ”‚    â”‚Airflowâ”‚             â”‚Airflowâ”‚    â”‚Airflowâ”‚               â”‚
â”‚   â”‚(DEV)  â”‚    â”‚(DEV)  â”‚             â”‚(PROD) â”‚    â”‚(PROD) â”‚               â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.3 Scope

**In Scope:**
- `AirflowClient` ì‹¤ì œ êµ¬í˜„ (í˜„ì¬ `MockAirflowClient` â†’ `RestAirflowClient`)
- `WorkflowStorage` ì‹¤ì œ êµ¬í˜„ (í˜„ì¬ `InMemoryWorkflowStorage` â†’ `S3WorkflowStorage`)
- **S3 Spec Sync ì„œë¹„ìŠ¤** (í•µì‹¬ ê¸°ëŠ¥): S3ì—ì„œ Dataset Specì„ ì£¼ê¸°ì ìœ¼ë¡œ ê°€ì ¸ì™€ Workflow ë“±ë¡
- **S3 Mock** êµ¬í˜„ (ë¡œì»¬ ê°œë°œ í™˜ê²½ìš©)
- `AirflowClusterEntity` í†µí•© (GITHUB_FEATURE.mdì—ì„œ ì´ê´€)
- íŒ€ë³„ Airflow Cluster ì§€ì› (ë™ì¼ í™˜ê²½ ë‚´)

**Out of Scope:**
- ê¶Œí•œ/ë³´ì•ˆ ì²´ê³„ (Phase 2ì—ì„œ êµ¬í˜„)
- DAG ì½”ë“œ ìë™ ìƒì„± (ê¸°ì¡´ DAG íŒ¨í„´ í™œìš©)
- Airflow UI í†µí•©
- Cluster ë“±ë¡ API (ê´€ë¦¬ìê°€ DBë¡œ ì§ì ‘ ë“±ë¡)

---

## 2. System Architecture

### 2.1 Data Source Classification

| ë°ì´í„° ì†ŒìŠ¤ | íƒ€ì… | ê´€ë¦¬ ì£¼ì²´ | ì„¤ëª… |
|-------------|------|-----------|------|
| `WorkflowEntity` | Self-managed JPA | Basecamp Server | ì›Œí¬í”Œë¡œìš° ë“±ë¡/ìƒíƒœ ê´€ë¦¬ |
| `WorkflowRunEntity` | Self-managed JPA | Basecamp Server | ì‹¤í–‰ ì´ë ¥ ì¶”ì  |
| `AirflowClusterEntity` | Self-managed JPA | ê´€ë¦¬ì (DB ì§ì ‘) | íŒ€ë³„ í´ëŸ¬ìŠ¤í„° ì„¤ì • |
| Airflow DAG Runs | External API | Airflow | DAG ì‹¤í–‰ ìƒíƒœ (polling) |
| YAML Specs | External Storage | S3 | ì›Œí¬í”Œë¡œìš° ì •ì˜ íŒŒì¼ |

### 2.2 High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              Data Flow                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚   â”‚  dli    â”‚ â”€â”€â”€â”€â”€â”€â–º â”‚  Basecamp Server â”‚ â”€â”€â”€â”€â”€â”€â–º â”‚    Airflow      â”‚      â”‚
â”‚   â”‚  CLI    â”‚         â”‚                  â”‚         â”‚   (Teamë³„)      â”‚      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                       â”‚  â”‚ Workflow   â”‚  â”‚                  â”‚               â”‚
â”‚                       â”‚  â”‚ Service    â”‚  â”‚                  â”‚               â”‚
â”‚                       â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚                  â”‚               â”‚
â”‚                       â”‚         â”‚        â”‚                  â”‚               â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”  â”‚                  â–¼               â”‚
â”‚   â”‚  S3     â”‚ â—„â”€â”€â”€â”€â”€â–º â”‚  â”‚ S3 Sync    â”‚  â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚   â”‚ Bucket  â”‚  Sync   â”‚  â”‚ Scheduler  â”‚  â”‚          â”‚  S3 (DAGs)    â”‚       â”‚
â”‚   â”‚(Specs)  â”‚         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚          â”‚  manual/      â”‚       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  code/        â”‚       â”‚
â”‚                                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.3 S3 Spec Sync Workflow (í•µì‹¬ ê¸°ëŠ¥)

```mermaid
sequenceDiagram
    participant Scheduler as S3 Sync Scheduler
    participant S3 as S3 Bucket
    participant Service as WorkflowSyncService
    participant DB as Database
    participant Airflow as Airflow Cluster

    Note over Scheduler,Airflow: Periodic S3 Sync (Configurable Interval)

    Scheduler->>S3: List YAML files (*.yaml, *.yml)
    S3-->>Scheduler: File list with LastModified

    loop For each YAML file
        Scheduler->>S3: Get YAML content
        S3-->>Scheduler: YAML content
        Scheduler->>Service: Parse & Validate Spec
        Service->>DB: Find existing Workflow
        alt Workflow exists
            Service->>DB: Update (S3 ìš°ì„  ë®ì–´ì“°ê¸°)
        else New Workflow
            Service->>DB: Create new Workflow
        end
        Service->>Airflow: Sync DAG status
    end
```

### 2.4 DAG Deployment Workflow

```mermaid
sequenceDiagram
    participant DA as DA/DAE (Local)
    participant Git as GitHub
    participant S3 as S3 Bucket
    participant Server as Basecamp Server
    participant Airflow as Airflow

    Note over DA,Airflow: CODE Workflow (Git-based)
    DA->>Git: Push to develop
    Git->>S3: CI/CD â†’ s3://bucket/workflows/code/
    S3->>Airflow: DAG Sync (S3 ì£¼ê¸°ì  sync)
    S3->>Server: S3 Sync Schedulerê°€ Spec ê°ì§€
    Server->>Server: Workflow ë“±ë¡/ì—…ë°ì´íŠ¸

    Note over DA,Airflow: MANUAL Workflow (API-based)
    DA->>DA: dli workflow register
    DA->>Server: POST /api/v1/workflows/register
    Server->>S3: Save YAML to s3://bucket/workflows/manual/
    S3->>Airflow: DAG Sync
```

---

## 3. Domain Model (GITHUB_FEATURE.mdì—ì„œ ì´ê´€)

### 3.1 AirflowClusterEntity

```kotlin
@Entity
@Table(
    name = "airflow_clusters",
    indexes = [
        Index(name = "idx_airflow_cluster_team", columnList = "team", unique = true),
        Index(name = "idx_airflow_cluster_env", columnList = "environment"),
        Index(name = "idx_airflow_cluster_active", columnList = "is_active"),
    ],
)
class AirflowClusterEntity(
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    val id: Long = 0,

    // íŒ€ ì‹ë³„ì - ë™ì¼ í™˜ê²½ ë‚´ íŒ€ë³„ 1ê°œ í´ëŸ¬ìŠ¤í„° (UNIQUE)
    @Column(nullable = false, length = 255, unique = true)
    val team: String,

    @Column(nullable = false, length = 100)
    val clusterName: String,

    @Column(nullable = false, length = 500)
    val airflowUrl: String,

    // í™˜ê²½ ì •ë³´ (ê´€ë¦¬/ë©”íƒ€ë°ì´í„° ëª©ì , ë¼ìš°íŒ…ì—ëŠ” ë¯¸ì‚¬ìš©)
    @Enumerated(EnumType.STRING)
    @Column(nullable = false, length = 50)
    val environment: AirflowEnvironment,

    @Column(nullable = false, length = 500)
    val dagS3Path: String,

    @Column(nullable = false, length = 200)
    val dagNamePrefix: String,

    @Column(nullable = false)
    val isActive: Boolean = true,

    // Airflow 3 JWT Token (API Key) ì¸ì¦
    @Column(nullable = false, length = 500)
    val apiKey: String,

    @Column(length = 1000)
    val description: String? = null,
) : BaseAuditableEntity()

enum class AirflowEnvironment {
    DEVELOPMENT, PRODUCTION
}
```

### 3.2 Database Schema

```sql
-- Airflow Clusters Table
CREATE TABLE airflow_clusters (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    team VARCHAR(255) NOT NULL,
    cluster_name VARCHAR(100) NOT NULL,
    airflow_url VARCHAR(500) NOT NULL,
    environment VARCHAR(50) NOT NULL,
    dag_s3_path VARCHAR(500) NOT NULL,
    dag_name_prefix VARCHAR(200) NOT NULL,
    is_active BOOLEAN NOT NULL DEFAULT TRUE,
    api_key VARCHAR(500) NOT NULL,
    description VARCHAR(1000),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    created_by BIGINT,  -- BaseAuditableEntity íŒ¨í„´ê³¼ ì¼ì¹˜ (User ID)
    updated_by BIGINT,  -- BaseAuditableEntity íŒ¨í„´ê³¼ ì¼ì¹˜ (User ID)

    UNIQUE KEY uk_airflow_cluster_team (team),
    INDEX idx_airflow_cluster_env (environment),
    INDEX idx_airflow_cluster_active (is_active),
    INDEX idx_airflow_cluster_name (cluster_name)
);
```

### 3.3 Repository Layer

```kotlin
// Domain Interface (module-core-domain)
interface AirflowClusterRepositoryJpa {
    fun save(cluster: AirflowClusterEntity): AirflowClusterEntity
    fun findById(id: Long): AirflowClusterEntity?
    fun findByTeam(team: String): AirflowClusterEntity?
    fun findAllActive(): List<AirflowClusterEntity>
    fun deleteById(id: Long)
}

interface AirflowClusterRepositoryDsl {
    fun findByAirflowUrl(url: String): AirflowClusterEntity?
    fun findByClusterName(name: String): List<AirflowClusterEntity>
}

// Infrastructure Implementation (module-core-infra)
@Repository("airflowClusterRepositoryJpa")
class AirflowClusterRepositoryJpaImpl(
    private val springDataRepository: AirflowClusterRepositoryJpaSpringData,
) : AirflowClusterRepositoryJpa {
    override fun findByTeam(team: String): AirflowClusterEntity? =
        springDataRepository.findByTeamAndIsActiveTrue(team)
    // ... ê¸°íƒ€ ë©”ì„œë“œ êµ¬í˜„
}
```

---

## 4. S3 Sync Service (í•µì‹¬ ê¸°ëŠ¥)

### 4.1 WorkflowSyncService

```kotlin
@Service
class WorkflowSyncService(
    private val workflowStorage: WorkflowStorage,
    private val workflowService: WorkflowService,
    private val yamlParser: WorkflowYamlParser,
) {
    private val log = LoggerFactory.getLogger(javaClass)

    /**
     * S3ì—ì„œ ëª¨ë“  YAML Specì„ ê°€ì ¸ì™€ Workflowë¡œ ë™ê¸°í™”
     * - S3 ìš°ì„  ì •ì±…: ê¸°ì¡´ Workflowê°€ ìˆìœ¼ë©´ ë®ì–´ì“°ê¸°
     */
    @Transactional
    fun syncFromS3(): SyncResult {
        val specs = workflowStorage.listAllSpecs()
        var created = 0
        var updated = 0
        var failed = 0
        val errors = mutableListOf<SyncError>()

        specs.forEach { specPath ->
            try {
                val yamlContent = workflowStorage.getWorkflowYaml(specPath)
                val spec = yamlParser.parse(yamlContent)

                val existing = workflowService.findByDatasetName(spec.datasetName)
                if (existing != null) {
                    workflowService.updateFromSpec(existing.id, spec, specPath)
                    updated++
                    log.info("Updated workflow: {} from {}", spec.datasetName, specPath)
                } else {
                    workflowService.createFromSpec(spec, specPath)
                    created++
                    log.info("Created workflow: {} from {}", spec.datasetName, specPath)
                }
            } catch (e: Exception) {
                failed++
                errors.add(SyncError(specPath, e.message ?: "Unknown error"))
                log.error("Failed to sync spec: {}", specPath, e)
            }
        }

        return SyncResult(
            totalProcessed = specs.size,
            created = created,
            updated = updated,
            failed = failed,
            errors = errors,
            syncedAt = Instant.now()
        )
    }
}

data class SyncResult(
    val totalProcessed: Int,
    val created: Int,
    val updated: Int,
    val failed: Int,
    val errors: List<SyncError>,
    val syncedAt: Instant
)

data class SyncError(
    val specPath: String,
    val message: String
)
```

### 4.2 S3 Sync Scheduler

```kotlin
@Component
@ConditionalOnProperty("basecamp.workflow.sync.enabled", havingValue = "true")
class WorkflowSyncScheduler(
    private val syncService: WorkflowSyncService,
    @Value("\${basecamp.workflow.sync.cron:0 */5 * * * *}") private val cronExpression: String,
) {
    private val log = LoggerFactory.getLogger(javaClass)

    @Scheduled(cron = "\${basecamp.workflow.sync.cron:0 */5 * * * *}")
    fun scheduledSync() {
        log.info("Starting scheduled S3 sync...")
        try {
            val result = syncService.syncFromS3()
            log.info("S3 sync completed: created={}, updated={}, failed={}",
                result.created, result.updated, result.failed)
        } catch (e: Exception) {
            log.error("S3 sync failed", e)
        }
    }
}
```

### 4.3 Manual Sync API

```kotlin
@RestController
@RequestMapping("/api/v1/admin/sync")
class SyncController(
    private val syncService: WorkflowSyncService,
) {
    /**
     * ìˆ˜ë™ S3 Sync íŠ¸ë¦¬ê±° (ê´€ë¦¬ììš©)
     */
    @PostMapping("/workflows")
    fun triggerSync(): ResponseEntity<SyncResult> {
        val result = syncService.syncFromS3()
        return ResponseEntity.ok(result)
    }
}
```

---

## 5. DAG Run Sync Service (Airflow ìƒíƒœ ë™ê¸°í™”)

### 5.1 Overview

Workflow APIì˜ GET ì—”ë“œí¬ì¸íŠ¸(run/history/status)ê°€ Airflowì˜ ì‹¤ì œ ì‹¤í–‰ ë°ì´í„°ë¥¼ ë°˜í™˜í•˜ë„ë¡ ì£¼ê¸°ì ìœ¼ë¡œ Airflow í´ëŸ¬ìŠ¤í„°ì—ì„œ DAG Run ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ ë¡œì»¬ DBì— ì €ì¥í•©ë‹ˆë‹¤.

**ì„¤ê³„ ê·¼ê±°:**
- ë‹¤ìˆ˜ì˜ Airflow í´ëŸ¬ìŠ¤í„°ê°€ ì¡´ì¬í•˜ë¯€ë¡œ ì‹¤ì‹œê°„ API í˜¸ì¶œ ì‹œ ì§€ì—° ë°œìƒ
- Airflow í´ëŸ¬ìŠ¤í„° ì¥ì•  ì‹œì—ë„ ìºì‹œëœ ë°ì´í„°ë¡œ ì„œë¹„ìŠ¤ ì§€ì† ê°€ëŠ¥
- DB ì¡°íšŒê°€ ì™¸ë¶€ API í˜¸ì¶œë³´ë‹¤ ë¹ ë¥´ê³  ì•ˆì •ì 

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DAG Run Sync Flow                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚   Airflow Clusters          Basecamp Server                    CLI/API      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚ Team A       â”‚         â”‚                 â”‚              â”‚          â”‚   â”‚
â”‚   â”‚ Airflow      â”‚â—„â”€â”€â”€â”€â”€â”€â–º â”‚  AirflowRun     â”‚              â”‚  dli     â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  Sync   â”‚  SyncService    â”‚              â”‚ workflow â”‚   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚                 â”‚              â”‚  status  â”‚   â”‚
â”‚   â”‚ Team B       â”‚â—„â”€â”€â”€â”€â”€â”€â–º â”‚       â†“         â”‚              â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â”‚
â”‚   â”‚ Airflow      â”‚         â”‚                 â”‚                   â”‚         â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  WorkflowRun    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                            â”‚  Entity (DB)    â”‚    Query (DB, not Airflow)  â”‚
â”‚                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 WorkflowRunEntity í™•ì¥

```kotlin
// ê¸°ì¡´ í•„ë“œì— Airflow ì—°ë™ìš© í•„ë“œ ì¶”ê°€
@Entity
@Table(name = "workflow_runs")
class WorkflowRunEntity(
    // ... ê¸°ì¡´ í•„ë“œ ìœ ì§€ ...

    // === Airflow ì—°ë™ í•„ë“œ (ì‹ ê·œ) ===

    /**
     * Airflowì˜ ì‹¤ì œ DAG Run ID
     * í˜•ì‹: {dag_id}__{logical_date} (Airflow ê¸°ë³¸ íŒ¨í„´)
     */
    @Column(name = "airflow_dag_run_id", length = 255)
    var airflowDagRunId: String? = null,

    /**
     * Airflowì˜ ì›ë³¸ ìƒíƒœê°’ (queued, running, success, failed ë“±)
     */
    @Column(name = "airflow_state", length = 50)
    var airflowState: String? = null,

    /**
     * Airflow UIì—ì„œ í•´ë‹¹ Runì„ ë³¼ ìˆ˜ ìˆëŠ” URL
     */
    @Column(name = "airflow_url", length = 1000)
    var airflowUrl: String? = null,

    /**
     * ë§ˆì§€ë§‰ìœ¼ë¡œ Airflowì—ì„œ ë™ê¸°í™”ëœ ì‹œê°„
     */
    @Column(name = "last_synced_at")
    var lastSyncedAt: LocalDateTime? = null,

    /**
     * Airflow í´ëŸ¬ìŠ¤í„° ID (ì–´ëŠ í´ëŸ¬ìŠ¤í„°ì—ì„œ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€)
     */
    @Column(name = "airflow_cluster_id")
    var airflowClusterId: Long? = null,

    /**
     * Task ì§„í–‰ ìƒí™© (JSON)
     * {"total": 10, "completed": 5, "failed": 0, "running": 2}
     */
    @Column(name = "task_progress", columnDefinition = "TEXT")
    var taskProgress: String? = null,
) : BaseEntity() {

    /**
     * Airflow ìƒíƒœë¡œ ì—…ë°ì´íŠ¸
     */
    fun updateFromAirflow(
        airflowState: String,
        airflowUrl: String?,
        taskProgress: String?,
        startedAt: LocalDateTime?,
        endedAt: LocalDateTime?,
    ) {
        this.airflowState = airflowState
        this.airflowUrl = airflowUrl
        this.taskProgress = taskProgress
        this.lastSyncedAt = LocalDateTime.now()

        // Airflow ìƒíƒœ â†’ ë‚´ë¶€ ìƒíƒœ ë§¤í•‘
        this.status = mapAirflowState(airflowState)

        // ì‹œê°„ ì—…ë°ì´íŠ¸ (Airflow ë°ì´í„° ìš°ì„ )
        if (startedAt != null && this.startedAt == null) {
            this.startedAt = startedAt
        }
        if (endedAt != null && this.endedAt == null) {
            this.endedAt = endedAt
        }
    }

    private fun mapAirflowState(state: String): WorkflowRunStatus {
        return when (state.lowercase()) {
            "queued" -> WorkflowRunStatus.PENDING
            "running", "restarting" -> WorkflowRunStatus.RUNNING
            "success" -> WorkflowRunStatus.SUCCESS
            "failed", "upstream_failed" -> WorkflowRunStatus.FAILED
            "skipped" -> WorkflowRunStatus.SKIPPED
            else -> WorkflowRunStatus.UNKNOWN
        }
    }
}

// âš ï¸ WorkflowRunStatus Enum í™•ì¥ í•„ìš” (module-core-domain/model/workflow/WorkflowEnums.kt)
// ê¸°ì¡´ enumì— SKIPPED, UNKNOWN ì¶”ê°€:
// enum class WorkflowRunStatus {
//     PENDING, RUNNING, SUCCESS, FAILED, STOPPING, STOPPED, SKIPPED, UNKNOWN
// }
```

### 5.3 Database Schema í™•ì¥

```sql
-- WorkflowRunEntity í…Œì´ë¸”ì— Airflow ì—°ë™ ì»¬ëŸ¼ ì¶”ê°€
ALTER TABLE workflow_runs ADD COLUMN airflow_dag_run_id VARCHAR(255);
ALTER TABLE workflow_runs ADD COLUMN airflow_state VARCHAR(50);
ALTER TABLE workflow_runs ADD COLUMN airflow_url VARCHAR(1000);
ALTER TABLE workflow_runs ADD COLUMN last_synced_at TIMESTAMP;
ALTER TABLE workflow_runs ADD COLUMN airflow_cluster_id BIGINT;
ALTER TABLE workflow_runs ADD COLUMN task_progress TEXT;

-- ì¸ë±ìŠ¤ ì¶”ê°€
CREATE INDEX idx_workflow_runs_airflow_dag_run_id ON workflow_runs(airflow_dag_run_id);
CREATE INDEX idx_workflow_runs_last_synced_at ON workflow_runs(last_synced_at);
CREATE INDEX idx_workflow_runs_airflow_cluster_id ON workflow_runs(airflow_cluster_id);
```

### 5.4 Repository Interface í™•ì¥

```kotlin
// module-core-domain/repository/WorkflowRunRepositoryJpa.kt í™•ì¥
interface WorkflowRunRepositoryJpa {
    // ... ê¸°ì¡´ ë©”ì„œë“œ ...

    /**
     * Airflow DAG Run IDë¡œ ì¡°íšŒ (ë™ê¸°í™”ìš©)
     */
    fun findByAirflowDagRunId(dagRunId: String): WorkflowRunEntity?
}

// module-core-domain/repository/WorkflowRunRepositoryDsl.kt í™•ì¥
interface WorkflowRunRepositoryDsl {
    // ... ê¸°ì¡´ ë©”ì„œë“œ ...

    /**
     * íŠ¹ì • í´ëŸ¬ìŠ¤í„°ì˜ ì§„í–‰ ì¤‘ì¸ Run ì¡°íšŒ (ë™ê¸°í™”ìš©)
     * @param clusterId Airflow í´ëŸ¬ìŠ¤í„° ID
     * @param since ì¡°íšŒ ì‹œì‘ ì‹œì 
     */
    fun findPendingRunsByCluster(
        clusterId: Long,
        since: LocalDateTime
    ): List<WorkflowRunEntity>
}
```

### 5.5 AirflowService

```kotlin
@Service
class AirflowService(
    private val airflowClient: AirflowClient,
    private val clusterRepository: AirflowClusterRepositoryJpa,
    private val workflowRunRepositoryJpa: WorkflowRunRepositoryJpa,
    private val workflowRunRepositoryDsl: WorkflowRunRepositoryDsl,
    private val objectMapper: ObjectMapper,  // Jackson ObjectMapper
    @Value("\${basecamp.workflow.run-sync.lookback-hours:24}") private val lookbackHours: Int,
    @Value("\${basecamp.workflow.run-sync.batch-size:100}") private val batchSize: Int,
    @Value("\${basecamp.workflow.run-sync.stale-threshold-hours:1}") private val staleThresholdHours: Int,
) {
    private val log = LoggerFactory.getLogger(javaClass)

    /**
     * ëª¨ë“  í™œì„± Airflow í´ëŸ¬ìŠ¤í„°ì—ì„œ DAG Run ë°ì´í„° ë™ê¸°í™”
     */
    @Transactional
    fun syncAllClusters(): RunSyncResult {
        val clusters = clusterRepository.findAllActive()
        val results = mutableListOf<ClusterSyncResult>()

        clusters.forEach { cluster ->
            try {
                val clusterResult = syncClusterInternal(cluster)
                results.add(clusterResult)
                log.info("Synced cluster {}: {} runs updated", cluster.clusterName, clusterResult.updatedCount)
            } catch (e: Exception) {
                log.error("Failed to sync cluster {}: {}", cluster.clusterName, e.message)
                results.add(ClusterSyncResult(cluster.clusterName, 0, 0, e.message))
            }
        }

        return RunSyncResult(
            totalClusters = clusters.size,
            clusterResults = results,
            syncedAt = Instant.now()
        )
    }

    /**
     * íŠ¹ì • í´ëŸ¬ìŠ¤í„°ì˜ DAG Run ë°ì´í„° ë™ê¸°í™” (í´ëŸ¬ìŠ¤í„° IDë¡œ)
     * Admin APIì—ì„œ ì‚¬ìš©
     */
    fun syncCluster(clusterId: Long): ClusterSyncResult {
        val cluster = clusterRepository.findById(clusterId)
            ?: return ClusterSyncResult("unknown", 0, 0, "Cluster not found: $clusterId")
        return syncClusterInternal(cluster)
    }

    /**
     * íŠ¹ì • í´ëŸ¬ìŠ¤í„°ì˜ DAG Run ë°ì´í„° ë™ê¸°í™” (ë‚´ë¶€ìš©)
     */
    private fun syncClusterInternal(cluster: AirflowClusterEntity): ClusterSyncResult {
        val cutoffTime = LocalDateTime.now().minusHours(lookbackHours.toLong())
        var updatedCount = 0
        var createdCount = 0

        // 1. í•´ë‹¹ í´ëŸ¬ìŠ¤í„°ì— ì†í•œ ì§„í–‰ ì¤‘ì¸ Run ì¡°íšŒ (DB)
        val pendingRuns = workflowRunRepositoryDsl.findPendingRunsByCluster(
            clusterId = cluster.id,
            since = cutoffTime
        )

        // 2. Airflowì—ì„œ ìµœê·¼ DAG Run ëª©ë¡ ì¡°íšŒ
        val dagRuns = airflowClient.listRecentDagRuns(
            since = cutoffTime,
            limit = batchSize
        )

        // 3. ê° DAG Runì— ëŒ€í•´ ë¡œì»¬ ë°ì´í„° ì—…ë°ì´íŠ¸
        dagRuns.forEach { airflowRun ->
            val existing = workflowRunRepositoryJpa.findByAirflowDagRunId(airflowRun.dagRunId)

            if (existing != null) {
                // ê¸°ì¡´ Run ì—…ë°ì´íŠ¸
                existing.updateFromAirflow(
                    airflowState = airflowRun.state,
                    airflowUrl = buildAirflowUrl(cluster, airflowRun),
                    taskProgress = fetchTaskProgress(airflowRun),
                    startedAt = airflowRun.startDate,
                    endedAt = airflowRun.endDate
                )
                workflowRunRepositoryJpa.save(existing)
                updatedCount++
            } else {
                // Basecampì—ì„œ íŠ¸ë¦¬ê±°ë˜ì§€ ì•Šì€ Run (ì™¸ë¶€ íŠ¸ë¦¬ê±°)ì€ ìŠ¤í‚µ ë˜ëŠ” ìƒì„±
                // ì •ì±…ì— ë”°ë¼ ê²°ì • (í˜„ì¬ëŠ” ìŠ¤í‚µ)
                log.debug("Skipping external run: {}", airflowRun.dagRunId)
            }
        }

        // 4. DBì—ëŠ” ìˆì§€ë§Œ Airflowì—ì„œ ì™„ë£Œëœ Run í™•ì¸ (ì˜¤ë˜ëœ Pending ìƒíƒœ ì •ë¦¬)
        pendingRuns.filter { run ->
            dagRuns.none { it.dagRunId == run.airflowDagRunId }
        }.forEach { staleRun ->
            // Airflowì—ì„œ ì¡°íšŒë˜ì§€ ì•ŠëŠ” ì˜¤ë˜ëœ Pending ìƒíƒœ ì²˜ë¦¬
            if (staleRun.startedAt?.isBefore(cutoffTime.minusHours(staleThresholdHours.toLong())) == true) {
                log.warn("Marking stale run as unknown: {}", staleRun.runId)
                staleRun.status = WorkflowRunStatus.UNKNOWN
                staleRun.lastSyncedAt = LocalDateTime.now()
                workflowRunRepositoryJpa.save(staleRun)
            }
        }

        return ClusterSyncResult(cluster.clusterName, updatedCount, createdCount, null)
    }

    private fun buildAirflowUrl(cluster: AirflowClusterEntity, run: AirflowDagRun): String {
        return "${cluster.airflowUrl}/dags/${run.dagId}/grid?dag_run_id=${run.dagRunId}"
    }

    private fun fetchTaskProgress(run: AirflowDagRun): String? {
        // Task Instance ì¡°íšŒí•˜ì—¬ ì§„í–‰ ìƒí™© ìƒì„±
        return try {
            val instances = airflowClient.getTaskInstances(run.dagId, run.dagRunId)
            val progress = TaskProgress(
                total = instances.size,
                completed = instances.count { it.state == "success" },
                failed = instances.count { it.state == "failed" },
                running = instances.count { it.state == "running" }
            )
            objectMapper.writeValueAsString(progress)
        } catch (e: Exception) {
            log.warn("Failed to fetch task progress for {}: {}", run.dagRunId, e.message)
            null
        }
    }
}

data class RunSyncResult(
    val totalClusters: Int,
    val clusterResults: List<ClusterSyncResult>,
    val syncedAt: Instant
)

data class ClusterSyncResult(
    val clusterName: String,
    val updatedCount: Int,
    val createdCount: Int,
    val error: String?
)

data class TaskProgress(
    val total: Int,
    val completed: Int,
    val failed: Int,
    val running: Int
)
```

### 5.6 AirflowSyncScheduler

```kotlin
@Component
@ConditionalOnProperty("basecamp.workflow.run-sync.enabled", havingValue = "true")
class AirflowSyncScheduler(
    private val syncService: AirflowService,
) {
    private val log = LoggerFactory.getLogger(javaClass)

    @Scheduled(cron = "\${basecamp.workflow.run-sync.cron:0 */2 * * * *}")
    fun scheduledSync() {
        log.info("Starting scheduled DAG Run sync...")
        try {
            val result = syncService.syncAllClusters()
            val totalUpdated = result.clusterResults.sumOf { it.updatedCount }
            log.info("DAG Run sync completed: {} clusters, {} runs updated",
                result.totalClusters, totalUpdated)
        } catch (e: Exception) {
            log.error("DAG Run sync failed", e)
        }
    }
}
```

### 5.7 AirflowClient ì¸í„°í˜ì´ìŠ¤ í™•ì¥

> **Note:** ì´ ë©”ì„œë“œë“¤ì€ Â§6.4 `AirflowClient` ì¸í„°í˜ì´ìŠ¤ì— ì¶”ê°€ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

```kotlin
// AirflowClient ì¸í„°í˜ì´ìŠ¤ì— ì¶”ê°€í•  ë©”ì„œë“œ
interface AirflowClient {
    // ... ê¸°ì¡´ ë©”ì„œë“œ ...

    /**
     * ìµœê·¼ DAG Run ëª©ë¡ ì¡°íšŒ (ë™ê¸°í™”ìš©)
     */
    fun listRecentDagRuns(since: LocalDateTime, limit: Int = 100): List<AirflowDagRun>

    /**
     * íŠ¹ì • DAG Runì˜ Task Instance ëª©ë¡ ì¡°íšŒ
     */
    fun getTaskInstances(dagId: String, dagRunId: String): List<AirflowTaskInstance>
}

data class AirflowDagRun(
    val dagId: String,
    val dagRunId: String,
    val state: String,
    val logicalDate: LocalDateTime?,
    val startDate: LocalDateTime?,
    val endDate: LocalDateTime?,
    val conf: Map<String, Any>?
)

data class AirflowTaskInstance(
    val taskId: String,
    val state: String,
    val startDate: LocalDateTime?,
    val endDate: LocalDateTime?,
    val tryNumber: Int
)
```

### 5.8 Manual Sync API

```kotlin
@RestController
@RequestMapping("/api/v1/admin/sync")
class SyncController(
    private val workflowSyncService: WorkflowSyncService,
    private val runSyncService: AirflowService,  // ì¶”ê°€
) {
    /**
     * ìˆ˜ë™ S3 Spec Sync íŠ¸ë¦¬ê±°
     */
    @PostMapping("/workflows")
    fun triggerWorkflowSync(): ResponseEntity<SyncResult> {
        val result = workflowSyncService.syncFromS3()
        return ResponseEntity.ok(result)
    }

    /**
     * ìˆ˜ë™ DAG Run Sync íŠ¸ë¦¬ê±° (ì‹ ê·œ)
     */
    @PostMapping("/runs")
    fun triggerRunSync(): ResponseEntity<RunSyncResult> {
        val result = runSyncService.syncAllClusters()
        return ResponseEntity.ok(result)
    }

    /**
     * íŠ¹ì • í´ëŸ¬ìŠ¤í„°ì˜ DAG Run Sync íŠ¸ë¦¬ê±°
     */
    @PostMapping("/runs/cluster/{clusterId}")
    fun triggerClusterRunSync(@PathVariable clusterId: Long): ResponseEntity<ClusterSyncResult> {
        val result = runSyncService.syncCluster(clusterId)
        return ResponseEntity.ok(result)
    }
}
```

### 5.9 Configuration

```yaml
# application.yml
basecamp:
  workflow:
    # ... ê¸°ì¡´ ì„¤ì • ...

    run-sync:
      enabled: true
      cron: "0 */2 * * * *"        # 2ë¶„ë§ˆë‹¤ (ì¡°ì • ê°€ëŠ¥)
      lookback-hours: 24            # ìµœê·¼ 24ì‹œê°„ ë°ì´í„° ì¡°íšŒ
      batch-size: 100               # í´ëŸ¬ìŠ¤í„°ë‹¹ ìµœëŒ€ ì¡°íšŒ ê±´ìˆ˜
      stale-threshold-hours: 1      # Stale run íŒì • ê¸°ì¤€ ì‹œê°„

# ë¡œì»¬ ê°œë°œ í™˜ê²½
---
spring:
  config:
    activate:
      on-profile: local

basecamp:
  workflow:
    run-sync:
      enabled: false  # Mock í™˜ê²½ì—ì„œëŠ” ë¹„í™œì„±í™”

# í”„ë¡œë•ì…˜ í™˜ê²½
---
spring:
  config:
    activate:
      on-profile: prod

basecamp:
  workflow:
    run-sync:
      enabled: true
      cron: "0 */1 * * * *"        # 1ë¶„ë§ˆë‹¤ (ë” ë¹ˆë²ˆí•˜ê²Œ)
      lookback-hours: 48            # 48ì‹œê°„
      stale-threshold-hours: 2      # PRODëŠ” ë” ë„‰ë„‰í•˜ê²Œ
```

---

## 6. Integration Components

### 6.1 WorkflowStorage Interface (Domain Port)

```kotlin
// module-core-domain/src/main/kotlin/.../external/WorkflowStorage.kt
interface WorkflowStorage {
    fun saveWorkflowYaml(datasetName: String, sourceType: WorkflowSourceType, yamlContent: String): String
    fun getWorkflowYaml(s3Path: String): String
    fun deleteWorkflowYaml(s3Path: String): Boolean
    fun existsWorkflowYaml(s3Path: String): Boolean
    fun listAllSpecs(): List<String>  // S3 Syncìš©
    fun listSpecsByPrefix(prefix: String): List<String>  // ë””ë ‰í† ë¦¬ë³„ ì¡°íšŒ
}
```

### 6.2 S3WorkflowStorage (Infrastructure Adapter)

```kotlin
@Repository("workflowStorage")
@ConditionalOnProperty("basecamp.workflow.storage.type", havingValue = "s3")
class S3WorkflowStorage(
    private val s3Client: S3Client,
    @Value("\${basecamp.workflow.storage.bucket}") private val bucket: String,
    @Value("\${basecamp.workflow.storage.prefix:workflows}") private val prefix: String,
) : WorkflowStorage {

    override fun listAllSpecs(): List<String> {
        val request = ListObjectsV2Request.builder()
            .bucket(bucket)
            .prefix(prefix)
            .build()

        return s3Client.listObjectsV2(request)
            .contents()
            .filter { it.key().endsWith(".yaml") || it.key().endsWith(".yml") }
            .map { "s3://$bucket/${it.key()}" }
    }

    override fun saveWorkflowYaml(
        datasetName: String,
        sourceType: WorkflowSourceType,
        yamlContent: String
    ): String {
        val key = generateKey(datasetName, sourceType)
        val s3Path = "s3://$bucket/$key"

        s3Client.putObject(
            PutObjectRequest.builder()
                .bucket(bucket)
                .key(key)
                .contentType("text/yaml")
                .build(),
            RequestBody.fromString(yamlContent)
        )

        log.info("Saved workflow YAML to S3: {}", s3Path)
        return s3Path
    }

    override fun getWorkflowYaml(s3Path: String): String {
        val (bucket, key) = parseS3Path(s3Path)
        return s3Client.getObjectAsBytes(
            GetObjectRequest.builder()
                .bucket(bucket)
                .key(key)
                .build()
        ).asUtf8String()
    }

    // ... ê¸°íƒ€ ë©”ì„œë“œ êµ¬í˜„
}
```

### 6.3 MockS3WorkflowStorage (ë¡œì»¬ ê°œë°œìš©)

```kotlin
@Repository("workflowStorage")
@ConditionalOnProperty("basecamp.workflow.storage.type", havingValue = "mock", matchIfMissing = true)
class MockS3WorkflowStorage(
    @Value("\${basecamp.workflow.storage.mock-dir:./mock-s3}") private val mockDir: String,
) : WorkflowStorage {

    private val log = LoggerFactory.getLogger(javaClass)
    private val basePath: Path by lazy { Path.of(mockDir).also { Files.createDirectories(it) } }

    override fun listAllSpecs(): List<String> {
        return Files.walk(basePath)
            .filter { Files.isRegularFile(it) }
            .filter { it.fileName.toString().endsWith(".yaml") || it.fileName.toString().endsWith(".yml") }
            .map { "mock-s3://${it.toAbsolutePath()}" }
            .toList()
    }

    override fun saveWorkflowYaml(
        datasetName: String,
        sourceType: WorkflowSourceType,
        yamlContent: String
    ): String {
        val subDir = if (sourceType == WorkflowSourceType.MANUAL) "manual" else "code"
        val filePath = basePath.resolve(subDir).resolve("$datasetName.yaml")
        Files.createDirectories(filePath.parent)
        Files.writeString(filePath, yamlContent)
        val mockPath = "mock-s3://${filePath.toAbsolutePath()}"
        log.info("Saved workflow YAML to mock S3: {}", mockPath)
        return mockPath
    }

    override fun getWorkflowYaml(s3Path: String): String {
        val path = parseMockPath(s3Path)
        return Files.readString(path)
    }

    override fun deleteWorkflowYaml(s3Path: String): Boolean {
        return try {
            val path = parseMockPath(s3Path)
            Files.deleteIfExists(path)
            true
        } catch (e: Exception) {
            log.warn("Failed to delete mock S3 file: {}", e.message)
            false
        }
    }

    override fun existsWorkflowYaml(s3Path: String): Boolean {
        val path = parseMockPath(s3Path)
        return Files.exists(path)
    }

    private fun parseMockPath(s3Path: String): Path {
        return Path.of(s3Path.removePrefix("mock-s3://"))
    }
}
```

### 6.4 AirflowClient Interface (Domain Port)

```kotlin
// module-core-domain/src/main/kotlin/.../external/AirflowClient.kt
interface AirflowClient {
    fun triggerDAGRun(dagId: String, runId: String, conf: Map<String, Any> = emptyMap()): String
    fun getDAGRun(dagId: String, runId: String): AirflowDAGRunStatus
    fun stopDAGRun(dagId: String, runId: String): Boolean
    fun pauseDAG(dagId: String, isPaused: Boolean): Boolean
    fun createDAG(datasetName: String, schedule: ScheduleInfo, s3Path: String): String  // ê¸°ì¡´ ë©”ì„œë“œ ìœ ì§€
    fun deleteDAG(dagId: String): Boolean  // ê¸°ì¡´ ë©”ì„œë“œ ìœ ì§€
    fun createBackfill(dagId: String, startDate: LocalDate, endDate: LocalDate): BackfillResponse
    fun getBackfill(dagId: String, backfillId: String): BackfillStatus  // dagId íŒŒë¼ë¯¸í„° ì¶”ê°€ (Cluster ì‹ë³„ìš©)
    fun cancelBackfill(dagId: String, backfillId: String): Boolean  // dagId íŒŒë¼ë¯¸í„° ì¶”ê°€ (Cluster ì‹ë³„ìš©)
    fun getDagStatus(dagId: String): AirflowDagStatus
    fun isAvailable(): Boolean
}
```

### 6.5 RestAirflowClient (Airflow 3 API ê¸°ì¤€)

```kotlin
@Component("airflowClient")  // ì™¸ë¶€ API ClientëŠ” @Component ì‚¬ìš© (ê¸°ì¡´ íŒ¨í„´ ì¤€ìˆ˜)
@ConditionalOnProperty("basecamp.workflow.client.type", havingValue = "airflow")
class RestAirflowClient(
    private val clusterRepository: AirflowClusterRepositoryJpa,
    private val restClientBuilder: RestClient.Builder,
) : AirflowClient {

    private val clientCache = ConcurrentHashMap<String, RestClient>()

    override fun triggerDAGRun(dagId: String, runId: String, conf: Map<String, Any>): String {
        val cluster = resolveCluster(dagId)
        val client = getOrCreateClient(cluster)

        // Airflow 3 API ìŠ¤í™
        return client.post()
            .uri("/api/v1/dags/{dag_id}/dagRuns", dagId)
            .body(TriggerDagRunRequest(dagRunId = runId, conf = conf))
            .retrieve()
            .body(DagRunResponse::class.java)
            ?.dagRunId
            ?: throw AirflowIntegrationException("Failed to trigger DAG run")
    }

    /**
     * Airflow 3 Backfill API ì‚¬ìš©
     * POST /api/v1/backfills
     */
    override fun createBackfill(dagId: String, startDate: LocalDate, endDate: LocalDate): BackfillResponse {
        val cluster = resolveCluster(dagId)
        val client = getOrCreateClient(cluster)

        return client.post()
            .uri("/api/v1/backfills")
            .body(CreateBackfillRequest(
                dagId = dagId,
                fromDate = startDate.atStartOfDay().atOffset(ZoneOffset.UTC).toString(),
                toDate = endDate.atStartOfDay().atOffset(ZoneOffset.UTC).toString()
            ))
            .retrieve()
            .body(BackfillResponse::class.java)
            ?: throw AirflowIntegrationException("Failed to create backfill")
    }

    override fun getBackfill(dagId: String, backfillId: String): BackfillStatus {
        val cluster = resolveCluster(dagId)  // dagIdë¡œ Cluster ì‹ë³„
        val client = getOrCreateClient(cluster)

        return client.get()
            .uri("/api/v1/backfills/{backfill_id}", backfillId)
            .retrieve()
            .body(BackfillStatus::class.java)
            ?: throw AirflowIntegrationException("Backfill not found: $backfillId")
    }

    override fun cancelBackfill(dagId: String, backfillId: String): Boolean {
        val cluster = resolveCluster(dagId)  // dagIdë¡œ Cluster ì‹ë³„
        val client = getOrCreateClient(cluster)

        return try {
            client.patch()
                .uri("/api/v1/backfills/{backfill_id}", backfillId)
                .body(UpdateBackfillRequest(isPaused = true))
                .retrieve()
                .toBodilessEntity()
            true
        } catch (e: Exception) {
            log.warn("Failed to cancel backfill: {}", e.message)
            false
        }
    }

    // íŒ€ ê¸°ì¤€ Cluster ë¼ìš°íŒ… (ë™ì¼ í™˜ê²½ ë‚´)
    private fun resolveCluster(dagId: String): AirflowClusterEntity {
        val team = extractTeamFromDagId(dagId)
        return clusterRepository.findByTeam(team)
            ?: throw AirflowClusterNotFoundException(team)
    }

    // Airflow 3 JWT Token (API Key) ì¸ì¦
    private fun getOrCreateClient(cluster: AirflowClusterEntity): RestClient {
        return clientCache.computeIfAbsent(cluster.clusterName) {
            restClientBuilder
                .baseUrl(cluster.airflowUrl)
                .defaultHeaders { headers ->
                    headers.setBearerAuth(cluster.apiKey)  // JWT Token ì¸ì¦
                }
                .build()
        }
    }
}
```

### 6.6 Airflow 3 API DTOs

```kotlin
// Trigger DAG Run
data class TriggerDagRunRequest(
    @JsonProperty("dag_run_id") val dagRunId: String,
    val conf: Map<String, Any> = emptyMap(),
    @JsonProperty("logical_date") val logicalDate: String? = null
)

data class DagRunResponse(
    @JsonProperty("dag_run_id") val dagRunId: String,
    @JsonProperty("dag_id") val dagId: String,
    val state: String,
    @JsonProperty("logical_date") val logicalDate: String?,
    @JsonProperty("start_date") val startDate: String?,
    @JsonProperty("end_date") val endDate: String?,
    val conf: Map<String, Any>?
)

// Backfill (Airflow 3)
data class CreateBackfillRequest(
    @JsonProperty("dag_id") val dagId: String,
    @JsonProperty("from_date") val fromDate: String,
    @JsonProperty("to_date") val toDate: String,
    @JsonProperty("max_active_runs") val maxActiveRuns: Int = 10,
    @JsonProperty("run_backwards") val runBackwards: Boolean = false
)

data class BackfillResponse(
    val id: String,
    @JsonProperty("dag_id") val dagId: String,
    @JsonProperty("from_date") val fromDate: String,
    @JsonProperty("to_date") val toDate: String,
    @JsonProperty("is_paused") val isPaused: Boolean,
    @JsonProperty("created_at") val createdAt: String
)

data class BackfillStatus(
    val id: String,
    @JsonProperty("dag_id") val dagId: String,
    @JsonProperty("from_date") val fromDate: String,
    @JsonProperty("to_date") val toDate: String,
    @JsonProperty("is_paused") val isPaused: Boolean,
    @JsonProperty("completed_at") val completedAt: String?
)

data class UpdateBackfillRequest(
    @JsonProperty("is_paused") val isPaused: Boolean
)
```

---

## 6. API Mapping

### 6.1 Basecamp Server API â†’ Airflow 3 REST API

| Basecamp API | Method | Airflow 3 REST API | Description |
|--------------|--------|-------------------|-------------|
| `POST /api/v1/workflows/{name}/run` | triggerDAGRun | `POST /api/v1/dags/{dag_id}/dagRuns` | DAG ì‹¤í–‰ íŠ¸ë¦¬ê±° |
| `GET /api/v1/workflows/runs/{run_id}` | getDAGRun | `GET /api/v1/dags/{dag_id}/dagRuns/{run_id}` | ì‹¤í–‰ ìƒíƒœ ì¡°íšŒ |
| `POST /api/v1/workflows/runs/{run_id}/stop` | stopDAGRun | `PATCH /api/v1/dags/{dag_id}/dagRuns/{run_id}` | ì‹¤í–‰ ì¤‘ì§€ |
| `POST /api/v1/workflows/{name}/pause` | pauseDAG | `PATCH /api/v1/dags/{dag_id}` | DAG ì¼ì‹œì •ì§€ |
| `POST /api/v1/workflows/{name}/unpause` | pauseDAG | `PATCH /api/v1/dags/{dag_id}` | DAG ì¬ê°œ |
| `POST /api/v1/workflows/{name}/backfill` | createBackfill | `POST /api/v1/backfills` | Backfill ìƒì„± (Airflow 3) |
| `GET /api/v1/workflows/backfills/{id}` | getBackfill | `GET /api/v1/backfills/{id}` | Backfill ìƒíƒœ ì¡°íšŒ |
| `POST /api/v1/workflows/backfills/{id}/cancel` | cancelBackfill | `PATCH /api/v1/backfills/{id}` | Backfill ì·¨ì†Œ |

### 6.2 Airflow 3 DAG Run State Mapping

| Airflow State | Basecamp RunStatus | Description |
|---------------|-------------------|-------------|
| `queued` | `PENDING` | ëŒ€ê¸°ì—´ |
| `running` | `RUNNING` | ì‹¤í–‰ ì¤‘ |
| `success` | `SUCCESS` | ì„±ê³µ |
| `failed` | `FAILED` | ì‹¤íŒ¨ |
| `upstream_failed` | `FAILED` | ì—…ìŠ¤íŠ¸ë¦¼ ì‹¤íŒ¨ |
| `skipped` | `SKIPPED` | ê±´ë„ˆëœ€ |
| `restarting` | `RUNNING` | ì¬ì‹œì‘ ì¤‘ |

---

## 7. Configuration

### 7.1 Application Configuration

```yaml
# application.yml
# ë„¤ì„ìŠ¤í˜ì´ìŠ¤: basecamp.workflow.* (ê¸°ì¡´ basecamp.* íŒ¨í„´ ì¤€ìˆ˜)
basecamp:
  workflow:
    client:
      type: mock   # mock | airflow
      connection-timeout: 10s
      read-timeout: 30s
      retry:
        max-attempts: 3
        delay: 1s
        multiplier: 2.0

    storage:
      type: mock   # mock | s3
      bucket: company-workflows
      prefix: workflows
      region: us-west-2
      mock-dir: ./mock-s3  # Mock ëª¨ë“œìš© ë¡œì»¬ ë””ë ‰í† ë¦¬

    sync:
      enabled: true
      cron: "0 */5 * * * *"  # 5ë¶„ë§ˆë‹¤ (ì„¤ì • ê°€ëŠ¥)

# ë¡œì»¬ ê°œë°œ í™˜ê²½
---
spring:
  config:
    activate:
      on-profile: local

basecamp:
  workflow:
    client:
      type: mock
    storage:
      type: mock
      mock-dir: ./mock-s3
    sync:
      enabled: true
      cron: "0 */1 * * * *"  # 1ë¶„ë§ˆë‹¤ (ê°œë°œìš©)

# í”„ë¡œë•ì…˜ í™˜ê²½
---
spring:
  config:
    activate:
      on-profile: prod

basecamp:
  workflow:
    client:
      type: airflow
    storage:
      type: s3
      bucket: ${WORKFLOW_S3_BUCKET}
      prefix: workflows
      region: ${AWS_REGION}
    sync:
      enabled: true
      cron: "0 */5 * * * *"
```

### 7.2 Sample Cluster Data (ê´€ë¦¬ì ì§ì ‘ ë“±ë¡)

```sql
-- DEV í™˜ê²½ ì˜ˆì‹œ
INSERT INTO airflow_clusters (team, cluster_name, airflow_url, environment, dag_s3_path, dag_name_prefix, is_active, api_key, description)
VALUES
('@data-platform', 'dp-airflow', 'https://airflow.dev.company.com', 'DEVELOPMENT', 's3://company-workflows-dev/', 'dp', true, '${AIRFLOW_API_KEY}', 'Data Platform Team Airflow'),
('@analytics', 'analytics-airflow', 'https://airflow-analytics.dev.company.com', 'DEVELOPMENT', 's3://analytics-workflows-dev/', 'an', true, '${AIRFLOW_API_KEY}', 'Analytics Team Airflow');
```

---

## 8. Error Handling

### 8.1 Exception Hierarchy

```kotlin
// module-core-infra/exception/AirflowIntegrationException.kt
// (ì™¸ë¶€ ì‹œìŠ¤í…œ ì—°ë™ ì˜ˆì™¸ëŠ” Infra ëª¨ë“ˆì— ë°°ì¹˜)
sealed class AirflowIntegrationException(message: String, cause: Throwable? = null)
    : RuntimeException(message, cause) {

    class ConnectionFailed(url: String, cause: Throwable)
        : AirflowIntegrationException("Failed to connect to Airflow at $url", cause)

    class AuthenticationFailed(url: String)
        : AirflowIntegrationException("JWT authentication failed for Airflow at $url")

    class DagNotFound(dagId: String)
        : AirflowIntegrationException("DAG not found: $dagId")

    class DagRunNotFound(dagId: String, runId: String)
        : AirflowIntegrationException("DAG run not found: $dagId/$runId")

    class BackfillNotFound(backfillId: String)
        : AirflowIntegrationException("Backfill not found: $backfillId")

    class RateLimitExceeded(retryAfter: Duration)
        : AirflowIntegrationException("Rate limit exceeded, retry after $retryAfter")

    class ServerError(statusCode: Int, message: String)
        : AirflowIntegrationException("Airflow server error ($statusCode): $message")
}

class AirflowClusterNotFoundException(team: String)
    : RuntimeException("No active Airflow cluster found for team: $team")
```

### 8.2 Error Response Mapping

| Airflow HTTP Status | Basecamp Error Code | Description |
|---------------------|---------------------|-------------|
| 401 | `AIRFLOW_AUTH_FAILED` | JWT ì¸ì¦ ì‹¤íŒ¨ |
| 403 | `AIRFLOW_PERMISSION_DENIED` | ê¶Œí•œ ë¶€ì¡± |
| 404 | `AIRFLOW_DAG_NOT_FOUND` | DAG/Run ì—†ìŒ |
| 429 | `AIRFLOW_RATE_LIMITED` | ìš”ì²­ ì œí•œ |
| 500-599 | `AIRFLOW_SERVER_ERROR` | ì„œë²„ ì˜¤ë¥˜ |
| Connection Error | `AIRFLOW_CONNECTION_FAILED` | ì—°ê²° ì‹¤íŒ¨ |
| Timeout | `AIRFLOW_TIMEOUT` | íƒ€ì„ì•„ì›ƒ |

---

## 8.3 Migration Note: InMemoryWorkflowStorage

> **ê¸°ì¡´ ì½”ë“œ ë§ˆì´ê·¸ë ˆì´ì…˜ í•„ìš”**

í˜„ì¬ `InMemoryWorkflowStorage`ëŠ” `@ConditionalOnProperty` ì—†ì´ ì •ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
ìƒˆë¡œìš´ `MockS3WorkflowStorage` êµ¬í˜„ê³¼ ì¶©ëŒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ë‹¤ìŒ ì‘ì—…ì´ í•„ìš”í•©ë‹ˆë‹¤:

```kotlin
// ê¸°ì¡´ InMemoryWorkflowStorageì— ì¡°ê±´ë¶€ í™œì„±í™” ì¶”ê°€
@Repository("workflowStorage")
@ConditionalOnProperty(
    "basecamp.workflow.storage.type",
    havingValue = "inmemory",  // ë³„ë„ íƒ€ì…ìœ¼ë¡œ ë¶„ë¦¬
    matchIfMissing = false     // ëª…ì‹œì  ì„¤ì • í•„ìš”
)
class InMemoryWorkflowStorage : WorkflowStorage {
    // ê¸°ì¡´ êµ¬í˜„...
}
```

**ë§ˆì´ê·¸ë ˆì´ì…˜ ìˆœì„œ:**
1. ê¸°ì¡´ `InMemoryWorkflowStorage`ì— `@ConditionalOnProperty` ì¶”ê°€
2. `MockS3WorkflowStorage` êµ¬í˜„ (íŒŒì¼ì‹œìŠ¤í…œ ê¸°ë°˜)
3. `S3WorkflowStorage` êµ¬í˜„ (ì‹¤ì œ S3)
4. í™˜ê²½ë³„ ì„¤ì • ì ìš© (`basecamp.workflow.storage.type`)

---

## 9. Implementation Checklist

### Phase 1: S3 Mock & Storage (Week 1-2, ìš°ì„ ìˆœìœ„ ìµœê³ )

| ì‘ì—… | ì˜ì¡´ì„± | ì˜ˆìƒ ê³µìˆ˜ |
|------|--------|-----------|
| [ ] `WorkflowStorage` ì¸í„°í˜ì´ìŠ¤ í™•ì¥ (listAllSpecs ì¶”ê°€) | - | 0.5ì¼ |
| [ ] `MockS3WorkflowStorage` êµ¬í˜„ (ë¡œì»¬ íŒŒì¼ì‹œìŠ¤í…œ ê¸°ë°˜) | Interface | 1ì¼ |
| [ ] `S3WorkflowStorage` êµ¬í˜„ (AWS SDK) | Interface | 1ì¼ |
| [ ] `WorkflowYamlParser` êµ¬í˜„ (YAML íŒŒì‹±) | - | 1ì¼ |
| [ ] Unit Tests (Storage, Parser) | êµ¬í˜„ ì™„ë£Œ | 1ì¼ |

### Phase 2: S3 Sync Service (Week 2-3, í•µì‹¬ ê¸°ëŠ¥)

| ì‘ì—… | ì˜ì¡´ì„± | ì˜ˆìƒ ê³µìˆ˜ |
|------|--------|-----------|
| [ ] `WorkflowSyncService` êµ¬í˜„ | Storage, Parser | 1.5ì¼ |
| [ ] `WorkflowSyncScheduler` êµ¬í˜„ (Spring Scheduler) | SyncService | 0.5ì¼ |
| [ ] ìˆ˜ë™ Sync API êµ¬í˜„ | SyncService | 0.5ì¼ |
| [ ] Integration Tests | ì „ì²´ | 1ì¼ |

### Phase 3: AirflowCluster Entity (Week 3)

| ì‘ì—… | ì˜ì¡´ì„± | ì˜ˆìƒ ê³µìˆ˜ |
|------|--------|-----------|
| [ ] `AirflowClusterEntity` ìƒì„± | - | 0.5ì¼ |
| [ ] `AirflowClusterRepository` ì¸í„°í˜ì´ìŠ¤/êµ¬í˜„ | Entity | 0.5ì¼ |
| [ ] Database Migration (DDL) | Entity | 0.5ì¼ |
| [ ] Unit Tests (Entity, Repository) | êµ¬í˜„ ì™„ë£Œ | 0.5ì¼ |

### Phase 4: Airflow 3 Client Implementation (Week 4-5)

| ì‘ì—… | ì˜ì¡´ì„± | ì˜ˆìƒ ê³µìˆ˜ |
|------|--------|-----------|
| [ ] Airflow 3 API DTO ì •ì˜ | - | 0.5ì¼ |
| [ ] `RestAirflowClient` ê¸°ë³¸ êµ¬í˜„ (Airflow 3 ê¸°ì¤€) | Cluster Entity | 1.5ì¼ |
| [ ] Backfill API êµ¬í˜„ (Airflow 3 /api/v1/backfills) | Client ê¸°ë³¸ | 0.5ì¼ |
| [ ] Resilience4j í†µí•© (Circuit Breaker, Retry) | Client ê¸°ë³¸ | 0.5ì¼ |
| [ ] Mock Airflow Server (WireMock) í…ŒìŠ¤íŠ¸ | Client êµ¬í˜„ | 1ì¼ |
| [ ] Integration Tests | ì „ì²´ | 1ì¼ |

### Phase 5: DAG Run Sync Service (Week 5-6)

| ì‘ì—… | ì˜ì¡´ì„± | ì˜ˆìƒ ê³µìˆ˜ |
|------|--------|-----------|
| [ ] `WorkflowRunEntity` í™•ì¥ (Airflow ì—°ë™ í•„ë“œ ì¶”ê°€) | - | 0.5ì¼ |
| [ ] Database Migration (workflow_runs í…Œì´ë¸” í™•ì¥) | Entity ìˆ˜ì • | 0.5ì¼ |
| [ ] `AirflowService` êµ¬í˜„ | Phase 4 ì™„ë£Œ | 1.5ì¼ |
| [ ] `AirflowSyncScheduler` êµ¬í˜„ | SyncService | 0.5ì¼ |
| [ ] ìˆ˜ë™ Run Sync API êµ¬í˜„ | SyncService | 0.5ì¼ |
| [ ] `AirflowClient` í™•ì¥ (listRecentDagRuns, getTaskInstances) | Client ê¸°ë³¸ | 1ì¼ |
| [ ] Unit Tests (SyncService) | êµ¬í˜„ ì™„ë£Œ | 1ì¼ |
| [ ] Integration Tests | ì „ì²´ | 1ì¼ |

### Phase 6: WorkflowService Integration (Week 6-7)

| ì‘ì—… | ì˜ì¡´ì„± | ì˜ˆìƒ ê³µìˆ˜ |
|------|--------|-----------|
| [ ] `WorkflowService` ìˆ˜ì • (Cluster ë¼ìš°íŒ… ì ìš©) | Phase 5 ì™„ë£Œ | 1ì¼ |
| [ ] GET API ìˆ˜ì • (DB ì¡°íšŒë¡œ ë³€ê²½, Airflow ì§ì ‘ í˜¸ì¶œ ì œê±°) | Phase 5 ì™„ë£Œ | 0.5ì¼ |
| [ ] í™˜ê²½ë³„ Client ì „í™˜ ë¡œì§ | Config | 0.5ì¼ |
| [ ] End-to-End Tests | ì „ì²´ í†µí•© | 1ì¼ |
| [ ] Documentation ì—…ë°ì´íŠ¸ | - | 0.5ì¼ |

**ì´ ì˜ˆìƒ ê¸°ê°„:** 7ì£¼ (1.75 FTE)

---

## 10. GITHUB_FEATURE.md í†µí•© ì™„ë£Œ

### 10.1 ì´ê´€ í•­ëª©

ë‹¤ìŒ ë‚´ìš©ì´ GITHUB_FEATURE.mdì—ì„œ ë³¸ ë¬¸ì„œë¡œ ì´ê´€ë˜ì—ˆìŠµë‹ˆë‹¤:

| í•­ëª© | ì›ë³¸ ìœ„ì¹˜ | ìƒíƒœ |
|------|-----------|------|
| `AirflowClusterEntity` | GITHUB_FEATURE.md Â§ Domain Model | âœ… ì´ê´€ ì™„ë£Œ |
| `AirflowClusterRepository` | GITHUB_FEATURE.md Â§ Repository Layer | âœ… ì´ê´€ ì™„ë£Œ |
| `AirflowEnvironment` enum | GITHUB_FEATURE.md Â§ Domain Model | âœ… ì´ê´€ ì™„ë£Œ |
| DDL: `airflow_clusters` í…Œì´ë¸” | GITHUB_FEATURE.md Â§ Database Schema | âœ… ì´ê´€ ì™„ë£Œ |

### 10.2 GITHUB_FEATURE.mdì—ì„œ ìœ ì§€í•  ë‚´ìš©

GITHUB_FEATURE.mdëŠ” ë‹¤ìŒ ë‚´ìš©ë§Œ ìœ ì§€:

- `GitHubRepositoryEntity` ë° ê´€ë ¨ Repository
- GitHub API ì—°ë™ (Mock)
- GitHub â†” S3 CI/CD ì›Œí¬í”Œë¡œìš° (ê°œë…ë§Œ)

---

## 11. Dependencies

### 11.1 ìƒˆë¡œ ì¶”ê°€ë  ì˜ì¡´ì„±

```kotlin
// build.gradle.kts

// AWS SDK v2 for S3
implementation("software.amazon.awssdk:s3:2.29.x")
implementation("software.amazon.awssdk:sso:2.29.x")  // SSO ì¸ì¦ìš©

// YAML Parser
implementation("com.fasterxml.jackson.dataformat:jackson-dataformat-yaml")

// Resilience4j for Circuit Breaker
implementation("io.github.resilience4j:resilience4j-spring-boot3:2.2.x")
implementation("io.github.resilience4j:resilience4j-circuitbreaker:2.2.x")
implementation("io.github.resilience4j:resilience4j-retry:2.2.x")

// Test: LocalStack for S3, WireMock for Airflow
testImplementation("org.testcontainers:localstack:1.20.x")
testImplementation("org.wiremock:wiremock:3.10.x")
```

### 11.2 ê¸°ì¡´ ì˜ì¡´ì„± í™œìš©

- Spring RestClient (Spring Boot 3.2+ì— í¬í•¨)
- Jackson (JSON ì§ë ¬í™”)
- Spring Data JPA (AirflowClusterEntity)
- Spring Scheduler (S3 Sync ìŠ¤ì¼€ì¤„ë§)

---

## 12. Appendix

### A. Airflow 3 REST API Reference

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/dags` | GET | DAG ëª©ë¡ ì¡°íšŒ |
| `/api/v1/dags/{dag_id}` | GET | DAG ìƒì„¸ ì¡°íšŒ |
| `/api/v1/dags/{dag_id}` | PATCH | DAG ìˆ˜ì • (pause/unpause) |
| `/api/v1/dags/{dag_id}/dagRuns` | GET | DAG Run ëª©ë¡ |
| `/api/v1/dags/{dag_id}/dagRuns` | POST | DAG Run ìƒì„± |
| `/api/v1/dags/{dag_id}/dagRuns/{run_id}` | GET | DAG Run ìƒì„¸ |
| `/api/v1/dags/{dag_id}/dagRuns/{run_id}` | PATCH | DAG Run ìˆ˜ì • |
| `/api/v1/backfills` | POST | Backfill ìƒì„± (Airflow 3) |
| `/api/v1/backfills/{backfill_id}` | GET | Backfill ìƒíƒœ ì¡°íšŒ |
| `/api/v1/backfills/{backfill_id}` | PATCH | Backfill ìˆ˜ì • (ì·¨ì†Œ) |
| `/api/v1/health` | GET | í—¬ìŠ¤ì²´í¬ |

### B. Related Documents

| Document | Purpose |
|----------|---------|
| [`WORKFLOW_FEATURE.md`](./WORKFLOW_FEATURE.md) | Workflow API ëª…ì„¸ (100% ì™„ë£Œ) |
| [`WORKFLOW_RELEASE.md`](./WORKFLOW_RELEASE.md) | Workflow API êµ¬í˜„ ìƒì„¸ |
| [`GITHUB_FEATURE.md`](./GITHUB_FEATURE.md) | GitHub ì—°ë™ (GitHubRepositoryEntityë§Œ ìœ ì§€) |
| [Apache Airflow REST API](https://airflow.apache.org/docs/apache-airflow/stable/stable-rest-api-ref.html) | ê³µì‹ API ë¬¸ì„œ |

---

**Document Version:** 2.2.0
**Created:** 2026-01-04
**Last Updated:** 2026-01-04

### Changelog

| Version | Date | Changes |
|---------|------|---------|
| 2.2.0 | 2026-01-04 | Implementation complete. All phases (1-6) implemented with Mock clients. |
| 2.1.1 | 2026-01-04 | Agent ë¦¬ë·° í”¼ë“œë°± ë°˜ì˜: H1-H4 ìˆ˜ì • (Enum í™•ì¥ ë…¸íŠ¸, Repository í™•ì¥ ì„¹ì…˜, ëª¨ë“ˆ ê²½ë¡œ, syncCluster public ë©”ì„œë“œ) |
| 2.1.0 | 2026-01-04 | DAG Run Sync Service ì„¹ì…˜ ì¶”ê°€ (Â§5), Implementation Checklist Phase 5-6 ì¶”ê°€ |
| 2.0.0 | 2026-01-04 | ì´ˆê¸° ë²„ì „, GITHUB_FEATURE.mdì—ì„œ Airflow ê´€ë ¨ ë‚´ìš© ì´ê´€, ë¦¬ë·° í”¼ë“œë°± ë°˜ì˜ |

**Author:** Platform Integration Architect

---

## âœ… Implementation Complete

**Completed:** 2026-01-04
**Release Document:** [AIRFLOW_RELEASE.md](./AIRFLOW_RELEASE.md)

All phases (1-6) have been implemented:

| Phase | Feature | Status | Lines |
|-------|---------|--------|-------|
| **Phase 1** | S3 Storage Infrastructure | âœ… Complete | MockS3WorkflowStorage (373 lines) |
| **Phase 2** | S3 Spec Sync Service | âœ… Complete | WorkflowSpecSyncService (247 lines) + WorkflowYamlParser (154 lines) |
| **Phase 3** | AirflowClusterEntity | âœ… Complete | Entity + Repositories (~200 lines total) |
| **Phase 4** | AirflowClient Extension (Mock) | âœ… Complete | MockRestAirflowClient (573 lines) + DTOs (166 lines) |
| **Phase 5** | DAG Run Sync Service | âœ… Complete | AirflowService (340 lines) + Scheduler (120 lines) |
| **Phase 6** | WorkflowService Integration | âœ… Complete | AirflowSyncController (183 lines) + DTOs/Mapper (~190 lines) |

**API Endpoints Implemented:**
- `POST /api/v1/airflow/sync/manual/specs` - Manual S3 Spec Sync
- `POST /api/v1/airflow/sync/manual/runs` - Manual DAG Run Sync
- `POST /api/v1/airflow/sync/manual/runs/cluster/{id}` - Cluster-specific Run Sync
- `POST /api/v1/airflow/sync/manual/runs/stale` - Sync stale runs

**Test Coverage:** 100+ tests (~2,617 lines)

**Future Work (Production):**
- Real S3WorkflowStorage implementation (AWS SDK)
- Real RestAirflowClient implementation (Airflow 3 REST API)
- Resilience4j integration (Circuit Breaker, Retry)
